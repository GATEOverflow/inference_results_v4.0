[2024-02-22 06:45:44,752][INFO] run.py:23   - Loading configurations from /home/ucstme/inference-v4.01/closed/Intel/code/automation/config.yaml.
[2024-02-22 06:45:44,788][INFO] run.py:141  - Parsing args:
[2024-02-22 06:45:44,789][INFO] run.py:144  - args: Namespace(model='gptj-99', implementation='pytorch-cpu', dtype='int4', dataset_dir='/data/mlperf_data1/gpt-j/data', model_dir='/data/mlperf_data1/gpt-j/data', output='/data/mlperf_data1/gpt-j', container_name_suffix='Cisco-UCS', performance_only=False, accuracy_only=False, offline_only=False, server_only=False, compliance_only=False, skip_docker_build=False, skip_create_container=False, skip_data_preprocess=False, ci_run=False)
[2024-02-22 06:45:44,790][INFO] run.py:281  - Collecting environment information on baremetal.
[2024-02-22 06:45:44,916][INFO] run.py:212  - Building docker image for gptj-99/pytorch-cpu/int4.
[2024-02-22 07:32:30,155][INFO] run.py:239  - Successfully built image: sha256:a4bd8d81879cfc1068caae64943f7bc39cd9f9bbfb1c266274231d4af3fe8914
[2024-02-22 07:32:30,155][INFO] run.py:299  - ===== Using docker image: sha256:a4bd8d81879c =====
[2024-02-22 07:32:30,155][INFO] run.py:243  - Launching docker container for gptj-99.
[2024-02-22 07:32:30,236][INFO] run.py:258  - Successfully launched container: 402ae81fc7e8 for image: sha256:a4bd8d81879c
[2024-02-22 07:32:30,236][INFO] run.py:308  - ===== Running workloads in container: 402ae81fc7e8 =====
[2024-02-22 07:32:32,237][INFO] common.py:17    - Executing bash commands: export CONTAINER_MODEL_DIR=/data/mlperf_data/gpt-j/models && export CONTAINER_DATA_DIR=/data/mlperf_data/gpt-j/data && export CONTAINER_CODE_DIR=/opt/workdir/code/gptj-99/pytorch-cpu && export CONTAINER_OUTPUT_DIR=/output && export CONTAINER_COMPLIANCE_SUITE_DIR=/opt/workdir/code/gptj-99/pytorch-cpu/gpt-j-env/mlperf_inference/compliance/nvidia && export MODEL=gptj-99 && export IMPL=pytorch-cpu && export DTYPE=int4 && export ci_run=0 && export WORKLOAD_DATA=${CONTAINER_CODE_DIR}/data && export CALIBRATION_DATA_JSON=${WORKLOAD_DATA}/calibration-data/cnn_dailymail_calibration.json && export CHECKPOINT_DIR=${WORKLOAD_DATA}/gpt-j-checkpoint && export VALIDATION_DATA_JSON=${WORKLOAD_DATA}/validation-data/cnn_dailymail_validation.json && export INT4_MODEL_DIR=${WORKLOAD_DATA}/gpt-j-int4-model && export CALIBRATION_DIR=${CONTAINER_CODE_DIR}/../../../calibration/gptj-99/pytorch-cpu  && ln -sf ${CONTAINER_DATA_DIR} ${WORKLOAD_DATA} && cd ${CALIBRATION_DIR} && bash run_int4_gpt-j_on_cnndailymail.sh && rm -rf ${INT4_MODEL_DIR} && mkdir -p ${INT4_MODEL_DIR} && ln -sf ${CALIBRATION_DIR}/saved_results/int4_model.pt ${INT4_MODEL_DIR}/best_int4_model.pt 2>&1 | tee ${CONTAINER_OUTPUT_DIR}/preproc_${MODEL}_${IMPL}_${DTYPE}.log
[2024-02-22 07:32:32,237][INFO] run.py:338  - Loading configurations from config.yaml.

[2024-02-22 07:32:32,237][INFO] run.py:338  - Parsing args:

[2024-02-22 07:32:32,237][INFO] run.py:338  - args in container: Namespace(model='gptj-99', implementation='pytorch-cpu', dtype='int4', prepare=True, performance=True, accuracy=True, compliance=True, offline=True, server=True, sensors=True, cirun=False)

[2024-02-22 07:32:32,237][INFO] run.py:338  - Collecting environment information in container.

[2024-02-22 07:32:32,237][INFO] run.py:338  - Exporting environment variables.

[2024-02-22 07:32:32,237][INFO] run.py:338  - ===== Preprocessing for gptj-99 =====

[2024-02-22 07:32:32,237][INFO] run.py:338  - [2024-02-22 07:32:32,237][INFO] common.py:17    - Executing bash commands: export CONTAINER_MODEL_DIR=/data/mlperf_data/gpt-j/models && export CONTAINER_DATA_DIR=/data/mlperf_data/gpt-j/data && export CONTAINER_CODE_DIR=/opt/workdir/code/gptj-99/pytorch-cpu && export CONTAINER_OUTPUT_DIR=/output && export CONTAINER_COMPLIANCE_SUITE_DIR=/opt/workdir/code/gptj-99/pytorch-cpu/gpt-j-env/mlperf_inference/compliance/nvidia && export MODEL=gptj-99 && export IMPL=pytorch-cpu && export DTYPE=int4 && export ci_run=0 && export WORKLOAD_DATA=${CONTAINER_CODE_DIR}/data && export CALIBRATION_DATA_JSON=${WORKLOAD_DATA}/calibration-data/cnn_dailymail_calibration.json && export CHECKPOINT_DIR=${WORKLOAD_DATA}/gpt-j-checkpoint && export VALIDATION_DATA_JSON=${WORKLOAD_DATA}/validation-data/cnn_dailymail_validation.json && export INT4_MODEL_DIR=${WORKLOAD_DATA}/gpt-j-int4-model && export CALIBRATION_DIR=${CONTAINER_CODE_DIR}/../../../calibration/gptj-99/pytorch-cpu  && ln -sf ${CONTAINER_DATA_DIR} ${WORKLOAD_DATA} && cd ${CALIBRATION_DIR} && bash run_int4_gpt-j_on_cnndailymail.sh && rm -rf ${INT4_MODEL_DIR} && mkdir -p ${INT4_MODEL_DIR} && ln -sf ${CALIBRATION_DIR}/saved_results/int4_model.pt ${INT4_MODEL_DIR}/best_int4_model.pt 2>&1 | tee ${CONTAINER_OUTPUT_DIR}/preproc_${MODEL}_${IMPL}_${DTYPE}.log

[2024-02-22 07:32:32,239][INFO] run.py:338  - + export LD_LIBRARY_PATH=/opt/conda/lib:

[2024-02-22 07:32:32,239][INFO] run.py:338  - + LD_LIBRARY_PATH=/opt/conda/lib:

[2024-02-22 07:32:32,239][INFO] run.py:338  - + export GROUP_SIZE=-1

[2024-02-22 07:32:32,239][INFO] run.py:338  - + GROUP_SIZE=-1

[2024-02-22 07:32:32,239][INFO] run.py:338  - + export OUTPUT_DIR=saved_results

[2024-02-22 07:32:32,239][INFO] run.py:338  - + OUTPUT_DIR=saved_results

[2024-02-22 07:32:32,239][INFO] run.py:338  - + unset LD_PRELOAD KMP_BLOCKTIME KMP_TPAUSE KMP_SETTINGS KMP_AFFINITY KMP_FORKJOIN_BARRIER_PATTERN KMP_PLAIN_BARRIER_PATTERN KMP_REDUCTION_BARRIER_PATTERN

[2024-02-22 07:32:32,239][INFO] run.py:338  - ++ date '+%Y-%m-%d %T'

[2024-02-22 07:32:32,240][INFO] run.py:338  - + echo '2024-02-22 07:32:32 - INFO - Download finetuned GPT-J model...'

[2024-02-22 07:32:32,240][INFO] run.py:338  - + retVal=0

[2024-02-22 07:32:32,240][INFO] run.py:338  - + '[' 0 -ne 0 ']'

[2024-02-22 07:32:32,240][INFO] run.py:338  - ++ date '+%Y-%m-%d %T'

[2024-02-22 07:32:32,241][INFO] run.py:338  - + echo '2024-02-22 07:32:32 - INFO - Finetuned GPT-J model downloaded'

[2024-02-22 07:32:32,241][INFO] run.py:338  - ++ date '+%Y-%m-%d %T'

[2024-02-22 07:32:32,241][INFO] run.py:338  - + echo '2024-02-22 07:32:32 - INFO - Extract GPT-J model...'

[2024-02-22 07:32:32,241][INFO] run.py:338  - + model_path=/opt/workdir/code/gptj-99/pytorch-cpu/data/gpt-j-checkpoint

[2024-02-22 07:32:32,242][INFO] run.py:338  - ++ date '+%Y-%m-%d %T'

[2024-02-22 07:32:32,242][INFO] run.py:338  - + echo '2024-02-22 07:32:32 - INFO - GPT-J model extracted to  /opt/workdir/code/gptj-99/pytorch-cpu/data/gpt-j-checkpoint'

[2024-02-22 07:32:32,242][INFO] run.py:338  - + python ./run_int4_gpt-j_on_cnndailymail.py --model /opt/workdir/code/gptj-99/pytorch-cpu/data/gpt-j-checkpoint --output-dir saved_results --group-size -1

[2024-02-22 07:32:33,177][INFO] run.py:338  - /opt/conda/lib/python3.9/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.

[2024-02-22 07:32:33,177][INFO] run.py:338  -   _torch_pytree._register_pytree_node(

[2024-02-22 07:32:34,241][INFO] run.py:338  - /opt/conda/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.

[2024-02-22 07:32:34,241][INFO] run.py:338  -   _torch_pytree._register_pytree_node(

[2024-02-22 07:32:34,620][INFO] run.py:338  - /opt/conda/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.

[2024-02-22 07:32:34,620][INFO] run.py:338  -   _torch_pytree._register_pytree_node(

[2024-02-22 07:32:35,460][INFO] run.py:338  - [nltk_data] Downloading package punkt to /root/nltk_data...

[2024-02-22 07:32:35,621][INFO] run.py:338  - [nltk_data]   Unzipping tokenizers/punkt.zip.

[2024-02-22 07:32:36,396][INFO] run.py:338  - Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]Downloading builder script: 100%|██████████| 6.27k/6.27k [00:00<00:00, 28.8MB/s]

[2024-02-22 07:32:36,414][INFO] run.py:338  - 2024-02-22 07:32:36,414 - root - INFO - Loading validation split of /opt/workdir/code/gptj-99/pytorch-cpu/data/gpt-j-checkpoint dataset...

[2024-02-22 07:32:37,248][INFO] run.py:338  - Downloading readme:   0%|          | 0.00/15.6k [00:00<?, ?B/s]Downloading readme: 100%|██████████| 15.6k/15.6k [00:00<00:00, 57.7MB/s]

[2024-02-22 07:32:45,972][INFO] run.py:338  - Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]Downloading data:   2%|▏         | 4.19M/257M [00:00<00:15, 16.0MB/s]Downloading data:   5%|▍         | 12.6M/257M [00:00<00:07, 32.1MB/s]Downloading data:   8%|▊         | 21.0M/257M [00:00<00:05, 40.1MB/s]Downloading data:  11%|█▏        | 29.4M/257M [00:00<00:05, 44.4MB/s]Downloading data:  15%|█▍        | 37.7M/257M [00:00<00:04, 44.9MB/s]Downloading data:  18%|█▊        | 46.1M/257M [00:01<00:04, 47.6MB/s]Downloading data:  21%|██▏       | 54.5M/257M [00:01<00:04, 48.0MB/s]Downloading data:  25%|██▍       | 62.9M/257M [00:01<00:03, 48.9MB/s]Downloading data:  28%|██▊       | 71.3M/257M [00:01<00:03, 50.0MB/s]Downloading data:  31%|███       | 79.7M/257M [00:01<00:03, 50.0MB/s]Downloading data:  34%|███▍      | 88.1M/257M [00:01<00:03, 50.7MB/s]Downloading data:  38%|███▊      | 96.5M/257M [00:02<00:03, 50.9MB/s]Downloading data:  41%|████      | 105M/257M [00:02<00:02, 51.4MB/s] Downloading data:  44%|████▍     | 113M/257M [00:02<00:02, 51.7MB/s]Downloading data:  47%|████▋     | 122M/257M [00:02<00:02, 51.9MB/s]Downloading data:  51%|█████     | 130M/257M [00:02<00:02, 52.0MB/s]Downloading data:  54%|█████▍    | 138M/257M [00:02<00:02, 51.9MB/s]Downloading data:  57%|█████▋    | 147M/257M [00:03<00:02, 44.6MB/s]Downloading data:  60%|██████    | 155M/257M [00:03<00:02, 46.7MB/s]Downloading data:  64%|██████▍   | 164M/257M [00:03<00:01, 48.1MB/s]Downloading data:  67%|██████▋   | 172M/257M [00:03<00:01, 49.3MB/s]Downloading data:  70%|███████   | 180M/257M [00:03<00:01, 50.9MB/s]Downloading data:  74%|███████▎  | 189M/257M [00:03<00:01, 51.8MB/s]Downloading data:  77%|███████▋  | 197M/257M [00:04<00:01, 52.0MB/s]Downloading data:  80%|████████  | 206M/257M [00:04<00:00, 52.2MB/s]Downloading data:  83%|████████▎ | 214M/257M [00:04<00:00, 52.4MB/s]Downloading data:  87%|████████▋ | 222M/257M [00:04<00:00, 52.5MB/s]Downloading data:  90%|████████▉ | 231M/257M [00:04<00:00, 52.2MB/s]Downloading data:  93%|█████████▎| 239M/257M [00:04<00:00, 51.9MB/s]Downloading data:  96%|█████████▋| 247M/257M [00:05<00:00, 52.2MB/s]Downloading data: 100%|█████████▉| 256M/257M [00:05<00:00, 56.5MB/s]Downloading data: 100%|██████████| 257M/257M [00:05<00:00, 49.7MB/s]

[2024-02-22 07:32:51,707][INFO] run.py:338  - Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]Downloading data:   2%|▏         | 4.19M/257M [00:00<00:18, 13.3MB/s]Downloading data:   5%|▍         | 12.6M/257M [00:00<00:08, 29.8MB/s]Downloading data:   8%|▊         | 21.0M/257M [00:00<00:06, 35.1MB/s]Downloading data:  11%|█▏        | 29.4M/257M [00:00<00:05, 41.0MB/s]Downloading data:  15%|█▍        | 37.7M/257M [00:01<00:05, 43.6MB/s]Downloading data:  18%|█▊        | 46.1M/257M [00:01<00:04, 46.3MB/s]Downloading data:  21%|██▏       | 54.5M/257M [00:01<00:04, 47.5MB/s]Downloading data:  25%|██▍       | 62.9M/257M [00:01<00:03, 48.5MB/s]Downloading data:  28%|██▊       | 71.3M/257M [00:01<00:03, 50.1MB/s]Downloading data:  31%|███       | 79.7M/257M [00:01<00:03, 50.8MB/s]Downloading data:  34%|███▍      | 88.1M/257M [00:01<00:03, 51.5MB/s]Downloading data:  38%|███▊      | 96.5M/257M [00:02<00:04, 38.5MB/s]Downloading data:  41%|████      | 105M/257M [00:02<00:03, 41.9MB/s] Downloading data:  44%|████▍     | 113M/257M [00:02<00:03, 44.3MB/s]Downloading data:  47%|████▋     | 122M/257M [00:02<00:02, 46.2MB/s]Downloading data:  51%|█████     | 130M/257M [00:02<00:02, 48.0MB/s]Downloading data:  54%|█████▍    | 138M/257M [00:03<00:02, 49.3MB/s]Downloading data:  57%|█████▋    | 147M/257M [00:03<00:02, 50.1MB/s]Downloading data:  60%|██████    | 155M/257M [00:03<00:02, 50.5MB/s]Downloading data:  64%|██████▍   | 164M/257M [00:03<00:01, 49.7MB/s]Downloading data:  67%|██████▋   | 172M/257M [00:03<00:01, 50.8MB/s]Downloading data:  70%|███████   | 180M/257M [00:03<00:01, 51.0MB/s]Downloading data:  74%|███████▎  | 189M/257M [00:04<00:01, 51.4MB/s]Downloading data:  77%|███████▋  | 197M/257M [00:04<00:01, 51.8MB/s]Downloading data:  80%|████████  | 206M/257M [00:04<00:00, 51.6MB/s]Downloading data:  83%|████████▎ | 214M/257M [00:04<00:00, 51.6MB/s]Downloading data:  87%|████████▋ | 222M/257M [00:04<00:00, 52.4MB/s]Downloading data:  90%|████████▉ | 231M/257M [00:04<00:00, 50.9MB/s]Downloading data:  93%|█████████▎| 239M/257M [00:05<00:00, 51.3MB/s]Downloading data:  96%|█████████▋| 247M/257M [00:05<00:00, 51.4MB/s]Downloading data: 100%|█████████▉| 256M/257M [00:05<00:00, 56.1MB/s]Downloading data: 100%|██████████| 257M/257M [00:05<00:00, 47.9MB/s]

[2024-02-22 07:32:57,014][INFO] run.py:338  - Downloading data:   0%|          | 0.00/259M [00:00<?, ?B/s]Downloading data:   2%|▏         | 4.19M/259M [00:00<00:11, 21.6MB/s]Downloading data:   5%|▍         | 12.6M/259M [00:00<00:06, 37.6MB/s]Downloading data:   8%|▊         | 21.0M/259M [00:00<00:05, 44.3MB/s]Downloading data:  11%|█▏        | 29.4M/259M [00:00<00:04, 47.2MB/s]Downloading data:  15%|█▍        | 37.7M/259M [00:00<00:04, 48.5MB/s]Downloading data:  18%|█▊        | 46.1M/259M [00:01<00:04, 49.8MB/s]Downloading data:  21%|██        | 54.5M/259M [00:01<00:04, 50.8MB/s]Downloading data:  24%|██▍       | 62.9M/259M [00:01<00:03, 50.8MB/s]Downloading data:  27%|██▋       | 71.3M/259M [00:01<00:03, 51.6MB/s]Downloading data:  31%|███       | 79.7M/259M [00:01<00:03, 51.8MB/s]Downloading data:  34%|███▍      | 88.1M/259M [00:01<00:03, 51.9MB/s]Downloading data:  37%|███▋      | 96.5M/259M [00:01<00:03, 51.9MB/s]Downloading data:  40%|████      | 105M/259M [00:02<00:02, 51.6MB/s] Downloading data:  44%|████▎     | 113M/259M [00:02<00:02, 51.9MB/s]Downloading data:  47%|████▋     | 122M/259M [00:02<00:02, 52.0MB/s]Downloading data:  50%|█████     | 130M/259M [00:02<00:02, 52.5MB/s]Downloading data:  53%|█████▎    | 138M/259M [00:02<00:02, 52.5MB/s]Downloading data:  57%|█████▋    | 147M/259M [00:02<00:02, 51.6MB/s]Downloading data:  60%|█████▉    | 155M/259M [00:03<00:01, 52.2MB/s]Downloading data:  63%|██████▎   | 164M/259M [00:03<00:01, 52.8MB/s]Downloading data:  66%|██████▋   | 172M/259M [00:03<00:01, 53.3MB/s]Downloading data:  70%|██████▉   | 180M/259M [00:03<00:01, 53.2MB/s]Downloading data:  73%|███████▎  | 189M/259M [00:03<00:01, 53.1MB/s]Downloading data:  76%|███████▌  | 197M/259M [00:03<00:01, 52.5MB/s]Downloading data:  79%|███████▉  | 206M/259M [00:04<00:01, 52.8MB/s]Downloading data:  82%|████████▏ | 214M/259M [00:04<00:00, 52.6MB/s]Downloading data:  86%|████████▌ | 222M/259M [00:04<00:00, 53.1MB/s]Downloading data:  89%|████████▉ | 231M/259M [00:04<00:00, 53.1MB/s]Downloading data:  92%|█████████▏| 239M/259M [00:04<00:00, 53.4MB/s]Downloading data:  95%|█████████▌| 247M/259M [00:04<00:00, 53.3MB/s]Downloading data:  99%|█████████▊| 256M/259M [00:04<00:00, 55.0MB/s]Downloading data: 100%|██████████| 259M/259M [00:04<00:00, 52.2MB/s]

[2024-02-22 07:32:58,132][INFO] run.py:338  - Downloading data:   0%|          | 0.00/34.7M [00:00<?, ?B/s]Downloading data:  12%|█▏        | 4.19M/34.7M [00:00<00:01, 25.8MB/s]Downloading data:  36%|███▋      | 12.6M/34.7M [00:00<00:00, 41.5MB/s]Downloading data:  60%|██████    | 21.0M/34.7M [00:00<00:00, 43.8MB/s]Downloading data:  85%|████████▍ | 29.4M/34.7M [00:00<00:00, 38.2MB/s]Downloading data: 100%|██████████| 34.7M/34.7M [00:00<00:00, 40.8MB/s]

[2024-02-22 07:32:59,051][INFO] run.py:338  - Downloading data:   0%|          | 0.00/30.0M [00:00<?, ?B/s]Downloading data:  14%|█▍        | 4.19M/30.0M [00:00<00:01, 22.5MB/s]Downloading data:  42%|████▏     | 12.6M/30.0M [00:00<00:00, 39.1MB/s]Downloading data:  70%|██████▉   | 21.0M/30.0M [00:00<00:00, 45.4MB/s]Downloading data:  98%|█████████▊| 29.4M/30.0M [00:00<00:00, 46.9MB/s]Downloading data: 100%|██████████| 30.0M/30.0M [00:00<00:00, 44.6MB/s]

[2024-02-22 07:33:02,005][INFO] run.py:338  - Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]Generating train split:   3%|▎         | 10000/287113 [00:00<00:03, 90034.35 examples/s]Generating train split:  10%|█         | 30000/287113 [00:00<00:02, 100472.34 examples/s]Generating train split:  17%|█▋        | 50000/287113 [00:00<00:02, 99520.66 examples/s] Generating train split:  21%|██        | 60000/287113 [00:00<00:02, 99066.49 examples/s]Generating train split:  24%|██▍       | 70000/287113 [00:00<00:02, 97949.47 examples/s]Generating train split:  28%|██▊       | 80000/287113 [00:00<00:02, 96442.44 examples/s]Generating train split:  31%|███▏      | 90000/287113 [00:00<00:02, 96530.93 examples/s]Generating train split:  37%|███▋      | 105705/287113 [00:01<00:01, 96496.26 examples/s]Generating train split:  40%|████      | 115705/287113 [00:01<00:01, 94581.49 examples/s]Generating train split:  47%|████▋     | 135705/287113 [00:01<00:01, 95235.22 examples/s]Generating train split:  51%|█████     | 145705/287113 [00:01<00:01, 96226.08 examples/s]Generating train split:  54%|█████▍    | 155705/287113 [00:01<00:01, 94242.29 examples/s]Generating train split:  61%|██████    | 175705/287113 [00:01<00:01, 101519.85 examples/s]Generating train split:  65%|██████▍   | 185705/287113 [00:01<00:01, 100244.45 examples/s]Generating train split:  70%|███████   | 201409/287113 [00:02<00:00, 101378.40 examples/s]Generating train split:  77%|███████▋  | 221409/287113 [00:02<00:00, 98628.97 examples/s] Generating train split:  84%|████████▍ | 241409/287113 [00:02<00:00, 97554.22 examples/s]Generating train split:  91%|█████████ | 261409/287113 [00:02<00:00, 94748.49 examples/s]Generating train split:  98%|█████████▊| 281409/287113 [00:02<00:00, 96295.66 examples/s]Generating train split: 100%|██████████| 287113/287113 [00:02<00:00, 97291.79 examples/s]

[2024-02-22 07:33:02,128][INFO] run.py:338  - Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]Generating validation split: 100%|██████████| 13368/13368 [00:00<00:00, 109899.17 examples/s]Generating validation split: 100%|██████████| 13368/13368 [00:00<00:00, 109729.26 examples/s]

[2024-02-22 07:33:02,234][INFO] run.py:338  - Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]Generating test split: 100%|██████████| 11490/11490 [00:00<00:00, 108113.96 examples/s]Generating test split: 100%|██████████| 11490/11490 [00:00<00:00, 107924.86 examples/s]

[2024-02-22 07:33:03,016][INFO] run.py:338  -   0%|          | 0/13368 [00:00<?, ?it/s] 22%|██▏       | 2993/13368 [00:00<00:00, 29922.11it/s] 45%|████▍     | 5986/13368 [00:00<00:00, 29516.58it/s] 67%|██████▋   | 8939/13368 [00:00<00:00, 28881.11it/s] 88%|████████▊ | 11829/13368 [00:00<00:00, 28506.79it/s]100%|██████████| 13368/13368 [00:00<00:00, 28660.75it/s]

[2024-02-22 07:33:03,579][INFO] run.py:338  - 2024-02-22 07:33:03,579 - root - INFO - validation data saved at saved_results/cnn_dailymail_validation.json

[2024-02-22 07:33:03,579][INFO] run.py:338  - 2024-02-22 07:33:03,579 - root - INFO - Do calibration with GPTQ to generate lowp-precision checkpoint.

[2024-02-22 07:33:03,579][INFO] run.py:338  - 2024-02-22 07:33:03,579 - root - INFO - Calibration with GPTQ will take an hour or so. Please wait.

[2024-02-22 07:33:03,579][INFO] run.py:338  - 2024-02-22 07:33:03,579 - root - INFO - Loading model /opt/workdir/code/gptj-99/pytorch-cpu/data/gpt-j-checkpoint...

[2024-02-22 07:33:19,457][INFO] run.py:338  - Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:06<00:13,  6.62s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:12<00:06,  6.44s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:15<00:00,  4.73s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:15<00:00,  5.21s/it]

[2024-02-22 07:33:19,508][INFO] run.py:338  - Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.

[2024-02-22 07:33:19,550][INFO] run.py:338  - Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.

[2024-02-22 07:33:19,553][INFO] run.py:338  - 2024-02-22 07:33:19,552 - root - INFO - model loaded.

[2024-02-22 07:33:19,598][INFO] run.py:338  - Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.

[2024-02-22 07:33:20,498][INFO] run.py:338  - 2024-02-22 07:33:20,498 - intel_extension_for_pytorch.quantization._GPTQ._quantize - INFO - quantizing with GPTQ algorithm

[2024-02-22 07:33:20,500][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - * * Layer to be quantized * *

[2024-02-22 07:33:20,500][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.0.attn.k_proj

[2024-02-22 07:33:20,500][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.0.attn.v_proj

[2024-02-22 07:33:20,500][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.0.attn.q_proj

[2024-02-22 07:33:20,500][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.0.attn.out_proj

[2024-02-22 07:33:20,500][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.0.mlp.fc_in

[2024-02-22 07:33:20,500][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.0.mlp.fc_out

[2024-02-22 07:33:20,500][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.1.attn.k_proj

[2024-02-22 07:33:20,500][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.1.attn.v_proj

[2024-02-22 07:33:20,500][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.1.attn.q_proj

[2024-02-22 07:33:20,500][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.1.attn.out_proj

[2024-02-22 07:33:20,500][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.1.mlp.fc_in

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.1.mlp.fc_out

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.2.attn.k_proj

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.2.attn.v_proj

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.2.attn.q_proj

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.2.attn.out_proj

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.2.mlp.fc_in

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.2.mlp.fc_out

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.3.attn.k_proj

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.3.attn.v_proj

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.3.attn.q_proj

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.3.attn.out_proj

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.3.mlp.fc_in

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.3.mlp.fc_out

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.4.attn.k_proj

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.4.attn.v_proj

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.4.attn.q_proj

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,500 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.4.attn.out_proj

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.4.mlp.fc_in

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.4.mlp.fc_out

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.5.attn.k_proj

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.5.attn.v_proj

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.5.attn.q_proj

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.5.attn.out_proj

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.5.mlp.fc_in

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.5.mlp.fc_out

[2024-02-22 07:33:20,501][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.6.attn.k_proj

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.6.attn.v_proj

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.6.attn.q_proj

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.6.attn.out_proj

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.6.mlp.fc_in

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.6.mlp.fc_out

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.7.attn.k_proj

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.7.attn.v_proj

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.7.attn.q_proj

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.7.attn.out_proj

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.7.mlp.fc_in

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.7.mlp.fc_out

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.8.attn.k_proj

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.8.attn.v_proj

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.8.attn.q_proj

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.8.attn.out_proj

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.8.mlp.fc_in

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.8.mlp.fc_out

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.9.attn.k_proj

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.9.attn.v_proj

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.9.attn.q_proj

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.9.attn.out_proj

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.9.mlp.fc_in

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.9.mlp.fc_out

[2024-02-22 07:33:20,502][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.10.attn.k_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.10.attn.v_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.10.attn.q_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.10.attn.out_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.10.mlp.fc_in

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.10.mlp.fc_out

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.11.attn.k_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.11.attn.v_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.11.attn.q_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.11.attn.out_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.11.mlp.fc_in

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.11.mlp.fc_out

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.12.attn.k_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.12.attn.v_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.12.attn.q_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.12.attn.out_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.12.mlp.fc_in

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.12.mlp.fc_out

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.13.attn.k_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.13.attn.v_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.13.attn.q_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.13.attn.out_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.13.mlp.fc_in

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.13.mlp.fc_out

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.14.attn.k_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.14.attn.v_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.14.attn.q_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.14.attn.out_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.14.mlp.fc_in

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.14.mlp.fc_out

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.15.attn.k_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.15.attn.v_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.15.attn.q_proj

[2024-02-22 07:33:20,503][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.15.attn.out_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.15.mlp.fc_in

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.15.mlp.fc_out

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.16.attn.k_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.16.attn.v_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.16.attn.q_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.16.attn.out_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.16.mlp.fc_in

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.16.mlp.fc_out

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.17.attn.k_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.17.attn.v_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.17.attn.q_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.17.attn.out_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.17.mlp.fc_in

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.17.mlp.fc_out

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.18.attn.k_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.18.attn.v_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.18.attn.q_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.18.attn.out_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.18.mlp.fc_in

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.18.mlp.fc_out

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.19.attn.k_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.19.attn.v_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.19.attn.q_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.19.attn.out_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.19.mlp.fc_in

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.19.mlp.fc_out

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.20.attn.k_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.20.attn.v_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.20.attn.q_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.20.attn.out_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.20.mlp.fc_in

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.20.mlp.fc_out

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.21.attn.k_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.21.attn.v_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.21.attn.q_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.21.attn.out_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.21.mlp.fc_in

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.21.mlp.fc_out

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.22.attn.k_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.22.attn.v_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.22.attn.q_proj

[2024-02-22 07:33:20,504][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.22.attn.out_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.22.mlp.fc_in

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.22.mlp.fc_out

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.23.attn.k_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.23.attn.v_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.23.attn.q_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.23.attn.out_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,502 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.23.mlp.fc_in

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.23.mlp.fc_out

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.24.attn.k_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.24.attn.v_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.24.attn.q_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.24.attn.out_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.24.mlp.fc_in

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.24.mlp.fc_out

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.25.attn.k_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.25.attn.v_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.25.attn.q_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.25.attn.out_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.25.mlp.fc_in

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.25.mlp.fc_out

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.26.attn.k_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.26.attn.v_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.26.attn.q_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.26.attn.out_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.26.mlp.fc_in

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.26.mlp.fc_out

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.27.attn.k_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.27.attn.v_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.27.attn.q_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.27.attn.out_proj

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.27.mlp.fc_in

[2024-02-22 07:33:20,505][INFO] run.py:338  - 2024-02-22 07:33:20,503 - intel_extension_for_pytorch.quantization._GPTQ.gptq.model_utils - INFO - transformer.h.27.mlp.fc_out

[2024-02-22 07:33:20,507][INFO] run.py:338  - 2024-02-22 07:33:20,507 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Begin ====>

[2024-02-22 07:33:20,507][INFO] run.py:338  - 2024-02-22 07:33:20,507 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Collecting calibration inputs...

[2024-02-22 07:33:20,508][INFO] run.py:338  - /opt/conda/lib/python3.9/site-packages/intel_extension_for_pytorch/quantization/_GPTQ/gptq/model_utils.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).

[2024-02-22 07:33:20,508][INFO] run.py:338  -   prev_size = torch.tensor(inp).size()

[2024-02-22 07:33:20,713][INFO] run.py:338  - 2024-02-22 07:33:20,713 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - All calibration data's shape =>

[2024-02-22 07:33:20,713][INFO] run.py:338  - 2024-02-22 07:33:20,713 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Done.

[2024-02-22 07:33:20,713][INFO] run.py:338  - 2024-02-22 07:33:20,713 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - GPTQ quantization prepared.

[2024-02-22 07:33:20,713][INFO] run.py:338  - 2024-02-22 07:33:20,713 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 1 / 28..

[2024-02-22 07:34:14,833][INFO] run.py:338  - 2024-02-22 07:34:14,833 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:34:16,551][INFO] run.py:338  - 2024-02-22 07:34:16,551 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:34:18,274][INFO] run.py:338  - 2024-02-22 07:34:18,274 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:34:19,986][INFO] run.py:338  - 2024-02-22 07:34:19,985 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:34:21,707][INFO] run.py:338  - 2024-02-22 07:34:21,706 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:34:26,795][INFO] run.py:338  - 2024-02-22 07:34:26,795 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 07:34:55,032][INFO] run.py:338  - 2024-02-22 07:34:55,031 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 07:34:55,032][INFO] run.py:338  - 2024-02-22 07:34:55,031 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 2 / 28..

[2024-02-22 07:35:35,958][INFO] run.py:338  - 2024-02-22 07:35:35,957 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:35:37,653][INFO] run.py:338  - 2024-02-22 07:35:37,652 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:35:39,344][INFO] run.py:338  - 2024-02-22 07:35:39,344 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:35:41,041][INFO] run.py:338  - 2024-02-22 07:35:41,041 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:35:42,732][INFO] run.py:338  - 2024-02-22 07:35:42,732 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:35:47,818][INFO] run.py:338  - 2024-02-22 07:35:47,817 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 07:36:15,889][INFO] run.py:338  - 2024-02-22 07:36:15,889 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 07:36:15,890][INFO] run.py:338  - 2024-02-22 07:36:15,889 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 3 / 28..

[2024-02-22 07:36:56,183][INFO] run.py:338  - 2024-02-22 07:36:56,182 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:36:57,888][INFO] run.py:338  - 2024-02-22 07:36:57,888 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:36:59,548][INFO] run.py:338  - 2024-02-22 07:36:59,548 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:37:01,251][INFO] run.py:338  - 2024-02-22 07:37:01,250 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:37:02,959][INFO] run.py:338  - 2024-02-22 07:37:02,959 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:37:07,946][INFO] run.py:338  - 2024-02-22 07:37:07,946 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 07:37:35,903][INFO] run.py:338  - 2024-02-22 07:37:35,903 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 07:37:35,904][INFO] run.py:338  - 2024-02-22 07:37:35,903 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 4 / 28..

[2024-02-22 07:38:16,783][INFO] run.py:338  - 2024-02-22 07:38:16,782 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:38:18,491][INFO] run.py:338  - 2024-02-22 07:38:18,491 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:38:20,201][INFO] run.py:338  - 2024-02-22 07:38:20,201 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:38:21,914][INFO] run.py:338  - 2024-02-22 07:38:21,913 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:38:23,630][INFO] run.py:338  - 2024-02-22 07:38:23,630 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:38:28,686][INFO] run.py:338  - 2024-02-22 07:38:28,686 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 07:38:56,861][INFO] run.py:338  - 2024-02-22 07:38:56,860 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 07:38:56,862][INFO] run.py:338  - 2024-02-22 07:38:56,861 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 5 / 28..

[2024-02-22 07:39:36,317][INFO] run.py:338  - 2024-02-22 07:39:36,316 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:39:37,993][INFO] run.py:338  - 2024-02-22 07:39:37,992 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:39:39,670][INFO] run.py:338  - 2024-02-22 07:39:39,669 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:39:41,333][INFO] run.py:338  - 2024-02-22 07:39:41,333 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:39:42,985][INFO] run.py:338  - 2024-02-22 07:39:42,984 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:39:47,913][INFO] run.py:338  - 2024-02-22 07:39:47,912 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 07:40:15,550][INFO] run.py:338  - 2024-02-22 07:40:15,549 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 07:40:15,550][INFO] run.py:338  - 2024-02-22 07:40:15,549 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 6 / 28..

[2024-02-22 07:40:55,520][INFO] run.py:338  - 2024-02-22 07:40:55,519 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:40:57,212][INFO] run.py:338  - 2024-02-22 07:40:57,212 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:40:58,897][INFO] run.py:338  - 2024-02-22 07:40:58,897 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:41:00,560][INFO] run.py:338  - 2024-02-22 07:41:00,558 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:41:02,236][INFO] run.py:338  - 2024-02-22 07:41:02,236 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:41:07,305][INFO] run.py:338  - 2024-02-22 07:41:07,304 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 07:41:35,235][INFO] run.py:338  - 2024-02-22 07:41:35,234 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 07:41:35,236][INFO] run.py:338  - 2024-02-22 07:41:35,234 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 7 / 28..

[2024-02-22 07:42:14,163][INFO] run.py:338  - 2024-02-22 07:42:14,162 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:42:15,851][INFO] run.py:338  - 2024-02-22 07:42:15,850 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:42:17,518][INFO] run.py:338  - 2024-02-22 07:42:17,517 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:42:19,165][INFO] run.py:338  - 2024-02-22 07:42:19,165 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:42:20,839][INFO] run.py:338  - 2024-02-22 07:42:20,839 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:42:25,812][INFO] run.py:338  - 2024-02-22 07:42:25,811 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 07:42:53,259][INFO] run.py:338  - 2024-02-22 07:42:53,257 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 07:42:53,259][INFO] run.py:338  - 2024-02-22 07:42:53,257 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 8 / 28..

[2024-02-22 07:43:33,421][INFO] run.py:338  - 2024-02-22 07:43:33,420 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:43:35,105][INFO] run.py:338  - 2024-02-22 07:43:35,105 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:43:36,776][INFO] run.py:338  - 2024-02-22 07:43:36,775 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:43:38,470][INFO] run.py:338  - 2024-02-22 07:43:38,469 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:43:40,188][INFO] run.py:338  - 2024-02-22 07:43:40,187 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:43:45,174][INFO] run.py:338  - 2024-02-22 07:43:45,173 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 07:44:12,922][INFO] run.py:338  - 2024-02-22 07:44:12,921 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 07:44:12,922][INFO] run.py:338  - 2024-02-22 07:44:12,921 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 9 / 28..

[2024-02-22 07:44:52,590][INFO] run.py:338  - 2024-02-22 07:44:52,589 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:44:54,280][INFO] run.py:338  - 2024-02-22 07:44:54,279 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:44:55,983][INFO] run.py:338  - 2024-02-22 07:44:55,983 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:44:57,705][INFO] run.py:338  - 2024-02-22 07:44:57,704 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:44:59,411][INFO] run.py:338  - 2024-02-22 07:44:59,410 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:45:04,418][INFO] run.py:338  - 2024-02-22 07:45:04,417 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 07:45:32,177][INFO] run.py:338  - 2024-02-22 07:45:32,176 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 07:45:32,177][INFO] run.py:338  - 2024-02-22 07:45:32,176 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 10 / 28..

[2024-02-22 07:46:12,548][INFO] run.py:338  - 2024-02-22 07:46:12,546 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:46:14,239][INFO] run.py:338  - 2024-02-22 07:46:14,238 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:46:15,943][INFO] run.py:338  - 2024-02-22 07:46:15,942 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:46:17,662][INFO] run.py:338  - 2024-02-22 07:46:17,662 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:46:19,368][INFO] run.py:338  - 2024-02-22 07:46:19,367 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:46:24,380][INFO] run.py:338  - 2024-02-22 07:46:24,380 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 07:46:52,395][INFO] run.py:338  - 2024-02-22 07:46:52,394 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 07:46:52,395][INFO] run.py:338  - 2024-02-22 07:46:52,394 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 11 / 28..

[2024-02-22 07:47:31,908][INFO] run.py:338  - 2024-02-22 07:47:31,907 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:47:33,588][INFO] run.py:338  - 2024-02-22 07:47:33,588 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:47:35,292][INFO] run.py:338  - 2024-02-22 07:47:35,292 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:47:36,990][INFO] run.py:338  - 2024-02-22 07:47:36,989 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:47:38,702][INFO] run.py:338  - 2024-02-22 07:47:38,701 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:47:43,727][INFO] run.py:338  - 2024-02-22 07:47:43,727 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 07:48:11,461][INFO] run.py:338  - 2024-02-22 07:48:11,460 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 07:48:11,461][INFO] run.py:338  - 2024-02-22 07:48:11,460 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 12 / 28..

[2024-02-22 07:48:51,358][INFO] run.py:338  - 2024-02-22 07:48:51,357 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:48:53,068][INFO] run.py:338  - 2024-02-22 07:48:53,068 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:48:54,760][INFO] run.py:338  - 2024-02-22 07:48:54,759 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:48:56,471][INFO] run.py:338  - 2024-02-22 07:48:56,470 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:48:58,172][INFO] run.py:338  - 2024-02-22 07:48:58,172 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:49:03,176][INFO] run.py:338  - 2024-02-22 07:49:03,176 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 07:49:30,984][INFO] run.py:338  - 2024-02-22 07:49:30,983 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 07:49:30,984][INFO] run.py:338  - 2024-02-22 07:49:30,983 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 13 / 28..

[2024-02-22 07:50:10,375][INFO] run.py:338  - 2024-02-22 07:50:10,374 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:50:12,090][INFO] run.py:338  - 2024-02-22 07:50:12,089 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:50:13,799][INFO] run.py:338  - 2024-02-22 07:50:13,799 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:50:15,507][INFO] run.py:338  - 2024-02-22 07:50:15,506 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:50:17,222][INFO] run.py:338  - 2024-02-22 07:50:17,221 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:50:22,247][INFO] run.py:338  - 2024-02-22 07:50:22,247 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 07:50:50,174][INFO] run.py:338  - 2024-02-22 07:50:50,174 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 07:50:50,175][INFO] run.py:338  - 2024-02-22 07:50:50,174 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 14 / 28..

[2024-02-22 07:51:29,766][INFO] run.py:338  - 2024-02-22 07:51:29,765 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:51:31,478][INFO] run.py:338  - 2024-02-22 07:51:31,478 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:51:33,181][INFO] run.py:338  - 2024-02-22 07:51:33,180 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:51:34,901][INFO] run.py:338  - 2024-02-22 07:51:34,900 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:51:36,604][INFO] run.py:338  - 2024-02-22 07:51:36,604 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:51:41,586][INFO] run.py:338  - 2024-02-22 07:51:41,585 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 07:52:09,605][INFO] run.py:338  - 2024-02-22 07:52:09,604 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 07:52:09,605][INFO] run.py:338  - 2024-02-22 07:52:09,604 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 15 / 28..

[2024-02-22 07:52:49,135][INFO] run.py:338  - 2024-02-22 07:52:49,134 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:52:50,850][INFO] run.py:338  - 2024-02-22 07:52:50,849 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:52:52,529][INFO] run.py:338  - 2024-02-22 07:52:52,529 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:52:54,208][INFO] run.py:338  - 2024-02-22 07:52:54,208 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:52:55,924][INFO] run.py:338  - 2024-02-22 07:52:55,924 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:53:00,891][INFO] run.py:338  - 2024-02-22 07:53:00,890 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 07:53:28,493][INFO] run.py:338  - 2024-02-22 07:53:28,492 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 07:53:28,493][INFO] run.py:338  - 2024-02-22 07:53:28,492 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 16 / 28..

[2024-02-22 07:54:08,405][INFO] run.py:338  - 2024-02-22 07:54:08,404 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:54:10,107][INFO] run.py:338  - 2024-02-22 07:54:10,106 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:54:11,836][INFO] run.py:338  - 2024-02-22 07:54:11,836 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:54:13,543][INFO] run.py:338  - 2024-02-22 07:54:13,543 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:54:15,257][INFO] run.py:338  - 2024-02-22 07:54:15,256 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:54:20,277][INFO] run.py:338  - 2024-02-22 07:54:20,277 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 07:54:48,266][INFO] run.py:338  - 2024-02-22 07:54:48,265 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 07:54:48,267][INFO] run.py:338  - 2024-02-22 07:54:48,265 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 17 / 28..

[2024-02-22 07:55:28,005][INFO] run.py:338  - 2024-02-22 07:55:28,005 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:55:29,710][INFO] run.py:338  - 2024-02-22 07:55:29,710 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:55:31,409][INFO] run.py:338  - 2024-02-22 07:55:31,408 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:55:33,108][INFO] run.py:338  - 2024-02-22 07:55:33,108 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:55:34,795][INFO] run.py:338  - 2024-02-22 07:55:34,795 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:55:39,786][INFO] run.py:338  - 2024-02-22 07:55:39,786 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 07:56:07,521][INFO] run.py:338  - 2024-02-22 07:56:07,520 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 07:56:07,521][INFO] run.py:338  - 2024-02-22 07:56:07,520 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 18 / 28..

[2024-02-22 07:56:47,355][INFO] run.py:338  - 2024-02-22 07:56:47,354 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:56:49,060][INFO] run.py:338  - 2024-02-22 07:56:49,059 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:56:50,748][INFO] run.py:338  - 2024-02-22 07:56:50,747 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:56:52,444][INFO] run.py:338  - 2024-02-22 07:56:52,443 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:56:54,141][INFO] run.py:338  - 2024-02-22 07:56:54,140 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:56:59,155][INFO] run.py:338  - 2024-02-22 07:56:59,154 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 07:57:27,087][INFO] run.py:338  - 2024-02-22 07:57:27,087 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 07:57:27,088][INFO] run.py:338  - 2024-02-22 07:57:27,087 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 19 / 28..

[2024-02-22 07:58:06,750][INFO] run.py:338  - 2024-02-22 07:58:06,749 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:58:08,456][INFO] run.py:338  - 2024-02-22 07:58:08,455 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:58:10,160][INFO] run.py:338  - 2024-02-22 07:58:10,159 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:58:11,868][INFO] run.py:338  - 2024-02-22 07:58:11,868 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:58:13,564][INFO] run.py:338  - 2024-02-22 07:58:13,563 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:58:18,602][INFO] run.py:338  - 2024-02-22 07:58:18,601 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 07:58:46,416][INFO] run.py:338  - 2024-02-22 07:58:46,415 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 07:58:46,416][INFO] run.py:338  - 2024-02-22 07:58:46,415 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 20 / 28..

[2024-02-22 07:59:26,440][INFO] run.py:338  - 2024-02-22 07:59:26,439 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 07:59:28,131][INFO] run.py:338  - 2024-02-22 07:59:28,130 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 07:59:29,826][INFO] run.py:338  - 2024-02-22 07:59:29,825 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 07:59:31,507][INFO] run.py:338  - 2024-02-22 07:59:31,506 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 07:59:33,188][INFO] run.py:338  - 2024-02-22 07:59:33,188 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 07:59:38,198][INFO] run.py:338  - 2024-02-22 07:59:38,197 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 08:00:06,010][INFO] run.py:338  - 2024-02-22 08:00:06,008 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 08:00:06,010][INFO] run.py:338  - 2024-02-22 08:00:06,008 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 21 / 28..

[2024-02-22 08:00:45,795][INFO] run.py:338  - 2024-02-22 08:00:45,794 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 08:00:47,497][INFO] run.py:338  - 2024-02-22 08:00:47,496 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 08:00:49,185][INFO] run.py:338  - 2024-02-22 08:00:49,184 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 08:00:50,877][INFO] run.py:338  - 2024-02-22 08:00:50,877 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 08:00:52,567][INFO] run.py:338  - 2024-02-22 08:00:52,567 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 08:00:57,535][INFO] run.py:338  - 2024-02-22 08:00:57,535 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 08:01:25,269][INFO] run.py:338  - 2024-02-22 08:01:25,268 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 08:01:25,270][INFO] run.py:338  - 2024-02-22 08:01:25,268 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 22 / 28..

[2024-02-22 08:02:04,961][INFO] run.py:338  - 2024-02-22 08:02:04,961 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 08:02:06,647][INFO] run.py:338  - 2024-02-22 08:02:06,646 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 08:02:08,372][INFO] run.py:338  - 2024-02-22 08:02:08,371 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 08:02:10,066][INFO] run.py:338  - 2024-02-22 08:02:10,065 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 08:02:11,773][INFO] run.py:338  - 2024-02-22 08:02:11,772 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 08:02:16,783][INFO] run.py:338  - 2024-02-22 08:02:16,782 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 08:02:44,652][INFO] run.py:338  - 2024-02-22 08:02:44,652 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 08:02:44,653][INFO] run.py:338  - 2024-02-22 08:02:44,652 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 23 / 28..

[2024-02-22 08:03:24,431][INFO] run.py:338  - 2024-02-22 08:03:24,430 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 08:03:26,119][INFO] run.py:338  - 2024-02-22 08:03:26,118 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 08:03:27,842][INFO] run.py:338  - 2024-02-22 08:03:27,841 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 08:03:29,536][INFO] run.py:338  - 2024-02-22 08:03:29,535 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 08:03:31,232][INFO] run.py:338  - 2024-02-22 08:03:31,231 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 08:03:36,228][INFO] run.py:338  - 2024-02-22 08:03:36,227 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 08:04:03,735][INFO] run.py:338  - 2024-02-22 08:04:03,734 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 08:04:03,735][INFO] run.py:338  - 2024-02-22 08:04:03,734 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 24 / 28..

[2024-02-22 08:04:43,768][INFO] run.py:338  - 2024-02-22 08:04:43,767 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 08:04:45,461][INFO] run.py:338  - 2024-02-22 08:04:45,460 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 08:04:47,175][INFO] run.py:338  - 2024-02-22 08:04:47,174 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 08:04:48,883][INFO] run.py:338  - 2024-02-22 08:04:48,882 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 08:04:50,589][INFO] run.py:338  - 2024-02-22 08:04:50,589 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 08:04:55,603][INFO] run.py:338  - 2024-02-22 08:04:55,603 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 08:05:23,516][INFO] run.py:338  - 2024-02-22 08:05:23,516 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 08:05:23,517][INFO] run.py:338  - 2024-02-22 08:05:23,516 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 25 / 28..

[2024-02-22 08:06:03,447][INFO] run.py:338  - 2024-02-22 08:06:03,446 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 08:06:05,156][INFO] run.py:338  - 2024-02-22 08:06:05,156 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 08:06:06,844][INFO] run.py:338  - 2024-02-22 08:06:06,844 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 08:06:08,553][INFO] run.py:338  - 2024-02-22 08:06:08,552 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 08:06:10,256][INFO] run.py:338  - 2024-02-22 08:06:10,255 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 08:06:15,258][INFO] run.py:338  - 2024-02-22 08:06:15,257 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 08:06:42,860][INFO] run.py:338  - 2024-02-22 08:06:42,859 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 08:06:42,861][INFO] run.py:338  - 2024-02-22 08:06:42,859 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 26 / 28..

[2024-02-22 08:07:23,425][INFO] run.py:338  - 2024-02-22 08:07:23,424 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 08:07:25,115][INFO] run.py:338  - 2024-02-22 08:07:25,115 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 08:07:26,810][INFO] run.py:338  - 2024-02-22 08:07:26,810 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 08:07:28,486][INFO] run.py:338  - 2024-02-22 08:07:28,485 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 08:07:30,182][INFO] run.py:338  - 2024-02-22 08:07:30,181 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 08:07:35,224][INFO] run.py:338  - 2024-02-22 08:07:35,224 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 08:08:03,002][INFO] run.py:338  - 2024-02-22 08:08:03,002 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 08:08:03,003][INFO] run.py:338  - 2024-02-22 08:08:03,002 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 27 / 28..

[2024-02-22 08:08:42,784][INFO] run.py:338  - 2024-02-22 08:08:42,783 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 08:08:44,502][INFO] run.py:338  - 2024-02-22 08:08:44,501 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 08:08:46,195][INFO] run.py:338  - 2024-02-22 08:08:46,194 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 08:08:47,885][INFO] run.py:338  - 2024-02-22 08:08:47,884 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 08:08:49,566][INFO] run.py:338  - 2024-02-22 08:08:49,565 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 08:08:54,563][INFO] run.py:338  - 2024-02-22 08:08:54,562 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 08:09:22,444][INFO] run.py:338  - 2024-02-22 08:09:22,443 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 08:09:22,444][INFO] run.py:338  - 2024-02-22 08:09:22,443 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer 28 / 28..

[2024-02-22 08:10:02,354][INFO] run.py:338  - 2024-02-22 08:10:02,353 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.k_proj

[2024-02-22 08:10:04,071][INFO] run.py:338  - 2024-02-22 08:10:04,070 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.v_proj

[2024-02-22 08:10:05,760][INFO] run.py:338  - 2024-02-22 08:10:05,759 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.q_proj

[2024-02-22 08:10:07,442][INFO] run.py:338  - 2024-02-22 08:10:07,441 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer attn.out_proj

[2024-02-22 08:10:09,139][INFO] run.py:338  - 2024-02-22 08:10:09,138 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_in

[2024-02-22 08:10:14,171][INFO] run.py:338  - 2024-02-22 08:10:14,170 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantizing layer mlp.fc_out

[2024-02-22 08:10:42,330][INFO] run.py:338  - 2024-02-22 08:10:42,329 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - ------------------------------

[2024-02-22 08:10:42,330][INFO] run.py:338  - 2024-02-22 08:10:42,329 - intel_extension_for_pytorch.quantization._GPTQ.gptq.gptq - INFO - Quantization done

[2024-02-22 08:10:43,270][INFO] run.py:338  - 2024-02-22 08:10:43,269 - intel_extension_for_pytorch.quantization._GPTQ._gptq_utils - INFO - GPTQ quantizing done.

[2024-02-22 08:15:03,789][INFO] run.py:338  - 2024-02-22 08:15:03,789 - root - INFO - Low-precision checkpoint generated and saved to saved_results/gptq_checkpoint_g-1.pt.

[2024-02-22 08:15:03,846][INFO] run.py:338  - 2024-02-22 08:15:03,845 - root - INFO - Calibration finished. Low-precision checkpoint generated at saved_results.

[2024-02-22 08:15:04,526][INFO] run.py:338  - + retVal=0

[2024-02-22 08:15:04,526][INFO] run.py:338  - + '[' 0 -ne 0 ']'

[2024-02-22 08:15:04,526][INFO] run.py:338  - + export LD_PRELOAD=/opt/conda/lib/libstdc++.so.6

[2024-02-22 08:15:04,526][INFO] run.py:338  - + LD_PRELOAD=/opt/conda/lib/libstdc++.so.6

[2024-02-22 08:15:04,526][INFO] run.py:338  - + export KMP_BLOCKTIME=INF

[2024-02-22 08:15:04,526][INFO] run.py:338  - + KMP_BLOCKTIME=INF

[2024-02-22 08:15:04,526][INFO] run.py:338  - + export KMP_TPAUSE=0

[2024-02-22 08:15:04,526][INFO] run.py:338  - + KMP_TPAUSE=0

[2024-02-22 08:15:04,526][INFO] run.py:338  - + export KMP_SETTINGS=1

[2024-02-22 08:15:04,526][INFO] run.py:338  - + KMP_SETTINGS=1

[2024-02-22 08:15:04,526][INFO] run.py:338  - + export KMP_AFFINITY=granularity=fine,compact,1,0

[2024-02-22 08:15:04,526][INFO] run.py:338  - + KMP_AFFINITY=granularity=fine,compact,1,0

[2024-02-22 08:15:04,526][INFO] run.py:338  - + export KMP_FORKJOIN_BARRIER_PATTERN=dist,dist

[2024-02-22 08:15:04,526][INFO] run.py:338  - + KMP_FORKJOIN_BARRIER_PATTERN=dist,dist

[2024-02-22 08:15:04,526][INFO] run.py:338  - + export KMP_PLAIN_BARRIER_PATTERN=dist,dist

[2024-02-22 08:15:04,526][INFO] run.py:338  - + KMP_PLAIN_BARRIER_PATTERN=dist,dist

[2024-02-22 08:15:04,526][INFO] run.py:338  - + export KMP_REDUCTION_BARRIER_PATTERN=dist,dist

[2024-02-22 08:15:04,526][INFO] run.py:338  - + KMP_REDUCTION_BARRIER_PATTERN=dist,dist

[2024-02-22 08:15:04,526][INFO] run.py:338  - + export LD_PRELOAD=/opt/conda/lib/libstdc++.so.6:/opt/conda/lib/libiomp5.so

[2024-02-22 08:15:04,526][INFO] run.py:338  - + LD_PRELOAD=/opt/conda/lib/libstdc++.so.6:/opt/conda/lib/libiomp5.so

[2024-02-22 08:15:04,526][INFO] run.py:338  - + export LD_PRELOAD=/opt/conda/lib/libstdc++.so.6:/opt/conda/lib/libiomp5.so:/opt/conda/lib/libtcmalloc.so

[2024-02-22 08:15:04,526][INFO] run.py:338  - + LD_PRELOAD=/opt/conda/lib/libstdc++.so.6:/opt/conda/lib/libiomp5.so:/opt/conda/lib/libtcmalloc.so

[2024-02-22 08:15:04,526][INFO] run.py:338  - + python ./run_int4_gpt-j_on_cnndailymail.py --dataset-path ./saved_results/cnn_dailymail_validation.json --model /opt/workdir/code/gptj-99/pytorch-cpu/data/gpt-j-checkpoint --output-dir saved_results --low-precision-checkpoint saved_results/gptq_checkpoint_g-1.pt

[2024-02-22 08:15:04,989][INFO] run.py:338  - 

[2024-02-22 08:15:04,990][INFO] run.py:338  - User settings:

[2024-02-22 08:15:04,990][INFO] run.py:338  - 

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_AFFINITY=granularity=fine,compact,1,0

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_BLOCKTIME=INF

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_FORKJOIN_BARRIER_PATTERN=dist,dist

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_PLAIN_BARRIER_PATTERN=dist,dist

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_REDUCTION_BARRIER_PATTERN=dist,dist

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_SETTINGS=1

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_TPAUSE=0

[2024-02-22 08:15:04,990][INFO] run.py:338  - 

[2024-02-22 08:15:04,990][INFO] run.py:338  - Effective settings:

[2024-02-22 08:15:04,990][INFO] run.py:338  - 

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_ABORT_DELAY=0

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_ADAPTIVE_LOCK_PROPS='1,1024'

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_ALIGN_ALLOC=64

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_ALL_THREADPRIVATE=1024

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_ATOMIC_MODE=2

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_BLOCKTIME=2147483646

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_CPUINFO_FILE: value is not defined

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_DETERMINISTIC_REDUCTION=false

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_DEVICE_THREAD_LIMIT=2147483647

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_DISP_HAND_THREAD=false

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_DISP_NUM_BUFFERS=7

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_DUPLICATE_LIB_OK=false

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_ENABLE_TASK_THROTTLING=true

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_FORCE_MONOTONIC_DYNAMIC_SCHEDULE=false

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_FORCE_REDUCTION: value is not defined

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_FOREIGN_THREADS_THREADPRIVATE=true

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_FORKJOIN_BARRIER='2,2'

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_FORKJOIN_BARRIER_PATTERN='dist,dist'

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_FORKJOIN_FRAMES=true

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_FORKJOIN_FRAMES_MODE=3

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_GTID_MODE=3

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_HANDLE_SIGNALS=false

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_HIDDEN_HELPER_AFFINITY='noverbose,warnings,granularity=core,none'

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_HOT_TEAMS_MAX_LEVEL=1

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_HOT_TEAMS_MODE=0

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_INIT_AT_FORK=true

[2024-02-22 08:15:04,990][INFO] run.py:338  -    KMP_ITT_PREPARE_DELAY=0

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_LIBRARY=throughput

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_LOCK_KIND=tas

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_MALLOC_POOL_INCR=1M

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_MWAIT_HINTS=0

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_NESTING_MODE=0

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_NUM_LOCKS_IN_BLOCK=1

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_PLAIN_BARRIER='2,2'

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_PLAIN_BARRIER_PATTERN='dist,dist'

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_REDUCTION_BARRIER='1,1'

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_REDUCTION_BARRIER_PATTERN='dist,dist'

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_SCHEDULE='static,balanced;guided,iterative'

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_SETTINGS=true

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_SPIN_BACKOFF_PARAMS='4096,100'

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_STACKOFFSET=64

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_STACKPAD=0

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_STACKSIZE=8M

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_STORAGE_MAP=false

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_TASKING=2

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_TASKLOOP_MIN_TASKS=0

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_TASK_STEALING_CONSTRAINT=1

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_TEAMS_PROC_BIND=spread

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_TEAMS_THREAD_LIMIT=256

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_TOPOLOGY_METHOD=all

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_TPAUSE=0

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_USER_LEVEL_MWAIT=false

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_USE_YIELD=1

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_VERSION=false

[2024-02-22 08:15:04,991][INFO] run.py:338  -    KMP_WARNINGS=true

[2024-02-22 08:15:04,991][INFO] run.py:338  -    LIBOMP_NUM_HIDDEN_HELPER_THREADS=0

[2024-02-22 08:15:04,991][INFO] run.py:338  -    LIBOMP_USE_HIDDEN_HELPER_TASK=false

[2024-02-22 08:15:04,991][INFO] run.py:338  -    OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'

[2024-02-22 08:15:04,991][INFO] run.py:338  -    OMP_ALLOCATOR=omp_default_mem_alloc

[2024-02-22 08:15:04,991][INFO] run.py:338  -    OMP_CANCELLATION=false

[2024-02-22 08:15:04,991][INFO] run.py:338  -    OMP_DEBUG=disabled

[2024-02-22 08:15:04,991][INFO] run.py:338  -    OMP_DEFAULT_DEVICE=0

[2024-02-22 08:15:04,991][INFO] run.py:338  -    OMP_DISPLAY_AFFINITY=false

[2024-02-22 08:15:04,991][INFO] run.py:338  -    OMP_DISPLAY_ENV=false

[2024-02-22 08:15:04,991][INFO] run.py:338  -    OMP_DYNAMIC=false

[2024-02-22 08:15:04,991][INFO] run.py:338  -    OMP_MAX_ACTIVE_LEVELS=1

[2024-02-22 08:15:04,991][INFO] run.py:338  -    OMP_MAX_TASK_PRIORITY=0

[2024-02-22 08:15:04,991][INFO] run.py:338  -    OMP_NESTED: deprecated; max-active-levels-var=1

[2024-02-22 08:15:04,991][INFO] run.py:338  -    OMP_NUM_TEAMS=0

[2024-02-22 08:15:04,992][INFO] run.py:338  -    OMP_NUM_THREADS: value is not defined

[2024-02-22 08:15:04,992][INFO] run.py:338  -    OMP_PLACES='threads'

[2024-02-22 08:15:04,992][INFO] run.py:338  -    OMP_PROC_BIND='intel'

[2024-02-22 08:15:04,992][INFO] run.py:338  -    OMP_SCHEDULE='static'

[2024-02-22 08:15:04,992][INFO] run.py:338  -    OMP_STACKSIZE=8M

[2024-02-22 08:15:04,992][INFO] run.py:338  -    OMP_TARGET_OFFLOAD=DEFAULT

[2024-02-22 08:15:04,992][INFO] run.py:338  -    OMP_TEAMS_THREAD_LIMIT=0

[2024-02-22 08:15:04,992][INFO] run.py:338  -    OMP_THREAD_LIMIT=2147483647

[2024-02-22 08:15:04,992][INFO] run.py:338  -    OMP_TOOL=enabled

[2024-02-22 08:15:04,992][INFO] run.py:338  -    OMP_TOOL_LIBRARIES: value is not defined

[2024-02-22 08:15:04,992][INFO] run.py:338  -    OMP_TOOL_VERBOSE_INIT: value is not defined

[2024-02-22 08:15:04,992][INFO] run.py:338  -    OMP_WAIT_POLICY=PASSIVE

[2024-02-22 08:15:04,992][INFO] run.py:338  -    KMP_AFFINITY='noverbose,warnings,respect,noreset,granularity=thread,compact,1,0'

[2024-02-22 08:15:04,992][INFO] run.py:338  - 

[2024-02-22 08:15:05,434][INFO] run.py:338  - /opt/conda/lib/python3.9/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.

[2024-02-22 08:15:05,434][INFO] run.py:338  -   _torch_pytree._register_pytree_node(

[2024-02-22 08:15:06,478][INFO] run.py:338  - /opt/conda/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.

[2024-02-22 08:15:06,478][INFO] run.py:338  -   _torch_pytree._register_pytree_node(

[2024-02-22 08:15:06,520][INFO] run.py:338  - 

[2024-02-22 08:15:06,520][INFO] run.py:338  - User settings:

[2024-02-22 08:15:06,520][INFO] run.py:338  - 

[2024-02-22 08:15:06,520][INFO] run.py:338  -    KMP_AFFINITY=granularity=fine,compact,1,0

[2024-02-22 08:15:06,520][INFO] run.py:338  -    KMP_BLOCKTIME=INF

[2024-02-22 08:15:06,520][INFO] run.py:338  -    KMP_FORKJOIN_BARRIER_PATTERN=dist,dist

[2024-02-22 08:15:06,520][INFO] run.py:338  -    KMP_PLAIN_BARRIER_PATTERN=dist,dist

[2024-02-22 08:15:06,520][INFO] run.py:338  -    KMP_REDUCTION_BARRIER_PATTERN=dist,dist

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_SETTINGS=1

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_TPAUSE=0

[2024-02-22 08:15:06,521][INFO] run.py:338  - 

[2024-02-22 08:15:06,521][INFO] run.py:338  - Effective settings:

[2024-02-22 08:15:06,521][INFO] run.py:338  - 

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_ABORT_DELAY=0

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_ADAPTIVE_LOCK_PROPS='1,1024'

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_ALIGN_ALLOC=64

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_ALL_THREADPRIVATE=1024

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_ATOMIC_MODE=2

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_BLOCKTIME=2147483646

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_CPUINFO_FILE: value is not defined

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_DETERMINISTIC_REDUCTION=false

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_DEVICE_THREAD_LIMIT=2147483647

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_DISP_HAND_THREAD=false

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_DISP_NUM_BUFFERS=7

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_DUPLICATE_LIB_OK=false

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_ENABLE_TASK_THROTTLING=true

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_FORCE_MONOTONIC_DYNAMIC_SCHEDULE=false

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_FORCE_REDUCTION: value is not defined

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_FOREIGN_THREADS_THREADPRIVATE=true

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_FORKJOIN_BARRIER='2,2'

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_FORKJOIN_BARRIER_PATTERN='dist,dist'

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_FORKJOIN_FRAMES=true

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_FORKJOIN_FRAMES_MODE=3

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_GTID_MODE=3

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_HANDLE_SIGNALS=false

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_HIDDEN_HELPER_AFFINITY='noverbose,warnings,granularity=core,none'

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_HOT_TEAMS_MAX_LEVEL=1

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_HOT_TEAMS_MODE=0

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_INIT_AT_FORK=true

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_ITT_PREPARE_DELAY=0

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_LIBRARY=throughput

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_LOCK_KIND=tas

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_MALLOC_POOL_INCR=1M

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_MWAIT_HINTS=0

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_NESTING_MODE=0

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_NUM_LOCKS_IN_BLOCK=1

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_PLAIN_BARRIER='2,2'

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_PLAIN_BARRIER_PATTERN='dist,dist'

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_REDUCTION_BARRIER='1,1'

[2024-02-22 08:15:06,521][INFO] run.py:338  -    KMP_REDUCTION_BARRIER_PATTERN='dist,dist'

[2024-02-22 08:15:06,522][INFO] run.py:338  -    KMP_SCHEDULE='static,balanced;guided,iterative'

[2024-02-22 08:15:06,522][INFO] run.py:338  -    KMP_SETTINGS=true

[2024-02-22 08:15:06,522][INFO] run.py:338  -    KMP_SPIN_BACKOFF_PARAMS='4096,100'

[2024-02-22 08:15:06,522][INFO] run.py:338  -    KMP_STACKOFFSET=64

[2024-02-22 08:15:06,522][INFO] run.py:338  -    KMP_STACKPAD=0

[2024-02-22 08:15:06,522][INFO] run.py:338  -    KMP_STACKSIZE=8M

[2024-02-22 08:15:06,522][INFO] run.py:338  -    KMP_STORAGE_MAP=false

[2024-02-22 08:15:06,522][INFO] run.py:338  -    KMP_TASKING=2

[2024-02-22 08:15:06,522][INFO] run.py:338  -    KMP_TASKLOOP_MIN_TASKS=0

[2024-02-22 08:15:06,522][INFO] run.py:338  -    KMP_TASK_STEALING_CONSTRAINT=1

[2024-02-22 08:15:06,522][INFO] run.py:338  -    KMP_TEAMS_PROC_BIND=spread

[2024-02-22 08:15:06,522][INFO] run.py:338  -    KMP_TEAMS_THREAD_LIMIT=256

[2024-02-22 08:15:06,522][INFO] run.py:338  -    KMP_TOPOLOGY_METHOD=all

[2024-02-22 08:15:06,522][INFO] run.py:338  -    KMP_TPAUSE=0

[2024-02-22 08:15:06,522][INFO] run.py:338  -    KMP_USER_LEVEL_MWAIT=false

[2024-02-22 08:15:06,522][INFO] run.py:338  -    KMP_USE_YIELD=1

[2024-02-22 08:15:06,522][INFO] run.py:338  -    KMP_VERSION=false

[2024-02-22 08:15:06,522][INFO] run.py:338  -    KMP_WARNINGS=true

[2024-02-22 08:15:06,522][INFO] run.py:338  -    LIBOMP_NUM_HIDDEN_HELPER_THREADS=0

[2024-02-22 08:15:06,522][INFO] run.py:338  -    LIBOMP_USE_HIDDEN_HELPER_TASK=false

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_ALLOCATOR=omp_default_mem_alloc

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_CANCELLATION=false

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_DEBUG=disabled

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_DEFAULT_DEVICE=0

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_DISPLAY_AFFINITY=false

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_DISPLAY_ENV=false

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_DYNAMIC=false

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_MAX_ACTIVE_LEVELS=1

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_MAX_TASK_PRIORITY=0

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_NESTED: deprecated; max-active-levels-var=1

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_NUM_TEAMS=0

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_NUM_THREADS: value is not defined

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_PLACES='threads'

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_PROC_BIND='intel'

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_SCHEDULE='static'

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_STACKSIZE=8M

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_TARGET_OFFLOAD=DEFAULT

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_TEAMS_THREAD_LIMIT=0

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_THREAD_LIMIT=2147483647

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_TOOL=enabled

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_TOOL_LIBRARIES: value is not defined

[2024-02-22 08:15:06,522][INFO] run.py:338  -    OMP_TOOL_VERBOSE_INIT: value is not defined

[2024-02-22 08:15:06,523][INFO] run.py:338  -    OMP_WAIT_POLICY=PASSIVE

[2024-02-22 08:15:06,523][INFO] run.py:338  -    KMP_AFFINITY='noverbose,warnings,respect,noreset,granularity=thread,compact,1,0'

[2024-02-22 08:15:06,523][INFO] run.py:338  - 

[2024-02-22 08:15:06,827][INFO] run.py:338  - /opt/conda/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.

[2024-02-22 08:15:06,827][INFO] run.py:338  -   _torch_pytree._register_pytree_node(

[2024-02-22 08:15:07,060][INFO] run.py:338  - 

[2024-02-22 08:15:07,060][INFO] run.py:338  - User settings:

[2024-02-22 08:15:07,060][INFO] run.py:338  - 

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_AFFINITY=granularity=fine,compact,1,0

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_BLOCKTIME=INF

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_DUPLICATE_LIB_OK=True

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_FORKJOIN_BARRIER_PATTERN=dist,dist

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_INIT_AT_FORK=FALSE

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_PLAIN_BARRIER_PATTERN=dist,dist

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_REDUCTION_BARRIER_PATTERN=dist,dist

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_SETTINGS=1

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_TPAUSE=0

[2024-02-22 08:15:07,060][INFO] run.py:338  - 

[2024-02-22 08:15:07,060][INFO] run.py:338  - Effective settings:

[2024-02-22 08:15:07,060][INFO] run.py:338  - 

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_ABORT_DELAY=0

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_ADAPTIVE_LOCK_PROPS='1,1024'

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_ALIGN_ALLOC=64

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_ALL_THREADPRIVATE=1024

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_ATOMIC_MODE=2

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_BLOCKTIME=2147483646

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_CPUINFO_FILE: value is not defined

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_DETERMINISTIC_REDUCTION=false

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_DEVICE_THREAD_LIMIT=2147483647

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_DISP_HAND_THREAD=false

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_DISP_NUM_BUFFERS=7

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_DUPLICATE_LIB_OK=true

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_ENABLE_TASK_THROTTLING=true

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_FORCE_MONOTONIC_DYNAMIC_SCHEDULE=false

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_FORCE_REDUCTION: value is not defined

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_FOREIGN_THREADS_THREADPRIVATE=true

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_FORKJOIN_BARRIER='2,2'

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_FORKJOIN_BARRIER_PATTERN='dist,dist'

[2024-02-22 08:15:07,060][INFO] run.py:338  -    KMP_FORKJOIN_FRAMES=true

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_FORKJOIN_FRAMES_MODE=3

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_GTID_MODE=3

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_HANDLE_SIGNALS=false

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_HIDDEN_HELPER_AFFINITY='noverbose,warnings,granularity=core,none'

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_HOT_TEAMS_MAX_LEVEL=1

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_HOT_TEAMS_MODE=0

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_INIT_AT_FORK=true

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_ITT_PREPARE_DELAY=0

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_LIBRARY=throughput

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_LOCK_KIND=tas

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_MALLOC_POOL_INCR=1M

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_MWAIT_HINTS=0

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_NESTING_MODE=0

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_NUM_LOCKS_IN_BLOCK=1

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_PLAIN_BARRIER='2,2'

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_PLAIN_BARRIER_PATTERN='dist,dist'

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_REDUCTION_BARRIER='1,1'

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_REDUCTION_BARRIER_PATTERN='dist,dist'

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_SCHEDULE='static,balanced;guided,iterative'

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_SETTINGS=true

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_SPIN_BACKOFF_PARAMS='4096,100'

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_STACKOFFSET=64

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_STACKPAD=0

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_STACKSIZE=8M

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_STORAGE_MAP=false

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_TASKING=2

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_TASKLOOP_MIN_TASKS=0

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_TASK_STEALING_CONSTRAINT=1

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_TEAMS_PROC_BIND=spread

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_TEAMS_THREAD_LIMIT=256

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_TOPOLOGY_METHOD=all

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_TPAUSE=0

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_USER_LEVEL_MWAIT=false

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_USE_YIELD=1

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_VERSION=false

[2024-02-22 08:15:07,061][INFO] run.py:338  -    KMP_WARNINGS=true

[2024-02-22 08:15:07,061][INFO] run.py:338  -    LIBOMP_NUM_HIDDEN_HELPER_THREADS=0

[2024-02-22 08:15:07,061][INFO] run.py:338  -    LIBOMP_USE_HIDDEN_HELPER_TASK=false

[2024-02-22 08:15:07,061][INFO] run.py:338  -    OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'

[2024-02-22 08:15:07,061][INFO] run.py:338  -    OMP_ALLOCATOR=omp_default_mem_alloc

[2024-02-22 08:15:07,061][INFO] run.py:338  -    OMP_CANCELLATION=false

[2024-02-22 08:15:07,061][INFO] run.py:338  -    OMP_DEBUG=disabled

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_DEFAULT_DEVICE=0

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_DISPLAY_AFFINITY=false

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_DISPLAY_ENV=false

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_DYNAMIC=false

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_MAX_ACTIVE_LEVELS=1

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_MAX_TASK_PRIORITY=0

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_NESTED: deprecated; max-active-levels-var=1

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_NUM_TEAMS=0

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_NUM_THREADS: value is not defined

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_PLACES='threads'

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_PROC_BIND='intel'

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_SCHEDULE='static'

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_STACKSIZE=8M

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_TARGET_OFFLOAD=DEFAULT

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_TEAMS_THREAD_LIMIT=0

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_THREAD_LIMIT=2147483647

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_TOOL=enabled

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_TOOL_LIBRARIES: value is not defined

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_TOOL_VERBOSE_INIT: value is not defined

[2024-02-22 08:15:07,062][INFO] run.py:338  -    OMP_WAIT_POLICY=PASSIVE

[2024-02-22 08:15:07,062][INFO] run.py:338  -    KMP_AFFINITY='noverbose,warnings,respect,noreset,granularity=thread,compact,1,0'

[2024-02-22 08:15:07,062][INFO] run.py:338  - 

[2024-02-22 08:15:07,536][INFO] run.py:338  - [nltk_data] Downloading package punkt to /root/nltk_data...

[2024-02-22 08:15:07,562][INFO] run.py:338  - [nltk_data]   Package punkt is already up-to-date!

[2024-02-22 08:15:08,009][INFO] run.py:338  - 2024-02-22 08:15:08,009 - root - INFO - Use the given dataset ./saved_results/cnn_dailymail_validation.json

[2024-02-22 08:15:08,009][INFO] run.py:338  - 2024-02-22 08:15:08,009 - root - INFO - low_precision_checkpoint is given. Calibration skipped.

[2024-02-22 08:15:08,009][INFO] run.py:338  - 2024-02-22 08:15:08,009 - root - INFO - Loading low_precision_checkpoint...

[2024-02-22 08:15:09,491][INFO] run.py:338  - 2024-02-22 08:15:09,491 - root - INFO - low_precision_checkpoint loaded.

[2024-02-22 08:15:09,491][INFO] run.py:338  - 2024-02-22 08:15:09,491 - root - INFO - Loading model /opt/workdir/code/gptj-99/pytorch-cpu/data/gpt-j-checkpoint...

[2024-02-22 08:15:18,131][INFO] run.py:338  - Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:07,  3.50s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:06<00:03,  3.45s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.57s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.82s/it]

[2024-02-22 08:15:18,183][INFO] run.py:338  - Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.

[2024-02-22 08:15:18,212][INFO] run.py:338  - Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.

[2024-02-22 08:15:18,217][INFO] run.py:338  - 2024-02-22 08:15:18,216 - root - INFO - model loaded.

[2024-02-22 08:15:18,217][INFO] run.py:338  - 2024-02-22 08:15:18,216 - root - INFO - Quantize model to INT4.

[2024-02-22 08:15:18,217][INFO] run.py:338  - 2024-02-22 08:15:18,217 - root - INFO - Start quantizing model to INT4 by ipex.llm.optimize.

[2024-02-22 08:15:29,501][INFO] run.py:338  - /opt/conda/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.

[2024-02-22 08:15:29,502][INFO] run.py:338  -   _torch_pytree._register_pytree_node(

[2024-02-22 08:15:29,771][INFO] run.py:338  - /opt/conda/lib/python3.9/site-packages/intel_extension_for_pytorch/quantization/_quantize.py:97: UserWarning: BatchNorm folding failed during the prepare process.

[2024-02-22 08:15:29,771][INFO] run.py:338  -   warnings.warn("BatchNorm folding failed during the prepare process.")

[2024-02-22 08:15:36,217][INFO] run.py:338  - /opt/conda/lib/python3.9/site-packages/transformers/models/gptj/modeling_gptj.py:605: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!

[2024-02-22 08:15:36,217][INFO] run.py:338  -   if batch_size <= 0:

[2024-02-22 08:15:36,224][INFO] run.py:338  - /opt/conda/lib/python3.9/site-packages/intel_extension_for_pytorch/transformers/models/cpu/fusions/mha_fusion.py:86: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.

[2024-02-22 08:15:36,224][INFO] run.py:338  -   seq_info = torch.tensor(

[2024-02-22 08:15:36,224][INFO] run.py:338  - /opt/conda/lib/python3.9/site-packages/intel_extension_for_pytorch/transformers/models/cpu/fusions/mha_fusion.py:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).

[2024-02-22 08:15:36,224][INFO] run.py:338  -   seq_info = torch.tensor(

[2024-02-22 08:15:40,518][INFO] run.py:338  - 2024-02-22 08:15:40,518 - root - INFO - Quantization finished. INT4 model saved to saved_results/int4_model.pt.

[2024-02-22 08:15:41,085][INFO] run.py:338  - + retVal=0

[2024-02-22 08:15:41,085][INFO] run.py:338  - + '[' 0 -ne 0 ']'

[2024-02-22 08:15:41,085][INFO] run.py:338  - ++ date '+%Y-%m-%d %T'

[2024-02-22 08:15:41,088][INFO] run.py:338  - + echo '2024-02-22 08:15:41 - INFO - Finished successfully.'

[2024-02-22 08:15:41,088][INFO] run.py:338  - + set +x

[2024-02-22 08:18:21,455][INFO] common.py:17    - Executing bash commands: export CONTAINER_MODEL_DIR=/data/mlperf_data/gpt-j/models && export CONTAINER_DATA_DIR=/data/mlperf_data/gpt-j/data && export CONTAINER_CODE_DIR=/opt/workdir/code/gptj-99/pytorch-cpu && export CONTAINER_OUTPUT_DIR=/output && export CONTAINER_COMPLIANCE_SUITE_DIR=/opt/workdir/code/gptj-99/pytorch-cpu/gpt-j-env/mlperf_inference/compliance/nvidia && export MODEL=gptj-99 && export IMPL=pytorch-cpu && export DTYPE=int4 && export ci_run=0 && export WORKLOAD_DATA=${CONTAINER_CODE_DIR}/data && export CALIBRATION_DATA_JSON=${WORKLOAD_DATA}/calibration-data/cnn_dailymail_calibration.json && export CHECKPOINT_DIR=${WORKLOAD_DATA}/gpt-j-checkpoint && export VALIDATION_DATA_JSON=${WORKLOAD_DATA}/validation-data/cnn_dailymail_validation.json && export INT4_MODEL_DIR=${WORKLOAD_DATA}/gpt-j-int4-model && export CALIBRATION_DIR=${CONTAINER_CODE_DIR}/../../../calibration/gptj-99/pytorch-cpu  && cd /opt/workdir/code/gptj-99/pytorch-cpu &&  pwd &&   bash run_offline_accuracy_int4.sh  
[2024-02-22 08:18:21,456][INFO] run.py:338  - Elapsed time: 2588.8544685840607 sec.

[2024-02-22 08:18:21,456][INFO] run.py:338  - Completed preprocessing for model gptj-99.

[2024-02-22 08:18:21,456][INFO] run.py:338  - ===== Performing gptj-99/pytorch-cpu/int4/Offline/accuracy =====

[2024-02-22 08:18:21,456][INFO] run.py:338  - Sleep 120 seconds.

[2024-02-22 08:18:21,456][INFO] run.py:338  - Clearing cache and setting environment parameters...

[2024-02-22 08:18:21,456][INFO] run.py:338  - [2024-02-22 08:18:21,455][INFO] common.py:17    - Executing bash commands: export CONTAINER_MODEL_DIR=/data/mlperf_data/gpt-j/models && export CONTAINER_DATA_DIR=/data/mlperf_data/gpt-j/data && export CONTAINER_CODE_DIR=/opt/workdir/code/gptj-99/pytorch-cpu && export CONTAINER_OUTPUT_DIR=/output && export CONTAINER_COMPLIANCE_SUITE_DIR=/opt/workdir/code/gptj-99/pytorch-cpu/gpt-j-env/mlperf_inference/compliance/nvidia && export MODEL=gptj-99 && export IMPL=pytorch-cpu && export DTYPE=int4 && export ci_run=0 && export WORKLOAD_DATA=${CONTAINER_CODE_DIR}/data && export CALIBRATION_DATA_JSON=${WORKLOAD_DATA}/calibration-data/cnn_dailymail_calibration.json && export CHECKPOINT_DIR=${WORKLOAD_DATA}/gpt-j-checkpoint && export VALIDATION_DATA_JSON=${WORKLOAD_DATA}/validation-data/cnn_dailymail_validation.json && export INT4_MODEL_DIR=${WORKLOAD_DATA}/gpt-j-int4-model && export CALIBRATION_DIR=${CONTAINER_CODE_DIR}/../../../calibration/gptj-99/pytorch-cpu  && cd /opt/workdir/code/gptj-99/pytorch-cpu &&  pwd &&   bash run_offline_accuracy_int4.sh  

[2024-02-22 11:45:32,142][INFO] common.py:17    - Executing bash commands: export CONTAINER_MODEL_DIR=/data/mlperf_data/gpt-j/models && export CONTAINER_DATA_DIR=/data/mlperf_data/gpt-j/data && export CONTAINER_CODE_DIR=/opt/workdir/code/gptj-99/pytorch-cpu && export CONTAINER_OUTPUT_DIR=/output && export CONTAINER_COMPLIANCE_SUITE_DIR=/opt/workdir/code/gptj-99/pytorch-cpu/gpt-j-env/mlperf_inference/compliance/nvidia && export MODEL=gptj-99 && export IMPL=pytorch-cpu && export DTYPE=int4 && export ci_run=0 && export WORKLOAD_DATA=${CONTAINER_CODE_DIR}/data && export CALIBRATION_DATA_JSON=${WORKLOAD_DATA}/calibration-data/cnn_dailymail_calibration.json && export CHECKPOINT_DIR=${WORKLOAD_DATA}/gpt-j-checkpoint && export VALIDATION_DATA_JSON=${WORKLOAD_DATA}/validation-data/cnn_dailymail_validation.json && export INT4_MODEL_DIR=${WORKLOAD_DATA}/gpt-j-int4-model && export CALIBRATION_DIR=${CONTAINER_CODE_DIR}/../../../calibration/gptj-99/pytorch-cpu  && cd /opt/workdir/code/gptj-99/pytorch-cpu &&  pwd &&   bash run_offline_int4.sh  
[2024-02-22 11:45:32,143][INFO] run.py:338  - ********************************************************************************

[2024-02-22 11:45:32,143][INFO] run.py:338  - gptj-99/pytorch-cpu/int4/Offline/accuracy:

[2024-02-22 11:45:32,143][INFO] run.py:338  -   Accuracy: INFO:datasets:PyTorch version 2.2.0 available.

[2024-02-22 11:45:32,143][INFO] run.py:338  - /opt/conda/lib/python3.9/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.

[2024-02-22 11:45:32,143][INFO] run.py:338  -   _torch_pytree._register_pytree_node(

[2024-02-22 11:45:32,143][INFO] run.py:338  - /opt/conda/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.

[2024-02-22 11:45:32,143][INFO] run.py:338  -   _torch_pytree._register_pytree_node(

[2024-02-22 11:45:32,143][INFO] run.py:338  - [nltk_data] Downloading package punkt to /root/nltk_data...

[2024-02-22 11:45:32,143][INFO] run.py:338  - [nltk_data]   Package punkt is already up-to-date!

[2024-02-22 11:45:32,143][INFO] run.py:338  - Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.

[2024-02-22 11:45:32,143][INFO] run.py:338  - Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.

[2024-02-22 11:45:32,143][INFO] run.py:338  - INFO:absl:Using default tokenizer.

[2024-02-22 11:45:32,143][INFO] run.py:338  - 

[2024-02-22 11:45:32,143][INFO] run.py:338  - Results

[2024-02-22 11:45:32,144][INFO] run.py:338  - 

[2024-02-22 11:45:32,144][INFO] run.py:338  - {'rouge1': 42.8468, 'rouge2': 20.0444, 'rougeL': 29.8491, 'rougeLsum': 39.9998, 'gen_len': 3968072, 'gen_num': 13368}

[2024-02-22 11:45:32,144][INFO] run.py:338  - 

[2024-02-22 11:45:32,144][INFO] run.py:338  -   Result dir: /output/closed/Intel/results/1-node-2S-SPR-PyTorch-INT4/gptj-99/Offline/accuracy

[2024-02-22 11:45:32,144][INFO] run.py:338  - ********************************************************************************

[2024-02-22 11:45:32,144][INFO] run.py:338  - Updating measurements of gptj-99/pytorch-cpu/int4/Offline/accuracy.

[2024-02-22 11:45:32,144][INFO] run.py:338  - Elapsed time: 12462.570087909698 sec.

[2024-02-22 11:45:32,144][INFO] run.py:338  - ===== Performing gptj-99/pytorch-cpu/int4/Offline/performance =====

[2024-02-22 11:45:32,144][INFO] run.py:338  - Sleep 120 seconds.

[2024-02-22 11:45:32,144][INFO] run.py:338  - Clearing cache and setting environment parameters...

[2024-02-22 11:45:32,144][INFO] run.py:338  - [2024-02-22 11:45:32,142][INFO] common.py:17    - Executing bash commands: export CONTAINER_MODEL_DIR=/data/mlperf_data/gpt-j/models && export CONTAINER_DATA_DIR=/data/mlperf_data/gpt-j/data && export CONTAINER_CODE_DIR=/opt/workdir/code/gptj-99/pytorch-cpu && export CONTAINER_OUTPUT_DIR=/output && export CONTAINER_COMPLIANCE_SUITE_DIR=/opt/workdir/code/gptj-99/pytorch-cpu/gpt-j-env/mlperf_inference/compliance/nvidia && export MODEL=gptj-99 && export IMPL=pytorch-cpu && export DTYPE=int4 && export ci_run=0 && export WORKLOAD_DATA=${CONTAINER_CODE_DIR}/data && export CALIBRATION_DATA_JSON=${WORKLOAD_DATA}/calibration-data/cnn_dailymail_calibration.json && export CHECKPOINT_DIR=${WORKLOAD_DATA}/gpt-j-checkpoint && export VALIDATION_DATA_JSON=${WORKLOAD_DATA}/validation-data/cnn_dailymail_validation.json && export INT4_MODEL_DIR=${WORKLOAD_DATA}/gpt-j-int4-model && export CALIBRATION_DIR=${CONTAINER_CODE_DIR}/../../../calibration/gptj-99/pytorch-cpu  && cd /opt/workdir/code/gptj-99/pytorch-cpu &&  pwd &&   bash run_offline_int4.sh  

[2024-02-22 13:38:46,322][INFO] common.py:17    - Executing bash commands: export CONTAINER_MODEL_DIR=/data/mlperf_data/gpt-j/models && export CONTAINER_DATA_DIR=/data/mlperf_data/gpt-j/data && export CONTAINER_CODE_DIR=/opt/workdir/code/gptj-99/pytorch-cpu && export CONTAINER_OUTPUT_DIR=/output && export CONTAINER_COMPLIANCE_SUITE_DIR=/opt/workdir/code/gptj-99/pytorch-cpu/gpt-j-env/mlperf_inference/compliance/nvidia && export MODEL=gptj-99 && export IMPL=pytorch-cpu && export DTYPE=int4 && export ci_run=0 && export WORKLOAD_DATA=${CONTAINER_CODE_DIR}/data && export CALIBRATION_DATA_JSON=${WORKLOAD_DATA}/calibration-data/cnn_dailymail_calibration.json && export CHECKPOINT_DIR=${WORKLOAD_DATA}/gpt-j-checkpoint && export VALIDATION_DATA_JSON=${WORKLOAD_DATA}/validation-data/cnn_dailymail_validation.json && export INT4_MODEL_DIR=${WORKLOAD_DATA}/gpt-j-int4-model && export CALIBRATION_DIR=${CONTAINER_CODE_DIR}/../../../calibration/gptj-99/pytorch-cpu  && cd /opt/workdir/code/gptj-99/pytorch-cpu &&  pwd &&   bash run_server_accuracy_int4.sh  
[2024-02-22 13:38:46,323][INFO] run.py:338  - ********************************************************************************

[2024-02-22 13:38:46,323][INFO] run.py:338  - gptj-99/pytorch-cpu/int4/Offline/performance:

[2024-02-22 13:38:46,323][INFO] run.py:338  -   Target QPS: 2.4

[2024-02-22 13:38:46,323][INFO] run.py:338  -   Perf QPS: 2.38751

[2024-02-22 13:38:46,323][INFO] run.py:338  -   99.00 percentile latency: 5505674614557.0

[2024-02-22 13:38:46,323][INFO] run.py:338  -   Result dir: /output/closed/Intel/results/1-node-2S-SPR-PyTorch-INT4/gptj-99/Offline/performance/run_1

[2024-02-22 13:38:46,323][INFO] run.py:338  - ********************************************************************************

[2024-02-22 13:38:46,323][INFO] run.py:338  - Updating measurements of gptj-99/pytorch-cpu/int4/Offline/performance.

[2024-02-22 13:38:46,323][INFO] run.py:338  - Elapsed time: 6794.132155656815 sec.

[2024-02-22 13:38:46,324][INFO] run.py:338  - ===== Performing gptj-99/pytorch-cpu/int4/Offline/compliance =====

[2024-02-22 13:38:46,324][INFO] run.py:338  - Completed gptj-99/pytorch-cpu/int4/Offline/compliance.

[2024-02-22 13:38:46,324][INFO] run.py:338  - Elapsed time: 3.814697265625e-05 sec.

[2024-02-22 13:38:46,324][INFO] run.py:338  - ===== Performing gptj-99/pytorch-cpu/int4/Server/accuracy =====

[2024-02-22 13:38:46,324][INFO] run.py:338  - Sleep 120 seconds.

[2024-02-22 13:38:46,324][INFO] run.py:338  - Clearing cache and setting environment parameters...

[2024-02-22 13:38:46,324][INFO] run.py:338  - [2024-02-22 13:38:46,322][INFO] common.py:17    - Executing bash commands: export CONTAINER_MODEL_DIR=/data/mlperf_data/gpt-j/models && export CONTAINER_DATA_DIR=/data/mlperf_data/gpt-j/data && export CONTAINER_CODE_DIR=/opt/workdir/code/gptj-99/pytorch-cpu && export CONTAINER_OUTPUT_DIR=/output && export CONTAINER_COMPLIANCE_SUITE_DIR=/opt/workdir/code/gptj-99/pytorch-cpu/gpt-j-env/mlperf_inference/compliance/nvidia && export MODEL=gptj-99 && export IMPL=pytorch-cpu && export DTYPE=int4 && export ci_run=0 && export WORKLOAD_DATA=${CONTAINER_CODE_DIR}/data && export CALIBRATION_DATA_JSON=${WORKLOAD_DATA}/calibration-data/cnn_dailymail_calibration.json && export CHECKPOINT_DIR=${WORKLOAD_DATA}/gpt-j-checkpoint && export VALIDATION_DATA_JSON=${WORKLOAD_DATA}/validation-data/cnn_dailymail_validation.json && export INT4_MODEL_DIR=${WORKLOAD_DATA}/gpt-j-int4-model && export CALIBRATION_DIR=${CONTAINER_CODE_DIR}/../../../calibration/gptj-99/pytorch-cpu  && cd /opt/workdir/code/gptj-99/pytorch-cpu &&  pwd &&   bash run_server_accuracy_int4.sh  

[2024-02-22 17:01:03,190][WARNING] submission_checker.py:55    - Output dir already existed: /home/ucstme/
[2024-02-22 17:01:41,492][WARNING] submission_checker.py:55    - Output dir already existed: /home/ucstme/test/
[2024-02-22 17:03:07,121][WARNING] submission_checker.py:55    - Output dir already existed: /home/ucstme/test
[2024-02-22 17:03:07,122][INFO] submission_checker.py:59    - Move the output dir to /home/ucstme/test_1708621387
[2024-02-22 17:03:07,122][INFO] submission_checker.py:66    - Fetching MLPerf inference kit...
[2024-02-22 17:03:07,122][INFO] common.py:50    - Executing bash commands: cd /tmp/mlperf/runtime; git clone --recurse-submodules https://github.com/mlcommons/inference.git
[2024-02-22 17:03:51,637][INFO] common.py:62    - stdout: Submodule path 'language/bert/DeepLearningExamples': checked out 'b03375bd6c2c5233130e61a3be49e26d1a20ac7c'
Submodule path 'language/bert/DeepLearningExamples/PyTorch/SpeechRecognition/Jasper/external/tensorrt-inference-server': checked out '71f0771cb8cb2a2eb1c6a9433f9a56dd1f206c96'
Submodule path 'language/bert/DeepLearningExamples/PyTorch/Translation/Transformer/cutlass': checked out 'ed2ed4d667ce95e1371bd62db32b6a114e774336'
Submodule path 'language/bert/DeepLearningExamples/PyTorch/Translation/Transformer/cutlass/tools/external/googletest': checked out '9077ec7efe5b652468ab051e93c67589d5cb8f85'
Submodule path 'vision/medical_imaging/3d-unet-brats19/nnUnet': checked out 'b38c69b345b2f60cd0d053039669e8f988b0c0af'

[2024-02-22 17:03:51,637][INFO] common.py:63    - stderr: 
[2024-02-22 17:03:51,637][INFO] common.py:69    - Successfully executed bash commands.
[2024-02-22 17:03:51,637][INFO] submission_checker.py:72    - ----------------------------------------
[2024-02-22 17:03:51,637][INFO] submission_checker.py:73    - Truncating accuracy logs...
[2024-02-22 17:03:51,637][INFO] submission_checker.py:74    - ----------------------------------------
[2024-02-22 17:03:51,637][INFO] common.py:50    - Executing bash commands: cd /tmp/mlperf/runtime/inference; python3 ./tools/submission/truncate_accuracy_log.py --input /submission --submitter Intel --output /home/ucstme/test
[2024-02-22 17:03:51,678][INFO] common.py:62    - stdout: 
[2024-02-22 17:03:51,678][INFO] common.py:63    - stderr: 
[2024-02-22 17:03:51,678][INFO] common.py:69    - Successfully executed bash commands.
[2024-02-22 17:03:51,678][INFO] submission_checker.py:101   - Clearing historical logs...
[2024-02-22 17:03:51,678][INFO] submission_checker.py:105   - ----------------------------------------
[2024-02-22 17:03:51,678][INFO] submission_checker.py:106   - Performing submission checker...
[2024-02-22 17:03:51,678][INFO] submission_checker.py:107   - ----------------------------------------
[2024-02-22 17:03:51,678][INFO] common.py:50    - Executing bash commands: cd /tmp/mlperf/runtime/inference; python3 ./tools/submission/submission_checker.py --input /home/ucstme/test --submitter Intel --version v4.0
[2024-02-22 17:03:51,726][INFO] common.py:62    - stdout: 
[2024-02-22 17:03:51,726][INFO] common.py:63    - stderr: 
[2024-02-22 17:03:51,726][INFO] common.py:69    - Successfully executed bash commands.
