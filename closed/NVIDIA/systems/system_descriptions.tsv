NVIDIA DGX H100 (8x H100-SXM-80GB, TensorRT)	DGX-H100_H100-SXM-80GBx8_TRT	NVIDIA	closed	datacenter	N/A	available	1	Intel(R) Xeon(R) Platinum 8480C	2	56				32x 64GB MTC40F2046S1RC48BA1	2 TB	2 TB SSD, 5 TB CIFS	NVMe SSD, CIFS mounted disk storage	Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s	Ethernet/Infiniband on switching network	8	NVIDIA H100-SXM-80GB		PCIe Gen5 x16	18x 4th Gen NVLink, 900GB/s		80 GB	HBM3		Air-cooled		TensorRT 9.3.0, CUDA 12.2	Ubuntu 20.04.4	TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0														SSD	NVMe
NVIDIA DGX H100 (1x H100-SXM-80GB, TensorRT)	DGX-H100_H100-SXM-80GBx1_TRT	NVIDIA	closed	datacenter	N/A	available	1	Intel(R) Xeon(R) Platinum 8480C	2	56				32x 64GB MTC40F2046S1RC48BA1	2 TB	2 TB SSD, 5 TB CIFS	NVMe SSD, CIFS mounted disk storage	Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s	Ethernet/Infiniband on switching network	1	NVIDIA H100-SXM-80GB		PCIe Gen5 x16	18x 4th Gen NVLink, 900GB/s		80 GB	HBM3		Air-cooled		TensorRT 9.3.0, CUDA 12.2	Ubuntu 20.04.4	TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0														SSD	NVMe
NVIDIA DGX H100 (2x H100-SXM-80GB, TensorRT)	DGX-H100_H100-SXM-80GBx2_TRT	NVIDIA	closed	datacenter	N/A	available	1	Intel(R) Xeon(R) Platinum 8480C	2	56				32x 64GB MTC40F2046S1RC48BA1	2 TB	2 TB SSD, 5 TB CIFS	NVMe SSD, CIFS mounted disk storage	Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s	Ethernet/Infiniband on switching network	2	NVIDIA H100-SXM-80GB		PCIe Gen5 x16	18x 4th Gen NVLink, 900GB/s		80 GB	HBM3		Air-cooled		TensorRT 9.3.0, CUDA 12.2	Ubuntu 20.04.4	TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0														SSD	NVMe
NVIDIA DGX H100 (8x H100-SXM-80GB, MaxQ, TensorRT)	DGX-H100_H100-SXM-80GBx8_TRT_MaxQ	NVIDIA	closed	datacenter	N/A	available	1	Intel(R) Xeon(R) Platinum 8480C	2	56				32x 64GB MTC40F2046S1RC48BA1	2 TB	2 TB SSD, 5 TB CIFS	NVMe SSD, CIFS mounted disk storage	Infiniband; Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s	Ethernet/Infiniband on switching network	8	NVIDIA H100-SXM-80GB		PCIe Gen5 x16	18x 4th Gen NVLink, 900GB/s		80 GB	HBM3		Air-cooled		TensorRT 9.3.0, CUDA 12.2	Ubuntu 20.04.4	TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0														SSD	NVMe
SYS-521GE-TNRT (8x H100-NVL-94GB, TensorRT)	H100-NVL-94GBx8_TRT	NVIDIA	closed	datacenter	N/A	available	1	Intel(R) Xeon(R) Platinum 8480+	2	56				32x 64GB M321R8GA0BB0-CQKZJ	2 TB	2 TB SSD, 5 TB CIFS	NVMe SSD, CIFS mounted disk storage	Gig Ethernet; Data bandwidth for GPU-PCIe: 504 GB/s	Ethernet on switching network	8	NVIDIA H100 NVL		PCIe Gen4 x16	18x 4th Gen NVLink, 600GB/s		94 GB	HBM3		Air-cooled		TensorRT 9.3.0, CUDA 12.2	Ubuntu 20.04.4	TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0														SSD	NVMe
NVIDIA H200 (1x H200-SXM-141GB, TensorRT)	H200-SXM-141GBx1_TRT	NVIDIA	closed	datacenter	N/A	preview	1	Intel(R) Xeon(R) Platinum 8480C	2	56				32x 64GB MTC40F2046S1RC48BA1	2 TB	2 TB SSD, 5 TB CIFS	NVMe SSD, CIFS mounted disk storage	Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s	Ethernet/Infiniband on switching network	1	NVIDIA H200-SXM-141GB		PCIe Gen5 x16	18x 4th Gen NVLink, 900GB/s		141 GB	HBM3		Air-cooled	H200 TGP 700W	TensorRT 9.3.0, CUDA 12.2	Ubuntu 20.04.4	TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 550.54, DALI 1.28.0														SSD	NVMe
NVIDIA H200 (8x H200-SXM-141GB, TensorRT)	H200-SXM-141GBx8_TRT	NVIDIA	closed	datacenter	N/A	preview	1	Intel(R) Xeon(R) Platinum 8480C	2	56				32x 64GB MTC40F2046S1RC48BA1	2 TB	2 TB SSD, 5 TB CIFS	NVMe SSD, CIFS mounted disk storage	Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s	Ethernet/Infiniband on switching network	8	NVIDIA H200-SXM-141GB		PCIe Gen5 x16	18x 4th Gen NVLink, 900GB/s		141 GB	HBM3		Air-cooled	H200 TGP 700W	TensorRT 9.3.0, CUDA 12.2	Ubuntu 20.04.4	TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 550.54, DALI 1.28.0														SSD	NVMe
NVIDIA H200 (1x H200-SXM-141GB-CTS, TensorRT)	H200-SXM-141GB-CTSx1_TRT	NVIDIA	closed	datacenter	N/A	preview	1	Intel(R) Xeon(R) Platinum 8480C	2	56				32x 64GB MTC40F2046S1RC48BA12	2 TB	2 TB SSD, 5 TB CIFS	NVMe SSD, CIFS mounted disk storage	Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s	Ethernet/Infiniband on switching network	1	NVIDIA H200-SXM-141GB-CTS		PCIe Gen5 x16	18x 4th Gen NVLink, 900GB/s		141 GB	HBM3		Air/liquid cooling	H200 TGP 1000W	TensorRT 9.3.0, CUDA 12.2	Ubuntu 20.04.4	TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 550.54, DALI 1.28.0														SSD	NVMe
NVIDIA H200 (8x H200-SXM-141GB-CTS, TensorRT)	H200-SXM-141GB-CTSx8_TRT	NVIDIA	closed	datacenter	N/A	preview	1	Intel(R) Xeon(R) Platinum 8480C	2	56				32x 64GB MTC40F2046S1RC48BA12	2 TB	2 TB SSD, 5 TB CIFS	NVMe SSD, CIFS mounted disk storage	Infiniband;  Data bandwidth for GPU-PCIe: 504GB/s; PCIe-NIC: 500GB/s	Ethernet/Infiniband on switching network	8	NVIDIA H200-SXM-141GB-CTS		PCIe Gen5 x16	18x 4th Gen NVLink, 900GB/s		141 GB	HBM3		Air/liquid cooling	H200 TGP 1000W	TensorRT 9.3.0, CUDA 12.2	Ubuntu 20.04.4	TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 550.54, DALI 1.28.0														SSD	NVMe
NVIDIA GH200-GraceHopper-Superchip (1x GH200-96GB_aarch64, TensorRT)	GH200-GraceHopper-Superchip_GH200-96GB_aarch64x1_TRT	NVIDIA	closed	datacenter	N/A	available	1	NVIDIA Grace CPU	1	72				16x 16DP (32GB) LPDDR5x	512 GB	2 TB SSD, 5 TB CIFS	NVMe SSD, CIFS mounted disk storage	Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s	Ethernet/Infiniband on switching network	1	NVIDIA GH200-GraceHopper-Superchip		NVLink-C2C	1x 400Gbe Infiniband		96 GB	HBM3		Air-cooled	NVIDIA MGX Reference Platform;	TensorRT 9.3.0, CUDA 12.2	Ubuntu 22.04.2	TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.65, DALI 1.28.0														SSD	NVMe
NVIDIA GH200-GraceHopper-Superchip (1x GH200-144GB_aarch64, TensorRT)	GH200-GraceHopper-Superchip_GH200-144GB_aarch64x1_TRT	NVIDIA	closed	datacenter	N/A	preview	1	NVIDIA Grace CPU	1	72				15x 16DP (32GB) LPDDR5x	480 GB	2 TB SSD, 5 TB CIFS	NVMe SSD, CIFS mounted disk storage	Ethernet; Data bandwidth for GPU-NIC is 252.06 GB/s	Ethernet/Infiniband on switching network	1	NVIDIA GH200-GraceHopper-Superchip		NVLink-C2C	1x 400Gbe Infiniband		144 GB	HBM3e		Air-cooled	NVIDIA MGX Reference Platform;	TensorRT 9.3.0, CUDA 12.2	Ubuntu 22.04.2	TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.65, DALI 1.28.0														SSD	NVMe
ASROCKRACK 4U8G-ROME2/4E (8x L40S, TensorRT)	L40Sx8_TRT	NVIDIA	closed	datacenter	N/A	available	1	AMD EPYC 7742 64-Core Processor	2	64				16x 64GB 36ASF8G72PZ-3G2E1	1 TB	3 TB SSD, 5 TB CIFS	NVMe SSD, CIFS mounted disk storage	Gig Ethernet; Data bandwidth for GPU-PCIe: 252 GB/s; PCIe-NIC: 7.877GB/s	Ethernet on switching network	8	NVIDIA L40S		PCIe Gen4 x16	N/A		48 GB	GDDR6		Air-cooled		TensorRT 9.3.0, CUDA 12.2	Ubuntu 20.04.4	TensorRT 9.3.0, CUDA 12.2, cuDNN 8.9.6, Driver 535.129.03, DALI 1.28.0														SSD	NVMe
NVIDIA Jetson AGX Orin Developer Kit 64G (TensorRT)	Orin_TRT	NVIDIA	closed	edge	N/A	available	1	12-core ARM Cortex-A78AE CPU	1	12				64GB 256-bit LPDDR5	64 GB	64 GB eMMC, 5TB CIFS	eMMC 5.1, CIFS mounted disk storage	Gig Ethernet	USB forwarded	1	NVIDIA Jetson AGX Orin 64G		N/A	N/A		Shared with host	LPDDR5		Air-cooled	GPU and both DLAs are used in resnet50 and Retinanet, in Offline scenario	Jetpack 5.1.1, TensorRT 9.0.1, CUDA 11.4	Jetson r35.3.1 L4T	Jetpack 5.1.1, TensorRT 9.0.1, CUDA 11.4, cuDNN 8.5.0, 												130W	Dell USB-C 130.0W Adapter (HA130PM170)	eMMC 5.1	eMMC 5.1
