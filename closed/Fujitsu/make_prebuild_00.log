make[1]: Entering directory '/mnt/data4/work/home/yhara/inference_v4.0/closed/Fujitsu'
Building Docker image
USE_LEGACY: 0
USE_NGC: 1
PARTNER_DROP: v4.0.2
BASE_IMAGE: nvcr.io/yrleydyexu3y/mlpinf-partner-v40/mlperf-inference-partner-v40:mlpinf-v4.0.2-cuda12.2-cudnn8.9-x86_64-ubuntu20.04-partner
DOCKER_FILENAME: docker/Dockerfile.x86_64
docker pull nvcr.io/yrleydyexu3y/mlpinf-partner-v40/mlperf-inference-partner-v40:mlpinf-v4.0.2-cuda12.2-cudnn8.9-x86_64-ubuntu20.04-partner
mlpinf-v4.0.2-cuda12.2-cudnn8.9-x86_64-ubuntu20.04-partner: Pulling from yrleydyexu3y/mlpinf-partner-v40/mlperf-inference-partner-v40
Digest: sha256:4100f0495ac5b9b6ae5de9e4df89eeba81d5196b390574eafb6243caba7fe0c7
Status: Image is up to date for nvcr.io/yrleydyexu3y/mlpinf-partner-v40/mlperf-inference-partner-v40:mlpinf-v4.0.2-cuda12.2-cudnn8.9-x86_64-ubuntu20.04-partner
nvcr.io/yrleydyexu3y/mlpinf-partner-v40/mlperf-inference-partner-v40:mlpinf-v4.0.2-cuda12.2-cudnn8.9-x86_64-ubuntu20.04-partner
DOCKER_BUILDKIT=1 docker build -t mlperf-inference:yhara-x86_64-latest \
	--build-arg BASE_IMAGE=nvcr.io/yrleydyexu3y/mlpinf-partner-v40/mlperf-inference-partner-v40:mlpinf-v4.0.2-cuda12.2-cudnn8.9-x86_64-ubuntu20.04-partner \
	--build-arg CUDA_VER=12.2 \
	--build-arg DRIVER_VER_MAJOR=515 \
	--build-arg USE_NIGHTLY=0 \
	--build-arg USE_NGC=1 \
	--build-arg EXTERNAL_USER=1 \
	--build-arg MITTEN_VER=0.1.3b0 \
	--network host \
	-f docker/Dockerfile.x86_64 docker
#0 building with "default" instance using docker driver

#1 [internal] load .dockerignore
#1 transferring context: 2B done
#1 DONE 0.0s

#2 [internal] load build definition from Dockerfile.x86_64
#2 transferring dockerfile: 12.38kB done
#2 DONE 0.0s

#3 [internal] load metadata for nvcr.io/yrleydyexu3y/mlpinf-partner-v40/mlperf-inference-partner-v40:mlpinf-v4.0.2-cuda12.2-cudnn8.9-x86_64-ubuntu20.04-partner
#3 DONE 0.0s

#4 [ 1/40] FROM nvcr.io/yrleydyexu3y/mlpinf-partner-v40/mlperf-inference-partner-v40:mlpinf-v4.0.2-cuda12.2-cudnn8.9-x86_64-ubuntu20.04-partner
#4 DONE 0.0s

#5 [internal] load build context
#5 transferring context: 2.81kB done
#5 DONE 0.0s

#6 [ 4/40] RUN apt install -y --no-install-recommends libarchive-dev
#6 CACHED

#7 [38/40] RUN apt install -y libgl1-mesa-glx
#7 CACHED

#8 [ 3/40] RUN apt install -y --no-install-recommends pkg-config zip g++ zlib1g-dev unzip
#8 CACHED

#9 [21/40] WORKDIR /tmp
#9 CACHED

#10 [26/40] RUN git clone -b v2.2.1 https://github.com/gflags/gflags.git     && cd gflags     && mkdir build && cd build     && cmake -DBUILD_SHARED_LIBS=ON -DBUILD_STATIC_LIBS=ON -DBUILD_gflags_LIB=ON ..     && make -j     && make install     && cd /tmp && rm -rf gflags
#10 CACHED

#11 [17/40] RUN if [[ 1 = 1 ]]; then     mv /opt/nvmitten-0.1.3b0-cp38-cp38-linux_x86_64.whl /tmp     && mv /opt/faster-transformer-bert-fp8-weights-scales.tar.gz /tmp; fi
#11 CACHED

#12 [16/40] COPY requirements.x86_64.1.txt requirements.x86_64.2.txt nvmitten-0.1.3b0-cp38-cp38-linux_x86_64.whl*     faster-transformer-bert-fp8-weights-scales.tar.gz* /tmp
#12 CACHED

#13 [35/40] RUN python3 -m pip install mpi4py==3.1.4
#13 CACHED

#14 [20/40] RUN python3 -m pip install -r requirements.x86_64.1.txt  && python3 -m pip install -r requirements.x86_64.2.txt
#14 CACHED

#15 [13/40] RUN apt install -y rapidjson-dev
#15 CACHED

#16 [18/40] WORKDIR /tmp
#16 CACHED

#17 [27/40] RUN git clone -b v0.3.5 https://github.com/google/glog.git     && cd glog     && cmake -H. -Bbuild -G "Unix Makefiles" -DBUILD_SHARED_LIBS=ON -DBUILD_STATIC_LIBS=ON     && cmake --build build     && cmake --build build --target install     && cd /tmp && rm -rf glog
#17 CACHED

#18 [28/40] RUN wget https://github.com/NVlabs/cub/archive/1.8.0.zip -O cub-1.8.0.zip     && unzip cub-1.8.0.zip     && mv cub-1.8.0/cub /usr/include/x86_64-linux-gnu/     && rm -rf cub-1.8.0.zip cub-1.8.0
#18 CACHED

#19 [33/40] RUN python3 -m pip install nvmitten-0.1.3b0-cp38-cp38-linux_x86_64.whl
#19 CACHED

#20 [ 6/40] RUN if [[ 1 = 0 ]]; then     cd /tmp     && install_deb_pkg() { wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64//$1 -O $1 && dpkg -i $1 && rm $1; }     && install_deb_pkg libcudnn8_8.9.6.50-1+cuda12.2_amd64.deb     && install_deb_pkg libcudnn8-dev_8.9.6.50-1+cuda12.2_amd64.deb     && unset -f install_deb_pkg; fi
#20 CACHED

#21 [10/40] RUN ln -sf /usr/bin/pip3 /usr/bin/pip
#21 CACHED

#22 [36/40] WORKDIR /opt
#22 CACHED

#23 [30/40] RUN cd /tmp && git clone -b v3.11.2 https://github.com/nlohmann/json.git     && cp -r json/single_include/nlohmann /usr/include/x86_64-linux-gnu/     && rm -rf json
#23 CACHED

#24 [31/40] RUN python3 -m pip uninstall -y pic-c
#24 CACHED

#25 [39/40] RUN apt install -y python3.8-venv
#25 CACHED

#26 [11/40] RUN apt install -y sox
#26 CACHED

#27 [32/40] WORKDIR /tmp
#27 CACHED

#28 [ 8/40] RUN if [[ 1 = 0 ]]; then if [[ 0 = 0 ]]; then     cd /tmp     && install_deb_pkg() { wget -q http://cuda-repo/release-candidates/Libraries/TensorRT/v9.3/9.3.0.1-d6cbd29d/12.2-r535/Ubuntu20_04-x64-agnostic/deb//$1 -O $1 && dpkg -i $1 && rm $1; }     && install_deb_pkg libnvinfer9_9.3.0.1-1+cuda12.2_amd64.deb     && install_deb_pkg libnvinfer-headers-dev_9.3.0.1-1+cuda12.2_amd64.deb     && install_deb_pkg libnvinfer-dev_9.3.0.1-1+cuda12.2_amd64.deb     && install_deb_pkg libnvinfer-headers-plugin-dev_9.3.0.1-1+cuda12.2_amd64.deb     && install_deb_pkg libnvinfer-lean9_9.3.0.1-1+cuda12.2_amd64.deb     && install_deb_pkg libnvinfer-lean-dev_9.3.0.1-1+cuda12.2_amd64.deb     && install_deb_pkg libnvinfer-dispatch9_9.3.0.1-1+cuda12.2_amd64.deb     && install_deb_pkg libnvinfer-dispatch-dev_9.3.0.1-1+cuda12.2_amd64.deb     && install_deb_pkg libnvinfer-plugin9_9.3.0.1-1+cuda12.2_amd64.deb     && install_deb_pkg libnvinfer-plugin-dev_9.3.0.1-1+cuda12.2_amd64.deb     && install_deb_pkg libnvinfer-vc-plugin9_9.3.0.1-1+cuda12.2_amd64.deb     && install_deb_pkg libnvinfer-vc-plugin-dev_9.3.0.1-1+cuda12.2_amd64.deb     && install_deb_pkg libnvonnxparsers9_9.3.0.1-1+cuda12.2_amd64.deb     && install_deb_pkg libnvonnxparsers-dev_9.3.0.1-1+cuda12.2_amd64.deb     && install_deb_pkg python3-libnvinfer_9.3.0.1-1+cuda12.2_amd64.deb     && install_deb_pkg python3-libnvinfer-lean_9.3.0.1-1+cuda12.2_amd64.deb     && install_deb_pkg python3-libnvinfer-dispatch_9.3.0.1-1+cuda12.2_amd64.deb     && install_deb_pkg python3-libnvinfer-dev_9.3.0.1-1+cuda12.2_amd64.deb     && install_deb_pkg libnvinfer-bin_9.3.0.1-1+cuda12.2_amd64.deb     && ln -sf /usr/src/tensorrt/bin/trtexec /usr/bin/trtexec     && unset -f install_deb_pkg; fi; fi
#28 CACHED

#29 [15/40] RUN apt install -y libgtest-dev
#29 CACHED

#30 [34/40] RUN apt install -y openmpi-bin openmpi-common libopenmpi-dev
#30 CACHED

#31 [22/40] RUN if [[ 1 != 0 ]]; then     wget https://repo.anaconda.com/miniconda/Miniconda3-py38_23.5.2-0-Linux-x86_64.sh     && bash Miniconda3-py38_23.5.2-0-Linux-x86_64.sh -b -p /opt/miniconda3; fi
#31 CACHED

#32 [24/40] RUN if [ 1 = 0 ]; then     git clone -b rel-4.0-x86_64 https://gitlab-master.nvidia.com/yihengz/mlperf-internal-wheels.git --depth 1     && python3 -m pip install mlperf-internal-wheels/x86_64/*     && rm -rf mlperf-internal-wheels; fi
#32 CACHED

#33 [29/40] RUN echo 'deb http://archive.ubuntu.com/ubuntu focal main restricted universe multiverse' | tee -a /etc/apt/sources.list.d/focal.list     && echo 'Package: *\nPin: release a=focal\nPin-Priority: -10\n' | tee -a /etc/apt/preferences.d/focal.pref     && apt update     && apt install --no-install-recommends -t focal -y libjemalloc2 libtcmalloc-minimal4
#33 CACHED

#34 [ 9/40] RUN ln -sf /usr/bin/python3 /usr/bin/python
#34 CACHED

#35 [12/40] RUN apt install -y --no-install-recommends libsndfile1-dev
#35 CACHED

#36 [37/40] RUN mkdir -p /opt/fp8/faster-transformer-bert-fp8-weights-scales/     && tar -zxvf /tmp/faster-transformer-bert-fp8-weights-scales.tar.gz -C /opt/fp8/faster-transformer-bert-fp8-weights-scales/ --strip-components=6
#36 CACHED

#37 [ 7/40] RUN if [[ 1 = 0 ]]; then rm -rf /usr/local/lib/python3.8/dist-packages/tensorrt/; fi
#37 CACHED

#38 [19/40] RUN python3 -m pip install --upgrade pip  && python3 -m pip install --upgrade setuptools wheel virtualenv
#38 CACHED

#39 [23/40] RUN if [[ 1 != 0 ]]; then     conda config --env --set always_yes true     && conda install cmake ninja     && cd /tmp     && export CUDA_NVCC_EXECUTABLE="/usr/local/cuda/bin/nvcc"     && export CUDA_HOME="/usr/local/cuda"     && export CUDNN_INCLUDE_PATH="/usr/local/cuda/include/"     && export CUDNN_LIBRARY_PATH="/usr/local/cuda/lib64/"     && export LIBRARY_PATH="/usr/local/cuda/lib64/stubs:/usr/local/cuda/lib64"     && export USE_CUDA=1 USE_CUDNN=1     && export TORCH_CUDA_ARCH_LIST="Ampere Ada Hopper"     && export TORCH_CXX_FLAGS="-D_GLIBCXX_USE_CXX11_ABI=1"     && git clone -b v0.4.0 --recursive https://github.com/pytorch/kineto.git     && mkdir kineto/libkineto/build     && cd kineto/libkineto/build     && cmake ..     && make     && make install     && cd -     && cd /tmp     && export CUDA_NVCC_EXECUTABLE="/usr/local/cuda/bin/nvcc"     && export CUDA_HOME="/usr/local/cuda"     && export CUDNN_INCLUDE_PATH="/usr/local/cuda/include/"     && export CUDNN_LIBRARY_PATH="/usr/local/cuda/lib64/"     && export LIBRARY_PATH="/usr/local/cuda/lib64/stubs:/usr/local/cuda/lib64"     && export USE_CUDA=1 USE_CUDNN=1     && export TORCH_CUDA_ARCH_LIST="Ampere Ada Hopper"     && export TORCH_CXX_FLAGS="-D_GLIBCXX_USE_CXX11_ABI=1"     && git clone https://github.com/pytorch/pytorch     && cd pytorch && git checkout -f 32f93b1     && git submodule update --init --recursive     && python3 -m pip install -r requirements.txt     && python setup.py bdist_wheel     && cd dist     && python3 -m pip install torch-2.1*linux_x86_64.whl     && cd -     && cd /tmp     && export CUDA_NVCC_EXECUTABLE="/usr/local/cuda/bin/nvcc"     && export CUDA_HOME="/usr/local/cuda"     && export CUDNN_INCLUDE_PATH="/usr/local/cuda/include/"     && export CUDNN_LIBRARY_PATH="/usr/local/cuda/lib64/"     && export LIBRARY_PATH="/usr/local/cuda/lib64/stubs:/usr/local/cuda/lib64"     && export USE_CUDA=1 USE_CUDNN=1     && export TORCH_CUDA_ARCH_LIST="Ampere Ada Hopper"     && export TORCH_CXX_FLAGS="-D_GLIBCXX_USE_CXX11_ABI=1"     && git clone https://github.com/pytorch/vision.git     && cd vision && git checkout -f 657027f3     && python setup.py bdist_wheel     && cd dist     && python3 -m pip install torchvision-0.16*linux_x86_64.whl     && cd -     && conda config --env --remove-key always_yes; fi
#39 CACHED

#40 [ 2/40] RUN rm -f /etc/apt/sources.list.d/cuda.list  && apt update  && apt install -y --no-install-recommends build-essential autoconf libtool git git-lfs         ccache curl wget pkg-config sudo ca-certificates automake libssl-dev         bc python3-dev python3-pip google-perftools gdb libglib2.0-dev clang sshfs libre2-dev         libboost-dev libnuma-dev numactl sysstat sshpass ntpdate less vim iputils-ping pybind11-dev  && apt install --only-upgrade libksba8  && apt remove -y cmake  && apt remove -y libgflags-dev  && apt remove -y libprotobuf-dev  && apt -y autoremove
#40 CACHED

#41 [14/40] RUN apt install -y libb64-dev
#41 CACHED

#42 [25/40] RUN python3 -m pip install apex@git+https://github.com/nvidia/apex@0da3ffb92ee6fbe5336602f0e3989db1cd16f880
#42 CACHED

#43 [ 5/40] RUN apt install -y --no-install-recommends rsync
#43 CACHED

#44 [40/40] WORKDIR /work
#44 CACHED

#45 exporting to image
#45 exporting layers done
#45 writing image sha256:cca0602eda6ca38ccaa823947adfd97da8d7267dfdc7474d4e69a28a46254816 done
#45 naming to docker.io/library/mlperf-inference:yhara-x86_64-latest done
#45 DONE 0.0s
make[1]: Leaving directory '/mnt/data4/work/home/yhara/inference_v4.0/closed/Fujitsu'
make[1]: Entering directory '/mnt/data4/work/home/yhara/inference_v4.0/closed/Fujitsu'
make[2]: Entering directory '/mnt/data4/work/home/yhara/inference_v4.0/closed/Fujitsu'
Adding user account into image
DOCKER_BUILDKIT=1 docker build -t mlperf-inference:yhara-x86_64 --network host \
	--build-arg BASE_IMAGE=mlperf-inference:yhara-x86_64-latest \
	--build-arg GID=1002 --build-arg UID=1002 --build-arg GROUP=yhara --build-arg USER=yhara \
	- < docker/Dockerfile.user
#0 building with "default" instance using docker driver

#1 [internal] load build definition from Dockerfile
#1 transferring dockerfile: 1.05kB done
#1 DONE 0.0s

#2 [internal] load .dockerignore
#2 transferring context: 2B done
#2 DONE 0.0s

#3 [internal] load metadata for docker.io/library/mlperf-inference:yhara-x86_64-latest
#3 DONE 0.0s

#4 [1/2] FROM docker.io/library/mlperf-inference:yhara-x86_64-latest
#4 DONE 0.0s

#5 [2/2] RUN echo root:root | chpasswd  && groupadd -f -g 1002 yhara  && useradd -G sudo -g 1002 -u 1002 -m yhara  && echo yhara:yhara | chpasswd  && echo -e "\nexport PS1="(mlperf) \u@\h:\w\$ "" | tee -a /home/yhara/.bashrc  && echo -e "\n%sudo ALL=(ALL:ALL) NOPASSWD:ALL\n" | tee -a /etc/sudoers
#5 CACHED

#6 exporting to image
#6 exporting layers done
#6 writing image sha256:d9f9538cf8cd74d3a27cc4a0f96c48dc3fc8dead013aeedf4f7a8d28ba030b21 done
#6 naming to docker.io/library/mlperf-inference:yhara-x86_64 done
#6 DONE 0.0s
make[2]: Leaving directory '/mnt/data4/work/home/yhara/inference_v4.0/closed/Fujitsu'
make[2]: Entering directory '/mnt/data4/work/home/yhara/inference_v4.0/closed/Fujitsu'
/bin/bash: line 1: [: ==: unary operator expected
/bin/bash: line 1: [: !=: unary operator expected
nvidia-docker run --rm -it -w /work \
	-v /mnt/data4/work/home/yhara/inference_v4.0/closed/Fujitsu:/work -v /home/yhara:/mnt//home/yhara \
	--cap-add SYS_ADMIN --cap-add SYS_TIME \
	-e NVIDIA_VISIBLE_DEVICES=all \
	-e HISTFILE=/mnt//home/yhara/.mlperf_bash_history \
	--shm-size=32gb \
	--ulimit memlock=-1 \
	-v /etc/timezone:/etc/timezone:ro -v /etc/localtime:/etc/localtime:ro \
	--security-opt apparmor=unconfined --security-opt seccomp=unconfined \
	--name mlperf-inference-yhara-x86_64-8374 -h mlperf-inference-yhara-x86-64-8374 --add-host mlperf-inference-yhara-x86_64-8374:127.0.0.1 \
	--cpuset-cpus 0-95 \
	--user 1002 --net host --device /dev/fuse \
	-v /mnt/data4/work/inference_scratch:/mnt/data4/work/inference_scratch  \
	-e MLPERF_SCRATCH_PATH=/mnt/data4/work/inference_scratch \
	-e HOST_HOSTNAME=mlperf-measure2 \
	 \
	mlperf-inference:yhara-x86_64 

==========
== CUDA ==
==========

To run a command as administrator (user "root"), use "sudo <command>".
See "man sudo_root" for details.

(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work$ export
declare -x CUDA_VERSION="12.2.2"
declare -x DEBIAN_FRONTEND="noninteractive"
declare -x HISTFILE="/mnt//home/yhara/.mlperf_bash_history"
declare -x HOME="/home/yhara"
declare -x HOSTNAME="mlperf-inference-yhara-x86-64-8374"
declare -x HOST_HOSTNAME="mlperf-measure2"
declare -x LANG="C.UTF-8"
declare -x LC_ALL="C.UTF-8"
declare -x LD_LIBRARY_PATH="/usr/local/nvidia/lib:/usr/local/nvidia/lib64"
declare -x LESSCLOSE="/usr/bin/lesspipe %s %s"
declare -x LESSOPEN="| /usr/bin/lesspipe %s"
declare -x LIBRARY_PATH="/usr/local/cuda/lib64/stubs"
declare -x LS_COLORS="rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:"
declare -x MLPERF_SCRATCH_PATH="/mnt/data4/work/inference_scratch"
declare -x NCCL_VERSION="2.19.3-1"
declare -x NVARCH="x86_64"
declare -x NVIDIA_DRIVER_CAPABILITIES="compute,utility"
declare -x NVIDIA_PRODUCT_NAME="CUDA"
declare -x NVIDIA_REQUIRE_CUDA="cuda>=12.2 brand=tesla,driver>=470,driver<471 brand=unknown,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=geforce,driver>=470,driver<471 brand=geforcertx,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=titan,driver>=470,driver<471 brand=titanrtx,driver>=470,driver<471 brand=tesla,driver>=525,driver<526 brand=unknown,driver>=525,driver<526 brand=nvidia,driver>=525,driver<526 brand=nvidiartx,driver>=525,driver<526 brand=geforce,driver>=525,driver<526 brand=geforcertx,driver>=525,driver<526 brand=quadro,driver>=525,driver<526 brand=quadrortx,driver>=525,driver<526 brand=titan,driver>=525,driver<526 brand=titanrtx,driver>=525,driver<526"
declare -x NVIDIA_VISIBLE_DEVICES="all"
declare -x NV_CUDA_COMPAT_PACKAGE="cuda-compat-12-2"
declare -x NV_CUDA_CUDART_DEV_VERSION="12.2.140-1"
declare -x NV_CUDA_CUDART_VERSION="12.2.140-1"
declare -x NV_CUDA_LIB_VERSION="12.2.2-1"
declare -x NV_CUDA_NSIGHT_COMPUTE_DEV_PACKAGE="cuda-nsight-compute-12-2=12.2.2-1"
declare -x NV_CUDA_NSIGHT_COMPUTE_VERSION="12.2.2-1"
declare -x NV_LIBCUBLAS_DEV_PACKAGE="libcublas-dev-12-2=12.2.5.6-1"
declare -x NV_LIBCUBLAS_DEV_PACKAGE_NAME="libcublas-dev-12-2"
declare -x NV_LIBCUBLAS_DEV_VERSION="12.2.5.6-1"
declare -x NV_LIBCUBLAS_PACKAGE="libcublas-12-2=12.2.5.6-1"
declare -x NV_LIBCUBLAS_PACKAGE_NAME="libcublas-12-2"
declare -x NV_LIBCUBLAS_VERSION="12.2.5.6-1"
declare -x NV_LIBCUSPARSE_DEV_VERSION="12.1.2.141-1"
declare -x NV_LIBCUSPARSE_VERSION="12.1.2.141-1"
declare -x NV_LIBNCCL_DEV_PACKAGE="libnccl-dev=2.19.3-1+cuda12.2"
declare -x NV_LIBNCCL_DEV_PACKAGE_NAME="libnccl-dev"
declare -x NV_LIBNCCL_DEV_PACKAGE_VERSION="2.19.3-1"
declare -x NV_LIBNCCL_PACKAGE="libnccl2=2.19.3-1+cuda12.2"
declare -x NV_LIBNCCL_PACKAGE_NAME="libnccl2"
declare -x NV_LIBNCCL_PACKAGE_VERSION="2.19.3-1"
declare -x NV_LIBNPP_DEV_PACKAGE="libnpp-dev-12-2=12.2.1.4-1"
declare -x NV_LIBNPP_DEV_VERSION="12.2.1.4-1"
declare -x NV_LIBNPP_PACKAGE="libnpp-12-2=12.2.1.4-1"
declare -x NV_LIBNPP_VERSION="12.2.1.4-1"
declare -x NV_NVML_DEV_VERSION="12.2.140-1"
declare -x NV_NVPROF_DEV_PACKAGE="cuda-nvprof-12-2=12.2.142-1"
declare -x NV_NVPROF_VERSION="12.2.142-1"
declare -x NV_NVTX_VERSION="12.2.140-1"
declare -x OLDPWD
declare -x PATH="/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/miniconda3/bin"
declare -x PS1="(mlperf) \\u@\\h:\\w\$ "
declare -x PWD="/work"
declare -x SHLVL="1"
declare -x TERM="xterm"
declare -x TZ="ETC/UTC"
declare -x http_proxy="http://empllinux:1234567890@rep2-ng.proxy.nic.fujitsu.com:8080"
declare -x https_proxy="http://empllinux:1234567890@rep2-ng.proxy.nic.fujitsu.com:8080"
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work$  export SUBMITTER=Fujitsu
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work$ export
declare -x CUDA_VERSION="12.2.2"
declare -x DEBIAN_FRONTEND="noninteractive"
declare -x HISTFILE="/mnt//home/yhara/.mlperf_bash_history"
declare -x HOME="/home/yhara"
declare -x HOSTNAME="mlperf-inference-yhara-x86-64-8374"
declare -x HOST_HOSTNAME="mlperf-measure2"
declare -x LANG="C.UTF-8"
declare -x LC_ALL="C.UTF-8"
declare -x LD_LIBRARY_PATH="/usr/local/nvidia/lib:/usr/local/nvidia/lib64"
declare -x LESSCLOSE="/usr/bin/lesspipe %s %s"
declare -x LESSOPEN="| /usr/bin/lesspipe %s"
declare -x LIBRARY_PATH="/usr/local/cuda/lib64/stubs"
declare -x LS_COLORS="rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:"
declare -x MLPERF_SCRATCH_PATH="/mnt/data4/work/inference_scratch"
declare -x NCCL_VERSION="2.19.3-1"
declare -x NVARCH="x86_64"
declare -x NVIDIA_DRIVER_CAPABILITIES="compute,utility"
declare -x NVIDIA_PRODUCT_NAME="CUDA"
declare -x NVIDIA_REQUIRE_CUDA="cuda>=12.2 brand=tesla,driver>=470,driver<471 brand=unknown,driver>=470,driver<471 brand=nvidia,driver>=470,driver<471 brand=nvidiartx,driver>=470,driver<471 brand=geforce,driver>=470,driver<471 brand=geforcertx,driver>=470,driver<471 brand=quadro,driver>=470,driver<471 brand=quadrortx,driver>=470,driver<471 brand=titan,driver>=470,driver<471 brand=titanrtx,driver>=470,driver<471 brand=tesla,driver>=525,driver<526 brand=unknown,driver>=525,driver<526 brand=nvidia,driver>=525,driver<526 brand=nvidiartx,driver>=525,driver<526 brand=geforce,driver>=525,driver<526 brand=geforcertx,driver>=525,driver<526 brand=quadro,driver>=525,driver<526 brand=quadrortx,driver>=525,driver<526 brand=titan,driver>=525,driver<526 brand=titanrtx,driver>=525,driver<526"
declare -x NVIDIA_VISIBLE_DEVICES="all"
declare -x NV_CUDA_COMPAT_PACKAGE="cuda-compat-12-2"
declare -x NV_CUDA_CUDART_DEV_VERSION="12.2.140-1"
declare -x NV_CUDA_CUDART_VERSION="12.2.140-1"
declare -x NV_CUDA_LIB_VERSION="12.2.2-1"
declare -x NV_CUDA_NSIGHT_COMPUTE_DEV_PACKAGE="cuda-nsight-compute-12-2=12.2.2-1"
declare -x NV_CUDA_NSIGHT_COMPUTE_VERSION="12.2.2-1"
declare -x NV_LIBCUBLAS_DEV_PACKAGE="libcublas-dev-12-2=12.2.5.6-1"
declare -x NV_LIBCUBLAS_DEV_PACKAGE_NAME="libcublas-dev-12-2"
declare -x NV_LIBCUBLAS_DEV_VERSION="12.2.5.6-1"
declare -x NV_LIBCUBLAS_PACKAGE="libcublas-12-2=12.2.5.6-1"
declare -x NV_LIBCUBLAS_PACKAGE_NAME="libcublas-12-2"
declare -x NV_LIBCUBLAS_VERSION="12.2.5.6-1"
declare -x NV_LIBCUSPARSE_DEV_VERSION="12.1.2.141-1"
declare -x NV_LIBCUSPARSE_VERSION="12.1.2.141-1"
declare -x NV_LIBNCCL_DEV_PACKAGE="libnccl-dev=2.19.3-1+cuda12.2"
declare -x NV_LIBNCCL_DEV_PACKAGE_NAME="libnccl-dev"
declare -x NV_LIBNCCL_DEV_PACKAGE_VERSION="2.19.3-1"
declare -x NV_LIBNCCL_PACKAGE="libnccl2=2.19.3-1+cuda12.2"
declare -x NV_LIBNCCL_PACKAGE_NAME="libnccl2"
declare -x NV_LIBNCCL_PACKAGE_VERSION="2.19.3-1"
declare -x NV_LIBNPP_DEV_PACKAGE="libnpp-dev-12-2=12.2.1.4-1"
declare -x NV_LIBNPP_DEV_VERSION="12.2.1.4-1"
declare -x NV_LIBNPP_PACKAGE="libnpp-12-2=12.2.1.4-1"
declare -x NV_LIBNPP_VERSION="12.2.1.4-1"
declare -x NV_NVML_DEV_VERSION="12.2.140-1"
declare -x NV_NVPROF_DEV_PACKAGE="cuda-nvprof-12-2=12.2.142-1"
declare -x NV_NVPROF_VERSION="12.2.142-1"
declare -x NV_NVTX_VERSION="12.2.140-1"
declare -x OLDPWD
declare -x PATH="/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/miniconda3/bin"
declare -x PS1="(mlperf) \\u@\\h:\\w\$ "
declare -x PWD="/work"
declare -x SHLVL="1"
declare -x SUBMITTER="Fujitsu"
declare -x TERM="xterm"
declare -x TZ="ETC/UTC"
declare -x http_proxy="http://empllinux:1234567890@rep2-ng.proxy.nic.fujitsu.com:8080"
declare -x https_proxy="http://empllinux:1234567890@rep2-ng.proxy.nic.fujitsu.com:8080"
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work$ make build 2>&1 | tee make_build_00.log
Cloning Official MLPerf Inference (For Loadgen Files)
Cloning into '/work/build/inference'...
Updating Loadgen
Note: switching to '0ed5190e82e1ca1cf95626e50e61cb6678c7f2ff'.

You are in 'detached HEAD' state. You can look around, make experimental
changes and commit them, and you can discard any commits you make in this
state without impacting any branches by switching back to a branch.

If you want to create a new branch to retain commits you create, you may
do so (now or later) by using -c with the switch command. Example:

  git switch -c <new-branch-name>

Or undo this operation with:

  git switch -

Turn off this advice by setting config variable advice.detachedHead to false

HEAD is now at 0ed5190 Fix submission checker and TEST06 for Llama2 (#1616)
Submodule 'language/bert/DeepLearningExamples' (https://github.com/NVIDIA/DeepLearningExamples.git) registered for path 'language/bert/DeepLearningExamples'
Cloning into '/work/build/inference/language/bert/DeepLearningExamples'...
Submodule path 'language/bert/DeepLearningExamples': checked out 'b03375bd6c2c5233130e61a3be49e26d1a20ac7c'
Submodule 'vision/medical_imaging/3d-unet-brats19/nnUnet' (https://github.com/MIC-DKFZ/nnUNet.git) registered for path 'vision/medical_imaging/3d-unet-brats19/nnUnet'
Cloning into '/work/build/inference/vision/medical_imaging/3d-unet-brats19/nnUnet'...
Submodule path 'vision/medical_imaging/3d-unet-brats19/nnUnet': checked out 'b38c69b345b2f60cd0d053039669e8f988b0c0af'
Cloning Official Power-Dev repo
Cloning into '/work/build/power-dev'...
Updating Power-Dev repo
Note: switching to 'f5ee305a867b24905fea1f04f1b68819d392a731'.

You are in 'detached HEAD' state. You can look around, make experimental
changes and commit them, and you can discard any commits you make in this
state without impacting any branches by switching back to a branch.

If you want to create a new branch to retain commits you create, you may
do so (now or later) by using -c with the switch command. Example:

  git switch -c <new-branch-name>

Or undo this operation with:

  git switch -

Turn off this advice by setting config variable advice.detachedHead to false

HEAD is now at f5ee305 Merge pull request #325 from krai/fix-power-whitespace
make[1]: Entering directory '/work'
mkdir -p build/plugins/NMSOptPlugin
cd build/plugins/NMSOptPlugin\
	&& cmake -DCMAKE_BUILD_TYPE=Release /work/code/plugin/NMSOptPlugin \
	&& make -j
-- The CXX compiler identification is GNU 9.4.0
-- The CUDA compiler identification is NVIDIA 12.2.140
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Detecting CUDA compiler ABI info
-- Detecting CUDA compiler ABI info - done
-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped
-- Detecting CUDA compile features
-- Detecting CUDA compile features - done
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed
-- Looking for pthread_create in pthreads
-- Looking for pthread_create in pthreads - not found
-- Looking for pthread_create in pthread
-- Looking for pthread_create in pthread - found
-- Found Threads: TRUE  
-- Found CUDA: /usr/local/cuda (found version "12.2") 

The following variables are derived from the values of the previous variables unless provided explicitly:

-- Configuring done
CMake Warning (dev) in CMakeLists.txt:
  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,
  empty CUDA_ARCHITECTURES not allowed.  Run "cmake --help-policy CMP0104"
  for policy details.  Use the cmake_policy command to set the policy and
  suppress this warning.

  CUDA_ARCHITECTURES is empty for target "nmsoptplugin".
This warning is for project developers.  Use -Wno-dev to suppress it.

-- Generating done
-- Build files have been written to: /work/build/plugins/NMSOptPlugin
make[2]: Entering directory '/work/build/plugins/NMSOptPlugin'
make[3]: Entering directory '/work/build/plugins/NMSOptPlugin'
make[4]: Entering directory '/work/build/plugins/NMSOptPlugin'
make[4]: Leaving directory '/work/build/plugins/NMSOptPlugin'
make[4]: Entering directory '/work/build/plugins/NMSOptPlugin'
[  7%] Building CUDA object CMakeFiles/nmsoptplugin.dir/src/allClassNMSOpt.cu.o
[ 14%] Building CUDA object CMakeFiles/nmsoptplugin.dir/src/decodeBBoxesOpt.cu.o
[ 21%] Building CUDA object CMakeFiles/nmsoptplugin.dir/src/detectionForwardOpt.cu.o
[ 28%] Building CUDA object CMakeFiles/nmsoptplugin.dir/src/gatherTopDetectionsOpt.cu.o
[ 35%] Building CUDA object CMakeFiles/nmsoptplugin.dir/src/nms_common.cu.o
[ 42%] Building CUDA object CMakeFiles/nmsoptplugin.dir/src/permuteConfData.cu.o
[ 50%] Building CUDA object CMakeFiles/nmsoptplugin.dir/src/topK.cu.o
[ 64%] Building CUDA object CMakeFiles/nmsoptplugin.dir/src/topKScoresPerClassFusedPermute.cu.o
[ 64%] Building CUDA object CMakeFiles/nmsoptplugin.dir/src/topKScoresPerClass.cu.o
[ 71%] Building CUDA object CMakeFiles/nmsoptplugin.dir/src/topKScoresPerImage.cu.o
[ 85%] Building CXX object CMakeFiles/nmsoptplugin.dir/src/nmsOptHelper.cpp.o
[ 92%] Building CXX object CMakeFiles/nmsoptplugin.dir/src/nmsPluginOpt.cpp.o
[ 92%] Building CXX object CMakeFiles/nmsoptplugin.dir/src/softmaxScore.cpp.o
/work/code/plugin/NMSOptPlugin/src/softmaxScore.cpp: In function ‘ssdStatus_t nvinfer1::plugin::softmaxScore(cudaStream_t, int, int, int, int, DType_t, const void*, void*, cudnnHandle_t, cudnnTensorDescriptor_t, cudnnTensorDescriptor_t)’:
/work/code/plugin/NMSOptPlugin/src/softmaxScore.cpp:43:19: warning: variable ‘status’ set but not used [-Wunused-but-set-variable]
   43 |     cudnnStatus_t status;
      |                   ^~~~~~
In file included from /work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.cpp:26:
/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.cpp: In instantiation of ‘void nvinfer1::plugin::DetectionOutputOpt<T>::configurePluginBase(const nvinfer1::PluginTensorDesc*, int, const nvinfer1::PluginTensorDesc*, int) [with T = nvinfer1::IPluginV2IOExt]’:
/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.cpp:416:53:   required from here
/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.cpp:392:58: warning: suggest parentheses around ‘&&’ within ‘||’ [-Wparentheses]
  392 |                 ASSERT(confInputType == DataType::kFLOAT && confInputFormat == TensorFormat::kLINEAR
      |                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/work/code/plugin/NMSOptPlugin/src/ssdOptMacros.h:37:15: note: in definition of macro ‘ASSERT’
   37 |         if (!(assertion))                                              \
      |               ^~~~~~~~~
/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.cpp: In instantiation of ‘void nvinfer1::plugin::DetectionOutputOpt<T>::configurePluginBase(const nvinfer1::PluginTensorDesc*, int, const nvinfer1::PluginTensorDesc*, int) [with T = nvinfer1::IPluginV2DynamicExt]’:
/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.cpp:426:75:   required from here
/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.cpp:392:58: warning: suggest parentheses around ‘&&’ within ‘||’ [-Wparentheses]
  392 |                 ASSERT(confInputType == DataType::kFLOAT && confInputFormat == TensorFormat::kLINEAR
      |                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/work/code/plugin/NMSOptPlugin/src/ssdOptMacros.h:37:15: note: in definition of macro ‘ASSERT’
   37 |         if (!(assertion))                                              \
      |               ^~~~~~~~~
/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.cpp: In instantiation of ‘bool nvinfer1::plugin::DetectionOutputOpt<T>::supportsFormatCombinationBase(int, const nvinfer1::PluginTensorDesc*, int, int) const [with T = nvinfer1::IPluginV2IOExt]’:
/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.cpp:485:73:   required from here
/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.cpp:445:51: warning: suggest parentheses around ‘&&’ within ‘||’ [-Wparentheses]
  445 |         rtn = inOut[pos].type == DataType::kFLOAT && (inOut[pos].format == TensorFormat::kLINEAR)
/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.cpp: In instantiation of ‘bool nvinfer1::plugin::DetectionOutputOpt<T>::supportsFormatCombinationBase(int, const nvinfer1::PluginTensorDesc*, int, int) const [with T = nvinfer1::IPluginV2DynamicExt]’:
/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.cpp:491:73:   required from here
/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.cpp:445:51: warning: suggest parentheses around ‘&&’ within ‘||’ [-Wparentheses]
/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(115): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const bool *, const bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptStatic::configurePlugin" -- virtual function override intended?
      void configurePlugin(
           ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(132): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(138): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::getWorkspaceSize" -- virtual function override intended?
      size_t getWorkspaceSize(const PluginTensorDesc* inputs, int nbInputs, const PluginTensorDesc* outputs,
             ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(140): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::enqueue" -- virtual function override intended?
      int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc, const void* const* inputs,
          ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(136): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const bool *, const bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int nbInputs, const DynamicPluginTensorDesc* out,
           ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(115): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptStatic::configurePlugin" -- virtual function override intended?
      void configurePlugin(
           ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(132): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(138): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::getWorkspaceSize" -- virtual function override intended?
      size_t getWorkspaceSize(const PluginTensorDesc* inputs, int nbInputs, const PluginTensorDesc* outputs,
             ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(140): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::enqueue" -- virtual function override intended?
      int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc, const void* const* inputs,
          ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(136): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int nbInputs, const DynamicPluginTensorDesc* out,
           ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(115): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptStatic::configurePlugin" -- virtual function override intended?
      void configurePlugin(
           ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(132): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(138): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::getWorkspaceSize" -- virtual function override intended?
      size_t getWorkspaceSize(const PluginTensorDesc* inputs, int nbInputs, const PluginTensorDesc* outputs,
             ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(140): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::enqueue" -- virtual function override intended?
      int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc, const void* const* inputs,
          ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(136): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int nbInputs, const DynamicPluginTensorDesc* out,
           ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(115): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptStatic::configurePlugin" -- virtual function override intended?
      void configurePlugin(
           ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(132): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(138): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::getWorkspaceSize" -- virtual function override intended?
      size_t getWorkspaceSize(const PluginTensorDesc* inputs, int nbInputs, const PluginTensorDesc* outputs,
             ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(140): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::enqueue" -- virtual function override intended?
      int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc, const void* const* inputs,
          ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(136): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int nbInputs, const DynamicPluginTensorDesc* out,
           ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(115): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptStatic::configurePlugin" -- virtual function override intended?
      void configurePlugin(
           ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(132): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(138): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::getWorkspaceSize" -- virtual function override intended?
      size_t getWorkspaceSize(const PluginTensorDesc* inputs, int nbInputs, const PluginTensorDesc* outputs,
             ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(140): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::enqueue" -- virtual function override intended?
      int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc, const void* const* inputs,
          ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h(136): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::DetectionOutputOptDynamic::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int nbInputs, const DynamicPluginTensorDesc* out,
           ^

/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h:101:46: warning: ‘IPluginV2Ext’ is deprecated [-Wdeprecated-declarations]
  101 |     IPluginV2Ext* clone() const noexcept override;
      |                                              ^~~~~   
/usr/include/x86_64-linux-gnu/NvInferRuntimePlugin.h:447:22: note: declared here
  447 | class TRT_DEPRECATED IPluginV2Ext : public IPluginV2
      |                      ^~~~~~~~~~~~
/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h:158:95: warning: ‘IPluginV2’ is deprecated [-Wdeprecated-declarations]
  158 |     IPluginV2* createPlugin(const char* name, const PluginFieldCollection* fc) noexcept override;
      |                                                                                               ^~~     
/usr/include/x86_64-linux-gnu/NvInferRuntimePlugin.h:117:22: note: declared here
  117 | class TRT_DEPRECATED IPluginV2
      |                      ^~~~~~~~~
/work/code/plugin/NMSOptPlugin/src/nmsPluginOpt.h:160:112: warning: ‘IPluginV2’ is deprecated [-Wdeprecated-declarations]
  160 |     IPluginV2* deserializePlugin(const char* name, const void* serialData, size_t serialLength) noexcept override;
      |                                                                                                                ^~~     
/usr/include/x86_64-linux-gnu/NvInferRuntimePlugin.h:117:22: note: declared here
  117 | class TRT_DEPRECATED IPluginV2
      |                      ^~~~~~~~~
[100%] Linking CXX shared module libnmsoptplugin.so
make[4]: Leaving directory '/work/build/plugins/NMSOptPlugin'
[100%] Built target nmsoptplugin
make[3]: Leaving directory '/work/build/plugins/NMSOptPlugin'
make[2]: Leaving directory '/work/build/plugins/NMSOptPlugin'
mkdir -p build/plugins/RNNTOptPlugin
cd build/plugins/RNNTOptPlugin\
	&& cmake -DCMAKE_BUILD_TYPE=Release /work/code/plugin/RNNTOptPlugin \
	&& make -j
-- The CXX compiler identification is GNU 9.4.0
-- The CUDA compiler identification is NVIDIA 12.2.140
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Detecting CUDA compiler ABI info
-- Detecting CUDA compiler ABI info - done
-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped
-- Detecting CUDA compile features
-- Detecting CUDA compile features - done
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed
-- Looking for pthread_create in pthreads
-- Looking for pthread_create in pthreads - not found
-- Looking for pthread_create in pthread
-- Looking for pthread_create in pthread - found
-- Found Threads: TRUE  
-- Found CUDA: /usr/local/cuda (found version "12.2") 
-- Configuring done
CMake Warning (dev) in CMakeLists.txt:
  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,
  empty CUDA_ARCHITECTURES not allowed.  Run "cmake --help-policy CMP0104"
  for policy details.  Use the cmake_policy command to set the policy and
  suppress this warning.

  CUDA_ARCHITECTURES is empty for target "rnntoptplugin".
This warning is for project developers.  Use -Wno-dev to suppress it.

CMake Warning (dev) in CMakeLists.txt:
  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,
  empty CUDA_ARCHITECTURES not allowed.  Run "cmake --help-policy CMP0104"
  for policy details.  Use the cmake_policy command to set the policy and
  suppress this warning.

  CUDA_ARCHITECTURES is empty for target "rnntoptplugin".
This warning is for project developers.  Use -Wno-dev to suppress it.

CMake Warning (dev) in CMakeLists.txt:
  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,
  empty CUDA_ARCHITECTURES not allowed.  Run "cmake --help-policy CMP0104"
  for policy details.  Use the cmake_policy command to set the policy and
  suppress this warning.

  CUDA_ARCHITECTURES is empty for target "rnntoptplugin".
This warning is for project developers.  Use -Wno-dev to suppress it.

-- Generating done
-- Build files have been written to: /work/build/plugins/RNNTOptPlugin
make[2]: Entering directory '/work/build/plugins/RNNTOptPlugin'
make[3]: Entering directory '/work/build/plugins/RNNTOptPlugin'
make[4]: Entering directory '/work/build/plugins/RNNTOptPlugin'
make[4]: Leaving directory '/work/build/plugins/RNNTOptPlugin'
make[4]: Entering directory '/work/build/plugins/RNNTOptPlugin'
[ 50%] Building CUDA object CMakeFiles/rnntoptplugin.dir/src/select3Plugin.cu.o
[ 50%] Building CUDA object CMakeFiles/rnntoptplugin.dir/src/decoderPlugin.cu.o
/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(69): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(71): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::getWorkspaceSize" -- virtual function override intended?
      virtual size_t getWorkspaceSize(const PluginTensorDesc* inputs, int nbInputs, const PluginTensorDesc* outputs,
                     ^

/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(73): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::enqueue" -- virtual function override intended?
      virtual int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc,
                  ^

/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(65): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const bool *, const bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int nbInputs, const DynamicPluginTensorDesc* out,
           ^

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(66): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(72): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::getWorkspaceSize" -- virtual function override intended?
      virtual size_t getWorkspaceSize(const PluginTensorDesc* inputs, int32_t nbInputs, const PluginTensorDesc* outputs,
                     ^

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(74): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::enqueue" -- virtual function override intended?
      virtual int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc,
                  ^

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(70): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const bool *, const bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int32_t nbInputs, const DynamicPluginTensorDesc* out,
           ^

/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(69): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(71): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::getWorkspaceSize" -- virtual function override intended?
      virtual size_t getWorkspaceSize(const PluginTensorDesc* inputs, int nbInputs, const PluginTensorDesc* outputs,
                     ^

/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(73): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::enqueue" -- virtual function override intended?
      virtual int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc,
                  ^

/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(65): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int nbInputs, const DynamicPluginTensorDesc* out,
           ^

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(66): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(72): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::getWorkspaceSize" -- virtual function override intended?
      virtual size_t getWorkspaceSize(const PluginTensorDesc* inputs, int32_t nbInputs, const PluginTensorDesc* outputs,
                     ^

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(74): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::enqueue" -- virtual function override intended?
      virtual int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc,
                  ^

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(70): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int32_t nbInputs, const DynamicPluginTensorDesc* out,
           ^

/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(69): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(71): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::getWorkspaceSize" -- virtual function override intended?
      virtual size_t getWorkspaceSize(const PluginTensorDesc* inputs, int nbInputs, const PluginTensorDesc* outputs,
                     ^

/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(73): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::enqueue" -- virtual function override intended?
      virtual int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc,
                  ^

/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(65): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int nbInputs, const DynamicPluginTensorDesc* out,
           ^

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(66): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(72): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::getWorkspaceSize" -- virtual function override intended?
      virtual size_t getWorkspaceSize(const PluginTensorDesc* inputs, int32_t nbInputs, const PluginTensorDesc* outputs,
                     ^

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(74): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::enqueue" -- virtual function override intended?
      virtual int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc,
                  ^

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(70): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int32_t nbInputs, const DynamicPluginTensorDesc* out,
           ^

/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(69): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(71): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::getWorkspaceSize" -- virtual function override intended?
      virtual size_t getWorkspaceSize(const PluginTensorDesc* inputs, int nbInputs, const PluginTensorDesc* outputs,
                     ^

/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(73): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::enqueue" -- virtual function override intended?
      virtual int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc,
                  ^

/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(65): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int nbInputs, const DynamicPluginTensorDesc* out,
           ^

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(66): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(72): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::getWorkspaceSize" -- virtual function override intended?
      virtual size_t getWorkspaceSize(const PluginTensorDesc* inputs, int32_t nbInputs, const PluginTensorDesc* outputs,
                     ^

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(74): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::enqueue" -- virtual function override intended?
      virtual int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc,
                  ^

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(70): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int32_t nbInputs, const DynamicPluginTensorDesc* out,
           ^

/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(69): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(71): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::getWorkspaceSize" -- virtual function override intended?
      virtual size_t getWorkspaceSize(const PluginTensorDesc* inputs, int nbInputs, const PluginTensorDesc* outputs,
                     ^

/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(73): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::enqueue" -- virtual function override intended?
      virtual int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc,
                  ^

/work/code/plugin/RNNTOptPlugin/src/select3Plugin.h(65): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::RNNTSelectPlugin::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int nbInputs, const DynamicPluginTensorDesc* out,
           ^

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(66): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(72): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::getWorkspaceSize" -- virtual function override intended?
      virtual size_t getWorkspaceSize(const PluginTensorDesc* inputs, int32_t nbInputs, const PluginTensorDesc* outputs,
                     ^

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(74): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::enqueue" -- virtual function override intended?
      virtual int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc,
                  ^

/work/code/plugin/RNNTOptPlugin/src/decoderPlugin.h(70): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::RNNTDecoderPlugin::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int32_t nbInputs, const DynamicPluginTensorDesc* out,
           ^

[ 75%] Linking CUDA device code CMakeFiles/rnntoptplugin.dir/cmake_device_link.o
[100%] Linking CUDA shared module librnntoptplugin.so
make[4]: Leaving directory '/work/build/plugins/RNNTOptPlugin'
[100%] Built target rnntoptplugin
make[3]: Leaving directory '/work/build/plugins/RNNTOptPlugin'
make[2]: Leaving directory '/work/build/plugins/RNNTOptPlugin'
mkdir -p build/plugins/pixelShuffle3DPlugin
cd build/plugins/pixelShuffle3DPlugin\
	&& cmake -DCMAKE_BUILD_TYPE=Release /work/code/plugin/pixelShuffle3DPlugin \
	&& make -j
-- The CXX compiler identification is GNU 9.4.0
-- The CUDA compiler identification is NVIDIA 12.2.140
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Detecting CUDA compiler ABI info
-- Detecting CUDA compiler ABI info - done
-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped
-- Detecting CUDA compile features
-- Detecting CUDA compile features - done
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed
-- Looking for pthread_create in pthreads
-- Looking for pthread_create in pthreads - not found
-- Looking for pthread_create in pthread
-- Looking for pthread_create in pthread - found
-- Found Threads: TRUE  
-- Found CUDA: /usr/local/cuda (found version "12.2") 

The following variables are derived from the values of the previous variables unless provided explicitly:

-- Configuring done
CMake Warning (dev) in CMakeLists.txt:
  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,
  empty CUDA_ARCHITECTURES not allowed.  Run "cmake --help-policy CMP0104"
  for policy details.  Use the cmake_policy command to set the policy and
  suppress this warning.

  CUDA_ARCHITECTURES is empty for target "pixelshuffle3dplugin".
This warning is for project developers.  Use -Wno-dev to suppress it.

CMake Warning (dev) in CMakeLists.txt:
  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,
  empty CUDA_ARCHITECTURES not allowed.  Run "cmake --help-policy CMP0104"
  for policy details.  Use the cmake_policy command to set the policy and
  suppress this warning.

  CUDA_ARCHITECTURES is empty for target "pixelshuffle3dplugin".
This warning is for project developers.  Use -Wno-dev to suppress it.

-- Generating done
-- Build files have been written to: /work/build/plugins/pixelShuffle3DPlugin
make[2]: Entering directory '/work/build/plugins/pixelShuffle3DPlugin'
make[3]: Entering directory '/work/build/plugins/pixelShuffle3DPlugin'
make[4]: Entering directory '/work/build/plugins/pixelShuffle3DPlugin'
make[4]: Leaving directory '/work/build/plugins/pixelShuffle3DPlugin'
make[4]: Entering directory '/work/build/plugins/pixelShuffle3DPlugin'
[ 33%] Building CUDA object CMakeFiles/pixelshuffle3dplugin.dir/src/pixelShuffle3DPlugin.cu.o
[ 66%] Building CUDA object CMakeFiles/pixelshuffle3dplugin.dir/src/pixel_shuffle_impl.cu.o
[100%] Linking CUDA shared module libpixelshuffle3dplugin.so
make[4]: Leaving directory '/work/build/plugins/pixelShuffle3DPlugin'
[100%] Built target pixelshuffle3dplugin
make[3]: Leaving directory '/work/build/plugins/pixelShuffle3DPlugin'
make[2]: Leaving directory '/work/build/plugins/pixelShuffle3DPlugin'
mkdir -p build/plugins/conv3D1X1X1K4Plugin
cd build/plugins/conv3D1X1X1K4Plugin\
	&& cmake -DCMAKE_BUILD_TYPE=Release /work/code/plugin/conv3D1X1X1K4Plugin \
	&& make -j
-- The CXX compiler identification is GNU 9.4.0
-- The CUDA compiler identification is NVIDIA 12.2.140
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Detecting CUDA compiler ABI info
-- Detecting CUDA compiler ABI info - done
-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped
-- Detecting CUDA compile features
-- Detecting CUDA compile features - done
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed
-- Looking for pthread_create in pthreads
-- Looking for pthread_create in pthreads - not found
-- Looking for pthread_create in pthread
-- Looking for pthread_create in pthread - found
-- Found Threads: TRUE  
-- Found CUDA: /usr/local/cuda (found version "12.2") 

The following variables are derived from the values of the previous variables unless provided explicitly:

-- Configuring done
CMake Warning (dev) in CMakeLists.txt:
  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,
  empty CUDA_ARCHITECTURES not allowed.  Run "cmake --help-policy CMP0104"
  for policy details.  Use the cmake_policy command to set the policy and
  suppress this warning.

  CUDA_ARCHITECTURES is empty for target "conv3D1X1X1K4Plugin".
This warning is for project developers.  Use -Wno-dev to suppress it.

CMake Warning (dev) in CMakeLists.txt:
  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,
  empty CUDA_ARCHITECTURES not allowed.  Run "cmake --help-policy CMP0104"
  for policy details.  Use the cmake_policy command to set the policy and
  suppress this warning.

  CUDA_ARCHITECTURES is empty for target "conv3D1X1X1K4Plugin".
This warning is for project developers.  Use -Wno-dev to suppress it.

-- Generating done
-- Build files have been written to: /work/build/plugins/conv3D1X1X1K4Plugin
make[2]: Entering directory '/work/build/plugins/conv3D1X1X1K4Plugin'
make[3]: Entering directory '/work/build/plugins/conv3D1X1X1K4Plugin'
make[4]: Entering directory '/work/build/plugins/conv3D1X1X1K4Plugin'
make[4]: Leaving directory '/work/build/plugins/conv3D1X1X1K4Plugin'
make[4]: Entering directory '/work/build/plugins/conv3D1X1X1K4Plugin'
[ 66%] Building CUDA object CMakeFiles/conv3D1X1X1K4Plugin.dir/src/conv3d1x1x1K4Plugin.cu.o
[ 66%] Building CUDA object CMakeFiles/conv3D1X1X1K4Plugin.dir/src/conv3d_1x1x1_k4_impl.cu.o
[100%] Linking CUDA shared module libconv3D1X1X1K4Plugin.so
make[4]: Leaving directory '/work/build/plugins/conv3D1X1X1K4Plugin'
[100%] Built target conv3D1X1X1K4Plugin
make[3]: Leaving directory '/work/build/plugins/conv3D1X1X1K4Plugin'
make[2]: Leaving directory '/work/build/plugins/conv3D1X1X1K4Plugin'
mkdir -p build/plugins/conv3D3X3X3C1K32Plugin
cd build/plugins/conv3D3X3X3C1K32Plugin\
	&& cmake -DCMAKE_BUILD_TYPE=Release /work/code/plugin/conv3D3X3X3C1K32Plugin \
	&& make -j
-- The CXX compiler identification is GNU 9.4.0
-- The CUDA compiler identification is NVIDIA 12.2.140
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Detecting CUDA compiler ABI info
-- Detecting CUDA compiler ABI info - done
-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped
-- Detecting CUDA compile features
-- Detecting CUDA compile features - done
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed
-- Looking for pthread_create in pthreads
-- Looking for pthread_create in pthreads - not found
-- Looking for pthread_create in pthread
-- Looking for pthread_create in pthread - found
-- Found Threads: TRUE  
-- Found CUDA: /usr/local/cuda (found version "12.2") 

The following variables are derived from the values of the previous variables unless provided explicitly:

-- Configuring done
CMake Warning (dev) in CMakeLists.txt:
  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,
  empty CUDA_ARCHITECTURES not allowed.  Run "cmake --help-policy CMP0104"
  for policy details.  Use the cmake_policy command to set the policy and
  suppress this warning.

  CUDA_ARCHITECTURES is empty for target "conv3D3X3X3C1K32Plugin".
This warning is for project developers.  Use -Wno-dev to suppress it.

-- Generating done
-- Build files have been written to: /work/build/plugins/conv3D3X3X3C1K32Plugin
make[2]: Entering directory '/work/build/plugins/conv3D3X3X3C1K32Plugin'
make[3]: Entering directory '/work/build/plugins/conv3D3X3X3C1K32Plugin'
make[4]: Entering directory '/work/build/plugins/conv3D3X3X3C1K32Plugin'
make[4]: Leaving directory '/work/build/plugins/conv3D3X3X3C1K32Plugin'
make[4]: Entering directory '/work/build/plugins/conv3D3X3X3C1K32Plugin'
[ 66%] Building CUDA object CMakeFiles/conv3D3X3X3C1K32Plugin.dir/src/conv3d_3x3x3_c1_k32_impl.cu.o
[ 66%] Building CXX object CMakeFiles/conv3D3X3X3C1K32Plugin.dir/src/conv3d3x3x3C1K32Plugin.cpp.o
In file included from /work/code/plugin/conv3D3X3X3C1K32Plugin/src/conv3d3x3x3C1K32Plugin.cpp:18:
/work/code/plugin/conv3D3X3X3C1K32Plugin/src/conv3d3x3x3C1K32Plugin.h: In constructor ‘nvinfer1::plugin::conv3D3X3X3C1K32Plugin::conv3D3X3X3C1K32Plugin(int, const std::vector<float>&)’:
/work/code/plugin/conv3D3X3X3C1K32Plugin/src/conv3d3x3x3C1K32Plugin.h:103:10: warning: ‘nvinfer1::plugin::conv3D3X3X3C1K32Plugin::mInitialized’ will be initialized after [-Wreorder]
  103 |     bool mInitialized{false};
      |          ^~~~~~~~~~~~
/work/code/plugin/conv3D3X3X3C1K32Plugin/src/conv3d3x3x3C1K32Plugin.h:94:9: warning:   ‘int nvinfer1::plugin::conv3D3X3X3C1K32Plugin::mInputChannels’ [-Wreorder]
   94 |     int mInputChannels;
      |         ^~~~~~~~~~~~~~
/work/code/plugin/conv3D3X3X3C1K32Plugin/src/conv3d3x3x3C1K32Plugin.cpp:89:1: warning:   when initialized here [-Wreorder]
   89 | conv3D3X3X3C1K32Plugin::conv3D3X3X3C1K32Plugin(int inputChannels, const std::vector<float>& weights)
      | ^~~~~~~~~~~~~~~~~~~~~~
In file included from /work/code/plugin/conv3D3X3X3C1K32Plugin/src/conv3d3x3x3C1K32Plugin.cpp:18:
/work/code/plugin/conv3D3X3X3C1K32Plugin/src/conv3d3x3x3C1K32Plugin.h:99:31: warning: ‘nvinfer1::plugin::conv3D3X3X3C1K32Plugin::mOutActivationScale’ will be initialized after [-Wreorder]
   99 |     float mInActivationScale, mOutActivationScale;
      |                               ^~~~~~~~~~~~~~~~~~~
/work/code/plugin/conv3D3X3X3C1K32Plugin/src/conv3d3x3x3C1K32Plugin.h:97:24: warning:   ‘std::vector<float> nvinfer1::plugin::conv3D3X3X3C1K32Plugin::mWeights’ [-Wreorder]
   97 |     std::vector<float> mWeights;
      |                        ^~~~~~~~
/work/code/plugin/conv3D3X3X3C1K32Plugin/src/conv3d3x3x3C1K32Plugin.cpp:89:1: warning:   when initialized here [-Wreorder]
   89 | conv3D3X3X3C1K32Plugin::conv3D3X3X3C1K32Plugin(int inputChannels, const std::vector<float>& weights)
      | ^~~~~~~~~~~~~~~~~~~~~~
/work/code/plugin/conv3D3X3X3C1K32Plugin/src/conv3d3x3x3C1K32Plugin.cpp: In member function ‘virtual int nvinfer1::plugin::conv3D3X3X3C1K32Plugin::initialize()’:
/work/code/plugin/conv3D3X3X3C1K32Plugin/src/conv3d3x3x3C1K32Plugin.cpp:150:46: warning: ‘void* memset(void*, int, size_t)’ clearing an object of non-trivial type ‘struct Conv3d3x3x3c1k32Context’; use assignment or value-initialization instead [-Wclass-memaccess]
  150 |         memset(&mContext, 0, sizeof(mContext));
      |                                              ^
In file included from /work/code/plugin/conv3D3X3X3C1K32Plugin/src/conv3d3x3x3C1K32Plugin.h:27,
                 from /work/code/plugin/conv3D3X3X3C1K32Plugin/src/conv3d3x3x3C1K32Plugin.cpp:18:
/work/code/plugin/conv3D3X3X3C1K32Plugin/src/conv3d_3x3x3_c1_k32.h:81:8: note: ‘struct Conv3d3x3x3c1k32Context’ declared here
   81 | struct Conv3d3x3x3c1k32Context
      |        ^~~~~~~~~~~~~~~~~~~~~~~
[100%] Linking CXX shared module libconv3D3X3X3C1K32Plugin.so
make[4]: Leaving directory '/work/build/plugins/conv3D3X3X3C1K32Plugin'
[100%] Built target conv3D3X3X3C1K32Plugin
make[3]: Leaving directory '/work/build/plugins/conv3D3X3X3C1K32Plugin'
make[2]: Leaving directory '/work/build/plugins/conv3D3X3X3C1K32Plugin'
mkdir -p build/plugins/retinanetConcatPlugin
cd build/plugins/retinanetConcatPlugin\
	&& cmake -DCMAKE_BUILD_TYPE=Release /work/code/plugin/retinanetConcatPlugin \
	&& make -j
-- The CXX compiler identification is GNU 9.4.0
-- The CUDA compiler identification is NVIDIA 12.2.140
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Detecting CUDA compiler ABI info
-- Detecting CUDA compiler ABI info - done
-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped
-- Detecting CUDA compile features
-- Detecting CUDA compile features - done
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed
-- Looking for pthread_create in pthreads
-- Looking for pthread_create in pthreads - not found
-- Looking for pthread_create in pthread
-- Looking for pthread_create in pthread - found
-- Found Threads: TRUE  
-- Found CUDA: /usr/local/cuda (found version "12.2") 

The following variables are derived from the values of the previous variables unless provided explicitly:

-- Configuring done
CMake Warning (dev) in CMakeLists.txt:
  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,
  empty CUDA_ARCHITECTURES not allowed.  Run "cmake --help-policy CMP0104"
  for policy details.  Use the cmake_policy command to set the policy and
  suppress this warning.

  CUDA_ARCHITECTURES is empty for target "retinanetconcatplugin".
This warning is for project developers.  Use -Wno-dev to suppress it.

CMake Warning (dev) in CMakeLists.txt:
  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,
  empty CUDA_ARCHITECTURES not allowed.  Run "cmake --help-policy CMP0104"
  for policy details.  Use the cmake_policy command to set the policy and
  suppress this warning.

  CUDA_ARCHITECTURES is empty for target "retinanetconcatplugin".
This warning is for project developers.  Use -Wno-dev to suppress it.

-- Generating done
-- Build files have been written to: /work/build/plugins/retinanetConcatPlugin
make[2]: Entering directory '/work/build/plugins/retinanetConcatPlugin'
make[3]: Entering directory '/work/build/plugins/retinanetConcatPlugin'
make[4]: Entering directory '/work/build/plugins/retinanetConcatPlugin'
make[4]: Leaving directory '/work/build/plugins/retinanetConcatPlugin'
make[4]: Entering directory '/work/build/plugins/retinanetConcatPlugin'
[ 50%] Building CUDA object CMakeFiles/retinanetconcatplugin.dir/src/concatNmsOutputs.cu.o
/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(69): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(71): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::getWorkspaceSize" -- virtual function override intended?
      virtual size_t getWorkspaceSize(const PluginTensorDesc* inputs, int nbInputs, const PluginTensorDesc* outputs,
                     ^

/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(73): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::enqueue" -- virtual function override intended?
      virtual int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc,
                  ^

/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(65): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const bool *, const bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int nbInputs, const DynamicPluginTensorDesc* out,
           ^

/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(69): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(71): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::getWorkspaceSize" -- virtual function override intended?
      virtual size_t getWorkspaceSize(const PluginTensorDesc* inputs, int nbInputs, const PluginTensorDesc* outputs,
                     ^

/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(73): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::enqueue" -- virtual function override intended?
      virtual int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc,
                  ^

/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(65): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int nbInputs, const DynamicPluginTensorDesc* out,
           ^

/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(69): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(71): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::getWorkspaceSize" -- virtual function override intended?
      virtual size_t getWorkspaceSize(const PluginTensorDesc* inputs, int nbInputs, const PluginTensorDesc* outputs,
                     ^

/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(73): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::enqueue" -- virtual function override intended?
      virtual int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc,
                  ^

/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(65): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int nbInputs, const DynamicPluginTensorDesc* out,
           ^

/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(69): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(71): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::getWorkspaceSize" -- virtual function override intended?
      virtual size_t getWorkspaceSize(const PluginTensorDesc* inputs, int nbInputs, const PluginTensorDesc* outputs,
                     ^

/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(73): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::enqueue" -- virtual function override intended?
      virtual int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc,
                  ^

/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(65): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int nbInputs, const DynamicPluginTensorDesc* out,
           ^

/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(69): warning #997-D: function "nvinfer1::IPluginV2::getOutputDimensions(int32_t, const nvinfer1::Dims *, int32_t)" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::getOutputDimensions" -- virtual function override intended?
      DimsExprs getOutputDimensions(
                ^

Remark: The warnings can be suppressed with "-diag-suppress <warning-number>"

/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(71): warning #997-D: function "nvinfer1::IPluginV2::getWorkspaceSize(int32_t) const" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::getWorkspaceSize" -- virtual function override intended?
      virtual size_t getWorkspaceSize(const PluginTensorDesc* inputs, int nbInputs, const PluginTensorDesc* outputs,
                     ^

/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(73): warning #997-D: function "nvinfer1::IPluginV2::enqueue(int32_t, const void *const *, void *const *, void *, cudaStream_t)" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::enqueue" -- virtual function override intended?
      virtual int enqueue(const PluginTensorDesc* inputDesc, const PluginTensorDesc* outputDesc,
                  ^

/work/code/plugin/retinanetConcatPlugin/src/concatNmsOutputs.h(65): warning #997-D: function "nvinfer1::IPluginV2Ext::configurePlugin(const nvinfer1::Dims *, int32_t, const nvinfer1::Dims *, int32_t, const nvinfer1::DataType *, const nvinfer1::DataType *, const __nv_bool *, const __nv_bool *, nvinfer1::PluginFormat, int32_t)" is hidden by "nvinfer1::plugin::RetinanetConcatNmsOutputsPlugin::configurePlugin" -- virtual function override intended?
      void configurePlugin(const DynamicPluginTensorDesc* in, int nbInputs, const DynamicPluginTensorDesc* out,
           ^

[100%] Linking CUDA shared module libretinanetconcatplugin.so
make[4]: Leaving directory '/work/build/plugins/retinanetConcatPlugin'
[100%] Built target retinanetconcatplugin
make[3]: Leaving directory '/work/build/plugins/retinanetConcatPlugin'
make[2]: Leaving directory '/work/build/plugins/retinanetConcatPlugin'
mkdir -p build/plugins/DLRMv2EmbeddingLookupPlugin
cd build/plugins/DLRMv2EmbeddingLookupPlugin\
	&& cmake -DCMAKE_BUILD_TYPE=Release /work/code/plugin/DLRMv2EmbeddingLookupPlugin \
	&& make -j
-- The CXX compiler identification is GNU 9.4.0
-- The CUDA compiler identification is NVIDIA 12.2.140
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Detecting CUDA compiler ABI info
-- Detecting CUDA compiler ABI info - done
-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped
-- Detecting CUDA compile features
-- Detecting CUDA compile features - done
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed
-- Looking for pthread_create in pthreads
-- Looking for pthread_create in pthreads - not found
-- Looking for pthread_create in pthread
-- Looking for pthread_create in pthread - found
-- Found Threads: TRUE  
-- Found CUDA: /usr/local/cuda (found version "12.2") 

The following variables are derived from the values of the previous variables unless provided explicitly:

-- Configuring done
CMake Warning (dev) in CMakeLists.txt:
  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,
  empty CUDA_ARCHITECTURES not allowed.  Run "cmake --help-policy CMP0104"
  for policy details.  Use the cmake_policy command to set the policy and
  suppress this warning.

  CUDA_ARCHITECTURES is empty for target "dlrmv2embeddinglookupplugin".
This warning is for project developers.  Use -Wno-dev to suppress it.

-- Generating done
-- Build files have been written to: /work/build/plugins/DLRMv2EmbeddingLookupPlugin
make[2]: Entering directory '/work/build/plugins/DLRMv2EmbeddingLookupPlugin'
make[3]: Entering directory '/work/build/plugins/DLRMv2EmbeddingLookupPlugin'
make[4]: Entering directory '/work/build/plugins/DLRMv2EmbeddingLookupPlugin'
make[4]: Leaving directory '/work/build/plugins/DLRMv2EmbeddingLookupPlugin'
make[4]: Entering directory '/work/build/plugins/DLRMv2EmbeddingLookupPlugin'
[ 60%] Building CUDA object CMakeFiles/dlrmv2embeddinglookupplugin.dir/src/embedding_remap_launch.cu.o
[ 60%] Building CUDA object CMakeFiles/dlrmv2embeddinglookupplugin.dir/src/embedding_gather_launch.cu.o
[ 60%] Building CXX object CMakeFiles/dlrmv2embeddinglookupplugin.dir/src/dlrmv2EmbeddingLookupPlugin.cpp.o
[ 80%] Building CXX object CMakeFiles/dlrmv2embeddinglookupplugin.dir/src/dlrmv2Helper.cpp.o
[100%] Linking CXX shared module libdlrmv2embeddinglookupplugin.so
make[4]: Leaving directory '/work/build/plugins/DLRMv2EmbeddingLookupPlugin'
[100%] Built target dlrmv2embeddinglookupplugin
make[3]: Leaving directory '/work/build/plugins/DLRMv2EmbeddingLookupPlugin'
make[2]: Leaving directory '/work/build/plugins/DLRMv2EmbeddingLookupPlugin'
make[1]: Leaving directory '/work'
make[1]: Entering directory '/work'
Building loadgen...
-- The C compiler identification is GNU 9.4.0
-- The CXX compiler identification is GNU 9.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
mlperf_loadgen v4.0
-- Using C++ compiler flags:  -O3 -W -Wall
-- Using C++ standard: 14
-- Using static linker flags: 
-- Using shared linker flags: 
-- Using output path: /work/build/inference/loadgen/build
-- Found PythonInterp: /usr/bin/python (found version "3.8.10") 
-- Using Python interpreter: /usr/bin/python
-- Configuring done
-- Generating done
-- Build files have been written to: /work/build/inference/loadgen/build
make[2]: Entering directory '/work/build/inference/loadgen/build'
make[3]: Entering directory '/work/build/inference/loadgen/build'
make[4]: Entering directory '/work/build/inference/loadgen/build'
make[4]: Leaving directory '/work/build/inference/loadgen/build'
make[4]: Entering directory '/work/build/inference/loadgen/build'
[  7%] Building CXX object CMakeFiles/mlperf_loadgen.dir/bindings/c_api.cc.o
[ 23%] Building CXX object CMakeFiles/mlperf_loadgen.dir/issue_query_controller.cc.o
[ 30%] Building CXX object CMakeFiles/mlperf_loadgen.dir/loadgen.cc.o
[ 38%] Building CXX object CMakeFiles/mlperf_loadgen.dir/logging.cc.o
[ 46%] Building CXX object CMakeFiles/mlperf_loadgen.dir/test_settings_internal.cc.o
[ 46%] Building CXX object CMakeFiles/mlperf_loadgen.dir/early_stopping.cc.o
[ 53%] Building CXX object CMakeFiles/mlperf_loadgen.dir/utils.cc.o
[ 61%] Building CXX object CMakeFiles/mlperf_loadgen.dir/results.cc.o
[ 76%] Building CXX object CMakeFiles/mlperf_loadgen.dir/version.cc.o
[ 76%] Building CXX object CMakeFiles/mlperf_loadgen.dir/version_generated.cc.o
/work/build/inference/loadgen/logging.cc: In member function ‘void mlperf::logging::AsyncLog::RecordTokenCompletion(uint64_t, std::chrono::_V2::system_clock::time_point, mlperf::QuerySampleLatency)’:
/work/build/inference/loadgen/logging.cc:483:61: warning: unused parameter ‘completion_time’ [-Wunused-parameter]
  483 |                                       PerfClock::time_point completion_time,
      |                                       ~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~
/work/build/inference/loadgen/logging.cc: In member function ‘std::vector<long int> mlperf::logging::AsyncLog::GetTokenLatencies(size_t)’:
/work/build/inference/loadgen/logging.cc:601:68: warning: unused parameter ‘expected_count’ [-Wunused-parameter]
  601 | std::vector<QuerySampleLatency> AsyncLog::GetTokenLatencies(size_t expected_count) {
      |                                                             ~~~~~~~^~~~~~~~~~~~~~
/work/build/inference/loadgen/logging.cc: In member function ‘std::vector<long int> mlperf::logging::AsyncLog::GetTimePerOutputToken(size_t)’:
/work/build/inference/loadgen/logging.cc:607:72: warning: unused parameter ‘expected_count’ [-Wunused-parameter]
  607 | std::vector<QuerySampleLatency> AsyncLog::GetTimePerOutputToken(size_t expected_count){
      |                                                                 ~~~~~~~^~~~~~~~~~~~~~
/work/build/inference/loadgen/logging.cc: In member function ‘std::vector<long int> mlperf::logging::AsyncLog::GetTokensPerSample(size_t)’:
/work/build/inference/loadgen/logging.cc:613:58: warning: unused parameter ‘expected_count’ [-Wunused-parameter]
  613 | std::vector<int64_t> AsyncLog::GetTokensPerSample(size_t expected_count) {
      |                                                   ~~~~~~~^~~~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘void mlperf::loadgen::RunPerformanceMode(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, const mlperf::loadgen::TestSettingsInternal&, mlperf::loadgen::SequenceGen*) [with mlperf::TestScenario scenario = mlperf::TestScenario::SingleStream]’:
/work/build/inference/loadgen/loadgen.cc:1132:61:   required from ‘static mlperf::loadgen::RunFunctions mlperf::loadgen::RunFunctions::GetCompileTime() [with mlperf::TestScenario compile_time_scenario = mlperf::TestScenario::SingleStream]’
/work/build/inference/loadgen/loadgen.cc:1138:59:   required from here
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
  918 |   PerformanceSummary perf_summary{sut->Name(), settings, std::move(pr)};
      |                      ^~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘void mlperf::loadgen::FindPeakPerformanceMode(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, const mlperf::loadgen::TestSettingsInternal&, mlperf::loadgen::SequenceGen*) [with mlperf::TestScenario scenario = mlperf::TestScenario::SingleStream]’:
/work/build/inference/loadgen/loadgen.cc:1132:61:   required from ‘static mlperf::loadgen::RunFunctions mlperf::loadgen::RunFunctions::GetCompileTime() [with mlperf::TestScenario compile_time_scenario = mlperf::TestScenario::SingleStream]’
/work/build/inference/loadgen/loadgen.cc:1138:59:   required from here
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
  988 |   PerformanceSummary base_perf_summary{sut->Name(), base_settings,
      |                      ^~~~~~~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
 1010 |     PerformanceSummary perf_summary{sut->Name(), base_settings,
      |                        ^~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘void mlperf::loadgen::RunPerformanceMode(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, const mlperf::loadgen::TestSettingsInternal&, mlperf::loadgen::SequenceGen*) [with mlperf::TestScenario scenario = mlperf::TestScenario::MultiStream]’:
/work/build/inference/loadgen/loadgen.cc:1132:61:   required from ‘static mlperf::loadgen::RunFunctions mlperf::loadgen::RunFunctions::GetCompileTime() [with mlperf::TestScenario compile_time_scenario = mlperf::TestScenario::MultiStream]’
/work/build/inference/loadgen/loadgen.cc:1140:58:   required from here
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
  918 |   PerformanceSummary perf_summary{sut->Name(), settings, std::move(pr)};
      |                      ^~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘void mlperf::loadgen::FindPeakPerformanceMode(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, const mlperf::loadgen::TestSettingsInternal&, mlperf::loadgen::SequenceGen*) [with mlperf::TestScenario scenario = mlperf::TestScenario::MultiStream]’:
/work/build/inference/loadgen/loadgen.cc:1132:61:   required from ‘static mlperf::loadgen::RunFunctions mlperf::loadgen::RunFunctions::GetCompileTime() [with mlperf::TestScenario compile_time_scenario = mlperf::TestScenario::MultiStream]’
/work/build/inference/loadgen/loadgen.cc:1140:58:   required from here
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
  988 |   PerformanceSummary base_perf_summary{sut->Name(), base_settings,
      |                      ^~~~~~~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
 1010 |     PerformanceSummary perf_summary{sut->Name(), base_settings,
      |                        ^~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘void mlperf::loadgen::RunPerformanceMode(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, const mlperf::loadgen::TestSettingsInternal&, mlperf::loadgen::SequenceGen*) [with mlperf::TestScenario scenario = mlperf::TestScenario::Server]’:
/work/build/inference/loadgen/loadgen.cc:1132:61:   required from ‘static mlperf::loadgen::RunFunctions mlperf::loadgen::RunFunctions::GetCompileTime() [with mlperf::TestScenario compile_time_scenario = mlperf::TestScenario::Server]’
/work/build/inference/loadgen/loadgen.cc:1142:53:   required from here
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
  918 |   PerformanceSummary perf_summary{sut->Name(), settings, std::move(pr)};
      |                      ^~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘void mlperf::loadgen::FindPeakPerformanceMode(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, const mlperf::loadgen::TestSettingsInternal&, mlperf::loadgen::SequenceGen*) [with mlperf::TestScenario scenario = mlperf::TestScenario::Server]’:
/work/build/inference/loadgen/loadgen.cc:1132:61:   required from ‘static mlperf::loadgen::RunFunctions mlperf::loadgen::RunFunctions::GetCompileTime() [with mlperf::TestScenario compile_time_scenario = mlperf::TestScenario::Server]’
/work/build/inference/loadgen/loadgen.cc:1142:53:   required from here
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
  988 |   PerformanceSummary base_perf_summary{sut->Name(), base_settings,
      |                      ^~~~~~~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
 1010 |     PerformanceSummary perf_summary{sut->Name(), base_settings,
      |                        ^~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘void mlperf::loadgen::RunPerformanceMode(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, const mlperf::loadgen::TestSettingsInternal&, mlperf::loadgen::SequenceGen*) [with mlperf::TestScenario scenario = mlperf::TestScenario::Offline]’:
/work/build/inference/loadgen/loadgen.cc:1132:61:   required from ‘static mlperf::loadgen::RunFunctions mlperf::loadgen::RunFunctions::GetCompileTime() [with mlperf::TestScenario compile_time_scenario = mlperf::TestScenario::Offline]’
/work/build/inference/loadgen/loadgen.cc:1144:54:   required from here
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
  918 |   PerformanceSummary perf_summary{sut->Name(), settings, std::move(pr)};
      |                      ^~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:918:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘void mlperf::loadgen::FindPeakPerformanceMode(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, const mlperf::loadgen::TestSettingsInternal&, mlperf::loadgen::SequenceGen*) [with mlperf::TestScenario scenario = mlperf::TestScenario::Offline]’:
/work/build/inference/loadgen/loadgen.cc:1132:61:   required from ‘static mlperf::loadgen::RunFunctions mlperf::loadgen::RunFunctions::GetCompileTime() [with mlperf::TestScenario compile_time_scenario = mlperf::TestScenario::Offline]’
/work/build/inference/loadgen/loadgen.cc:1144:54:   required from here
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
  988 |   PerformanceSummary base_perf_summary{sut->Name(), base_settings,
      |                      ^~~~~~~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:988:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
 1010 |     PerformanceSummary perf_summary{sut->Name(), base_settings,
      |                        ^~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:1010:24: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘std::pair<mlperf::loadgen::PerformanceSummary, mlperf::loadgen::PerformanceSummary> mlperf::loadgen::FindBoundaries(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, mlperf::loadgen::SequenceGen*, mlperf::loadgen::PerformanceSummary) [with mlperf::TestScenario scenario = mlperf::TestScenario::SingleStream]’:
/work/build/inference/loadgen/loadgen.cc:1031:31:   required from ‘void mlperf::loadgen::FindPeakPerformanceMode(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, const mlperf::loadgen::TestSettingsInternal&, mlperf::loadgen::SequenceGen*) [with mlperf::TestScenario scenario = mlperf::TestScenario::SingleStream]’
/work/build/inference/loadgen/loadgen.cc:1132:61:   required from ‘static mlperf::loadgen::RunFunctions mlperf::loadgen::RunFunctions::GetCompileTime() [with mlperf::TestScenario compile_time_scenario = mlperf::TestScenario::SingleStream]’
/work/build/inference/loadgen/loadgen.cc:1138:59:   required from here
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
  768 |   PerformanceSummary u_perf_summary{sut->Name(), u_settings, std::move(u_pr)};
      |                      ^~~~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘mlperf::loadgen::PerformanceSummary mlperf::loadgen::FindPeakPerformanceBinarySearch(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, mlperf::loadgen::SequenceGen*, const mlperf::loadgen::LoadableSampleSet&, mlperf::loadgen::PerformanceSummary, mlperf::loadgen::PerformanceSummary) [with mlperf::TestScenario scenario = mlperf::TestScenario::SingleStream]’:
/work/build/inference/loadgen/loadgen.cc:1057:78:   required from ‘void mlperf::loadgen::FindPeakPerformanceMode(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, const mlperf::loadgen::TestSettingsInternal&, mlperf::loadgen::SequenceGen*) [with mlperf::TestScenario scenario = mlperf::TestScenario::SingleStream]’
/work/build/inference/loadgen/loadgen.cc:1132:61:   required from ‘static mlperf::loadgen::RunFunctions mlperf::loadgen::RunFunctions::GetCompileTime() [with mlperf::TestScenario compile_time_scenario = mlperf::TestScenario::SingleStream]’
/work/build/inference/loadgen/loadgen.cc:1138:59:   required from here
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
  820 |   PerformanceSummary m_perf_summary{sut->Name(), m_settings, std::move(m_pr)};
      |                      ^~~~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘std::pair<mlperf::loadgen::PerformanceSummary, mlperf::loadgen::PerformanceSummary> mlperf::loadgen::FindBoundaries(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, mlperf::loadgen::SequenceGen*, mlperf::loadgen::PerformanceSummary) [with mlperf::TestScenario scenario = mlperf::TestScenario::MultiStream]’:
/work/build/inference/loadgen/loadgen.cc:1031:31:   required from ‘void mlperf::loadgen::FindPeakPerformanceMode(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, const mlperf::loadgen::TestSettingsInternal&, mlperf::loadgen::SequenceGen*) [with mlperf::TestScenario scenario = mlperf::TestScenario::MultiStream]’
/work/build/inference/loadgen/loadgen.cc:1132:61:   required from ‘static mlperf::loadgen::RunFunctions mlperf::loadgen::RunFunctions::GetCompileTime() [with mlperf::TestScenario compile_time_scenario = mlperf::TestScenario::MultiStream]’
/work/build/inference/loadgen/loadgen.cc:1140:58:   required from here
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
  768 |   PerformanceSummary u_perf_summary{sut->Name(), u_settings, std::move(u_pr)};
      |                      ^~~~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘mlperf::loadgen::PerformanceSummary mlperf::loadgen::FindPeakPerformanceBinarySearch(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, mlperf::loadgen::SequenceGen*, const mlperf::loadgen::LoadableSampleSet&, mlperf::loadgen::PerformanceSummary, mlperf::loadgen::PerformanceSummary) [with mlperf::TestScenario scenario = mlperf::TestScenario::MultiStream]’:
/work/build/inference/loadgen/loadgen.cc:1057:78:   required from ‘void mlperf::loadgen::FindPeakPerformanceMode(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, const mlperf::loadgen::TestSettingsInternal&, mlperf::loadgen::SequenceGen*) [with mlperf::TestScenario scenario = mlperf::TestScenario::MultiStream]’
/work/build/inference/loadgen/loadgen.cc:1132:61:   required from ‘static mlperf::loadgen::RunFunctions mlperf::loadgen::RunFunctions::GetCompileTime() [with mlperf::TestScenario compile_time_scenario = mlperf::TestScenario::MultiStream]’
/work/build/inference/loadgen/loadgen.cc:1140:58:   required from here
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
  820 |   PerformanceSummary m_perf_summary{sut->Name(), m_settings, std::move(m_pr)};
      |                      ^~~~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘std::pair<mlperf::loadgen::PerformanceSummary, mlperf::loadgen::PerformanceSummary> mlperf::loadgen::FindBoundaries(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, mlperf::loadgen::SequenceGen*, mlperf::loadgen::PerformanceSummary) [with mlperf::TestScenario scenario = mlperf::TestScenario::Server]’:
/work/build/inference/loadgen/loadgen.cc:1031:31:   required from ‘void mlperf::loadgen::FindPeakPerformanceMode(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, const mlperf::loadgen::TestSettingsInternal&, mlperf::loadgen::SequenceGen*) [with mlperf::TestScenario scenario = mlperf::TestScenario::Server]’
/work/build/inference/loadgen/loadgen.cc:1132:61:   required from ‘static mlperf::loadgen::RunFunctions mlperf::loadgen::RunFunctions::GetCompileTime() [with mlperf::TestScenario compile_time_scenario = mlperf::TestScenario::Server]’
/work/build/inference/loadgen/loadgen.cc:1142:53:   required from here
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
  768 |   PerformanceSummary u_perf_summary{sut->Name(), u_settings, std::move(u_pr)};
      |                      ^~~~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘mlperf::loadgen::PerformanceSummary mlperf::loadgen::FindPeakPerformanceBinarySearch(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, mlperf::loadgen::SequenceGen*, const mlperf::loadgen::LoadableSampleSet&, mlperf::loadgen::PerformanceSummary, mlperf::loadgen::PerformanceSummary) [with mlperf::TestScenario scenario = mlperf::TestScenario::Server]’:
/work/build/inference/loadgen/loadgen.cc:1057:78:   required from ‘void mlperf::loadgen::FindPeakPerformanceMode(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, const mlperf::loadgen::TestSettingsInternal&, mlperf::loadgen::SequenceGen*) [with mlperf::TestScenario scenario = mlperf::TestScenario::Server]’
/work/build/inference/loadgen/loadgen.cc:1132:61:   required from ‘static mlperf::loadgen::RunFunctions mlperf::loadgen::RunFunctions::GetCompileTime() [with mlperf::TestScenario compile_time_scenario = mlperf::TestScenario::Server]’
/work/build/inference/loadgen/loadgen.cc:1142:53:   required from here
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
  820 |   PerformanceSummary m_perf_summary{sut->Name(), m_settings, std::move(m_pr)};
      |                      ^~~~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘std::pair<mlperf::loadgen::PerformanceSummary, mlperf::loadgen::PerformanceSummary> mlperf::loadgen::FindBoundaries(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, mlperf::loadgen::SequenceGen*, mlperf::loadgen::PerformanceSummary) [with mlperf::TestScenario scenario = mlperf::TestScenario::Offline]’:
/work/build/inference/loadgen/loadgen.cc:1031:31:   required from ‘void mlperf::loadgen::FindPeakPerformanceMode(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, const mlperf::loadgen::TestSettingsInternal&, mlperf::loadgen::SequenceGen*) [with mlperf::TestScenario scenario = mlperf::TestScenario::Offline]’
/work/build/inference/loadgen/loadgen.cc:1132:61:   required from ‘static mlperf::loadgen::RunFunctions mlperf::loadgen::RunFunctions::GetCompileTime() [with mlperf::TestScenario compile_time_scenario = mlperf::TestScenario::Offline]’
/work/build/inference/loadgen/loadgen.cc:1144:54:   required from here
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
  768 |   PerformanceSummary u_perf_summary{sut->Name(), u_settings, std::move(u_pr)};
      |                      ^~~~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:768:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘mlperf::loadgen::PerformanceSummary mlperf::loadgen::FindPeakPerformanceBinarySearch(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, mlperf::loadgen::SequenceGen*, const mlperf::loadgen::LoadableSampleSet&, mlperf::loadgen::PerformanceSummary, mlperf::loadgen::PerformanceSummary) [with mlperf::TestScenario scenario = mlperf::TestScenario::Offline]’:
/work/build/inference/loadgen/loadgen.cc:1057:78:   required from ‘void mlperf::loadgen::FindPeakPerformanceMode(mlperf::SystemUnderTest*, mlperf::QuerySampleLibrary*, const mlperf::loadgen::TestSettingsInternal&, mlperf::loadgen::SequenceGen*) [with mlperf::TestScenario scenario = mlperf::TestScenario::Offline]’
/work/build/inference/loadgen/loadgen.cc:1132:61:   required from ‘static mlperf::loadgen::RunFunctions mlperf::loadgen::RunFunctions::GetCompileTime() [with mlperf::TestScenario compile_time_scenario = mlperf::TestScenario::Offline]’
/work/build/inference/loadgen/loadgen.cc:1144:54:   required from here
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
  820 |   PerformanceSummary m_perf_summary{sut->Name(), m_settings, std::move(m_pr)};
      |                      ^~~~~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::first_token_latency_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_min’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_max’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc:820:22: warning: missing initializer for member ‘mlperf::loadgen::PerformanceSummary::time_per_output_token_mean’ [-Wmissing-field-initializers]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘void mlperf::loadgen::ResponseDelegateDetailed<scenario, mode>::TokenComplete(mlperf::loadgen::SampleMetadata*, mlperf::QuerySampleResponse*, std::chrono::_V2::system_clock::time_point, const ResponseCallback&) [with mlperf::TestScenario scenario = mlperf::TestScenario::Offline; mlperf::TestMode mode = mlperf::TestMode::PerformanceOnly; std::chrono::_V2::system_clock::time_point = std::chrono::time_point<std::chrono::_V2::system_clock, std::chrono::duration<long int, std::ratio<1, 1000000000> > >; mlperf::ResponseCallback = std::function<void(mlperf::QuerySampleResponse*)>]’:
/work/build/inference/loadgen/loadgen.cc:135:10:   required from here
/work/build/inference/loadgen/loadgen.cc:137:47: warning: unused parameter ‘response_cb’ [-Wunused-parameter]
  137 |                       const ResponseCallback& response_cb) override {
      |                       ~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘void mlperf::loadgen::ResponseDelegateDetailed<scenario, mode>::TokenComplete(mlperf::loadgen::SampleMetadata*, mlperf::QuerySampleResponse*, std::chrono::_V2::system_clock::time_point, const ResponseCallback&) [with mlperf::TestScenario scenario = mlperf::TestScenario::Offline; mlperf::TestMode mode = mlperf::TestMode::AccuracyOnly; std::chrono::_V2::system_clock::time_point = std::chrono::time_point<std::chrono::_V2::system_clock, std::chrono::duration<long int, std::ratio<1, 1000000000> > >; mlperf::ResponseCallback = std::function<void(mlperf::QuerySampleResponse*)>]’:
/work/build/inference/loadgen/loadgen.cc:135:10:   required from here
/work/build/inference/loadgen/loadgen.cc:137:47: warning: unused parameter ‘response_cb’ [-Wunused-parameter]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘void mlperf::loadgen::ResponseDelegateDetailed<scenario, mode>::TokenComplete(mlperf::loadgen::SampleMetadata*, mlperf::QuerySampleResponse*, std::chrono::_V2::system_clock::time_point, const ResponseCallback&) [with mlperf::TestScenario scenario = mlperf::TestScenario::Server; mlperf::TestMode mode = mlperf::TestMode::PerformanceOnly; std::chrono::_V2::system_clock::time_point = std::chrono::time_point<std::chrono::_V2::system_clock, std::chrono::duration<long int, std::ratio<1, 1000000000> > >; mlperf::ResponseCallback = std::function<void(mlperf::QuerySampleResponse*)>]’:
/work/build/inference/loadgen/loadgen.cc:135:10:   required from here
/work/build/inference/loadgen/loadgen.cc:137:47: warning: unused parameter ‘response_cb’ [-Wunused-parameter]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘void mlperf::loadgen::ResponseDelegateDetailed<scenario, mode>::TokenComplete(mlperf::loadgen::SampleMetadata*, mlperf::QuerySampleResponse*, std::chrono::_V2::system_clock::time_point, const ResponseCallback&) [with mlperf::TestScenario scenario = mlperf::TestScenario::Server; mlperf::TestMode mode = mlperf::TestMode::AccuracyOnly; std::chrono::_V2::system_clock::time_point = std::chrono::time_point<std::chrono::_V2::system_clock, std::chrono::duration<long int, std::ratio<1, 1000000000> > >; mlperf::ResponseCallback = std::function<void(mlperf::QuerySampleResponse*)>]’:
/work/build/inference/loadgen/loadgen.cc:135:10:   required from here
/work/build/inference/loadgen/loadgen.cc:137:47: warning: unused parameter ‘response_cb’ [-Wunused-parameter]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘void mlperf::loadgen::ResponseDelegateDetailed<scenario, mode>::TokenComplete(mlperf::loadgen::SampleMetadata*, mlperf::QuerySampleResponse*, std::chrono::_V2::system_clock::time_point, const ResponseCallback&) [with mlperf::TestScenario scenario = mlperf::TestScenario::MultiStream; mlperf::TestMode mode = mlperf::TestMode::PerformanceOnly; std::chrono::_V2::system_clock::time_point = std::chrono::time_point<std::chrono::_V2::system_clock, std::chrono::duration<long int, std::ratio<1, 1000000000> > >; mlperf::ResponseCallback = std::function<void(mlperf::QuerySampleResponse*)>]’:
/work/build/inference/loadgen/loadgen.cc:135:10:   required from here
/work/build/inference/loadgen/loadgen.cc:137:47: warning: unused parameter ‘response_cb’ [-Wunused-parameter]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘void mlperf::loadgen::ResponseDelegateDetailed<scenario, mode>::TokenComplete(mlperf::loadgen::SampleMetadata*, mlperf::QuerySampleResponse*, std::chrono::_V2::system_clock::time_point, const ResponseCallback&) [with mlperf::TestScenario scenario = mlperf::TestScenario::MultiStream; mlperf::TestMode mode = mlperf::TestMode::AccuracyOnly; std::chrono::_V2::system_clock::time_point = std::chrono::time_point<std::chrono::_V2::system_clock, std::chrono::duration<long int, std::ratio<1, 1000000000> > >; mlperf::ResponseCallback = std::function<void(mlperf::QuerySampleResponse*)>]’:
/work/build/inference/loadgen/loadgen.cc:135:10:   required from here
/work/build/inference/loadgen/loadgen.cc:137:47: warning: unused parameter ‘response_cb’ [-Wunused-parameter]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘void mlperf::loadgen::ResponseDelegateDetailed<scenario, mode>::TokenComplete(mlperf::loadgen::SampleMetadata*, mlperf::QuerySampleResponse*, std::chrono::_V2::system_clock::time_point, const ResponseCallback&) [with mlperf::TestScenario scenario = mlperf::TestScenario::SingleStream; mlperf::TestMode mode = mlperf::TestMode::PerformanceOnly; std::chrono::_V2::system_clock::time_point = std::chrono::time_point<std::chrono::_V2::system_clock, std::chrono::duration<long int, std::ratio<1, 1000000000> > >; mlperf::ResponseCallback = std::function<void(mlperf::QuerySampleResponse*)>]’:
/work/build/inference/loadgen/loadgen.cc:135:10:   required from here
/work/build/inference/loadgen/loadgen.cc:137:47: warning: unused parameter ‘response_cb’ [-Wunused-parameter]
/work/build/inference/loadgen/loadgen.cc: In instantiation of ‘void mlperf::loadgen::ResponseDelegateDetailed<scenario, mode>::TokenComplete(mlperf::loadgen::SampleMetadata*, mlperf::QuerySampleResponse*, std::chrono::_V2::system_clock::time_point, const ResponseCallback&) [with mlperf::TestScenario scenario = mlperf::TestScenario::SingleStream; mlperf::TestMode mode = mlperf::TestMode::AccuracyOnly; std::chrono::_V2::system_clock::time_point = std::chrono::time_point<std::chrono::_V2::system_clock, std::chrono::duration<long int, std::ratio<1, 1000000000> > >; mlperf::ResponseCallback = std::function<void(mlperf::QuerySampleResponse*)>]’:
/work/build/inference/loadgen/loadgen.cc:135:10:   required from here
/work/build/inference/loadgen/loadgen.cc:137:47: warning: unused parameter ‘response_cb’ [-Wunused-parameter]
[ 84%] Linking CXX static library libmlperf_loadgen.a
make[4]: Leaving directory '/work/build/inference/loadgen/build'
[ 84%] Built target mlperf_loadgen
make[4]: Entering directory '/work/build/inference/loadgen/build'
make[4]: Leaving directory '/work/build/inference/loadgen/build'
make[4]: Entering directory '/work/build/inference/loadgen/build'
[ 92%] Building CXX object CMakeFiles/benchmark.dir/benchmark/repro.cpp.o
/work/build/inference/loadgen/benchmark/repro.cpp: In member function ‘virtual void QSL::LoadSamplesToRam(const std::vector<long unsigned int>&)’:
/work/build/inference/loadgen/benchmark/repro.cpp:37:52: warning: unused parameter ‘samples’ [-Wunused-parameter]
   37 |       const std::vector<mlperf::QuerySampleIndex>& samples) override {}
      |       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~
/work/build/inference/loadgen/benchmark/repro.cpp: In member function ‘virtual void QSL::UnloadSamplesFromRam(const std::vector<long unsigned int>&)’:
/work/build/inference/loadgen/benchmark/repro.cpp:39:52: warning: unused parameter ‘samples’ [-Wunused-parameter]
   39 |       const std::vector<mlperf::QuerySampleIndex>& samples) override {}
      |       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~
/work/build/inference/loadgen/benchmark/repro.cpp: In member function ‘virtual void BasicSUT::IssueQuery(const std::vector<mlperf::QuerySample>&)’:
/work/build/inference/loadgen/benchmark/repro.cpp:55:11: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<mlperf::QuerySampleResponse>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]
   55 |     if (n > mResponses.size()) {
      |         ~~^~~~~~~~~~~~~~~~~~~
/work/build/inference/loadgen/benchmark/repro.cpp: In member function ‘void QueueSUT::CompleteThread(int)’:
/work/build/inference/loadgen/benchmark/repro.cpp:125:27: warning: comparison of integer expressions of different signedness: ‘int’ and ‘size_t’ {aka ‘long unsigned int’} [-Wsign-compare]
  125 |         for (int i = 0; i < actualSize; i++) {
      |                         ~~^~~~~~~~~~~~
/work/build/inference/loadgen/benchmark/repro.cpp: In member function ‘virtual void MultiBasicSUT::IssueQuery(const std::vector<mlperf::QuerySample>&)’:
/work/build/inference/loadgen/benchmark/repro.cpp:171:11: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<mlperf::QuerySampleResponse>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]
  171 |     if (n > reponses.size()) {
      |         ~~^~~~~~~~~~~~~~~~~
[100%] Linking CXX executable benchmark
make[4]: Leaving directory '/work/build/inference/loadgen/build'
[100%] Built target benchmark
make[3]: Leaving directory '/work/build/inference/loadgen/build'
make[2]: Leaving directory '/work/build/inference/loadgen/build'
running bdist_wheel
running build
running build_ext
x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -std=c++14 -O3 -fPIC -I/usr/include/python3.8 -c flagcheck.cpp -o flagcheck.o -std=c++17
building 'mlperf_loadgen' extension
creating build/temp.linux-x86_64-cpython-38
creating build/temp.linux-x86_64-cpython-38/bindings
creating build/temp.linux-x86_64-cpython-38/generated
x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -std=c++14 -O3 -fPIC -DMAJOR_VERSION=4 -DMINOR_VERSION=0 -I. -I/usr/local/lib/python3.8/dist-packages/pybind11/include -I/usr/include/python3.8 -c bindings/python_api.cc -o build/temp.linux-x86_64-cpython-38/bindings/python_api.o -std=c++17 -fvisibility=hidden -g0
x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -std=c++14 -O3 -fPIC -DMAJOR_VERSION=4 -DMINOR_VERSION=0 -I. -I/usr/local/lib/python3.8/dist-packages/pybind11/include -I/usr/include/python3.8 -c early_stopping.cc -o build/temp.linux-x86_64-cpython-38/early_stopping.o -std=c++17 -fvisibility=hidden -g0
x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -std=c++14 -O3 -fPIC -DMAJOR_VERSION=4 -DMINOR_VERSION=0 -I. -I/usr/local/lib/python3.8/dist-packages/pybind11/include -I/usr/include/python3.8 -c generated/version_generated.cc -o build/temp.linux-x86_64-cpython-38/generated/version_generated.o -std=c++17 -fvisibility=hidden -g0
x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -std=c++14 -O3 -fPIC -DMAJOR_VERSION=4 -DMINOR_VERSION=0 -I. -I/usr/local/lib/python3.8/dist-packages/pybind11/include -I/usr/include/python3.8 -c issue_query_controller.cc -o build/temp.linux-x86_64-cpython-38/issue_query_controller.o -std=c++17 -fvisibility=hidden -g0
x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -std=c++14 -O3 -fPIC -DMAJOR_VERSION=4 -DMINOR_VERSION=0 -I. -I/usr/local/lib/python3.8/dist-packages/pybind11/include -I/usr/include/python3.8 -c loadgen.cc -o build/temp.linux-x86_64-cpython-38/loadgen.o -std=c++17 -fvisibility=hidden -g0
x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -std=c++14 -O3 -fPIC -DMAJOR_VERSION=4 -DMINOR_VERSION=0 -I. -I/usr/local/lib/python3.8/dist-packages/pybind11/include -I/usr/include/python3.8 -c logging.cc -o build/temp.linux-x86_64-cpython-38/logging.o -std=c++17 -fvisibility=hidden -g0
x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -std=c++14 -O3 -fPIC -DMAJOR_VERSION=4 -DMINOR_VERSION=0 -I. -I/usr/local/lib/python3.8/dist-packages/pybind11/include -I/usr/include/python3.8 -c results.cc -o build/temp.linux-x86_64-cpython-38/results.o -std=c++17 -fvisibility=hidden -g0
x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -std=c++14 -O3 -fPIC -DMAJOR_VERSION=4 -DMINOR_VERSION=0 -I. -I/usr/local/lib/python3.8/dist-packages/pybind11/include -I/usr/include/python3.8 -c test_settings_internal.cc -o build/temp.linux-x86_64-cpython-38/test_settings_internal.o -std=c++17 -fvisibility=hidden -g0
x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -std=c++14 -O3 -fPIC -DMAJOR_VERSION=4 -DMINOR_VERSION=0 -I. -I/usr/local/lib/python3.8/dist-packages/pybind11/include -I/usr/include/python3.8 -c utils.cc -o build/temp.linux-x86_64-cpython-38/utils.o -std=c++17 -fvisibility=hidden -g0
x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -std=c++14 -O3 -fPIC -DMAJOR_VERSION=4 -DMINOR_VERSION=0 -I. -I/usr/local/lib/python3.8/dist-packages/pybind11/include -I/usr/include/python3.8 -c version.cc -o build/temp.linux-x86_64-cpython-38/version.o -std=c++17 -fvisibility=hidden -g0
creating build/lib.linux-x86_64-cpython-38
x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -std=c++14 -O3 build/temp.linux-x86_64-cpython-38/bindings/python_api.o build/temp.linux-x86_64-cpython-38/early_stopping.o build/temp.linux-x86_64-cpython-38/generated/version_generated.o build/temp.linux-x86_64-cpython-38/issue_query_controller.o build/temp.linux-x86_64-cpython-38/loadgen.o build/temp.linux-x86_64-cpython-38/logging.o build/temp.linux-x86_64-cpython-38/results.o build/temp.linux-x86_64-cpython-38/test_settings_internal.o build/temp.linux-x86_64-cpython-38/utils.o build/temp.linux-x86_64-cpython-38/version.o -L/usr/lib -o build/lib.linux-x86_64-cpython-38/mlperf_loadgen.cpython-38-x86_64-linux-gnu.so
installing to build/bdist.linux-x86_64/wheel
running install
running install_lib
creating build/bdist.linux-x86_64
creating build/bdist.linux-x86_64/wheel
copying build/lib.linux-x86_64-cpython-38/mlperf_loadgen.cpython-38-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel
running install_egg_info
running egg_info
creating mlperf_loadgen.egg-info
writing mlperf_loadgen.egg-info/PKG-INFO
writing dependency_links to mlperf_loadgen.egg-info/dependency_links.txt
writing top-level names to mlperf_loadgen.egg-info/top_level.txt
writing manifest file 'mlperf_loadgen.egg-info/SOURCES.txt'
reading manifest file 'mlperf_loadgen.egg-info/SOURCES.txt'
writing manifest file 'mlperf_loadgen.egg-info/SOURCES.txt'
Copying mlperf_loadgen.egg-info to build/bdist.linux-x86_64/wheel/mlperf_loadgen-4.0-py3.8.egg-info
running install_scripts
creating build/bdist.linux-x86_64/wheel/mlperf_loadgen-4.0.dist-info/WHEEL
creating 'dist/mlperf_loadgen-4.0-cp38-cp38-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it
adding 'mlperf_loadgen.cpython-38-x86_64-linux-gnu.so'
adding 'mlperf_loadgen-4.0.dist-info/METADATA'
adding 'mlperf_loadgen-4.0.dist-info/WHEEL'
adding 'mlperf_loadgen-4.0.dist-info/top_level.txt'
adding 'mlperf_loadgen-4.0.dist-info/RECORD'
removing build/bdist.linux-x86_64/wheel
/usr/local/lib/python3.8/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.
  warnings.warn(
Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com
Processing ./dist/mlperf_loadgen-4.0-cp38-cp38-linux_x86_64.whl
Installing collected packages: mlperf-loadgen
Successfully installed mlperf-loadgen-4.0
make[1]: Leaving directory '/work'
make[1]: Entering directory '/work'
Building harness...
-- The C compiler identification is GNU 9.4.0
-- The CXX compiler identification is GNU 9.4.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: /usr/bin/cc - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: /usr/bin/c++ - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD
-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed
-- Looking for pthread_create in pthreads
-- Looking for pthread_create in pthreads - not found
-- Looking for pthread_create in pthread
-- Looking for pthread_create in pthread - found
-- Found Threads: TRUE  
-- Found CUDA: /usr/local/cuda (found version "12.2") 
Warning: setting -Wno-deprecated-declarations to avoid header warnings
-- The CUDA compiler identification is NVIDIA 12.2.140
-- Detecting CUDA compiler ABI info
-- Detecting CUDA compiler ABI info - done
-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped
-- Detecting CUDA compile features
-- Detecting CUDA compile features - done
Building default harness...
Building 3D-UNet-KiTS19 harness...
Building RNN-T harness...
-- DALI libraries DIR: /usr/local/lib/python3.8/dist-packages/nvidia/dali
-- DALI include DIR: /usr/local/lib/python3.8/dist-packages/nvidia/dali/include
-- DALI linked libraries: dalidali_operatorsdali_kernels
Building BERT harness...
Building DLRMv2 harness...
-- Configuring done
CMake Warning (dev) in CMakeLists.txt:
  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,
  empty CUDA_ARCHITECTURES not allowed.  Run "cmake --help-policy CMP0104"
  for policy details.  Use the cmake_policy command to set the policy and
  suppress this warning.

  CUDA_ARCHITECTURES is empty for target "harness_3dunet".
This warning is for project developers.  Use -Wno-dev to suppress it.

CMake Warning (dev) in CMakeLists.txt:
  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,
  empty CUDA_ARCHITECTURES not allowed.  Run "cmake --help-policy CMP0104"
  for policy details.  Use the cmake_policy command to set the policy and
  suppress this warning.

  CUDA_ARCHITECTURES is empty for target "harness_rnnt".
This warning is for project developers.  Use -Wno-dev to suppress it.

CMake Warning (dev) in CMakeLists.txt:
  Policy CMP0104 is not set: CMAKE_CUDA_ARCHITECTURES now detected for NVCC,
  empty CUDA_ARCHITECTURES not allowed.  Run "cmake --help-policy CMP0104"
  for policy details.  Use the cmake_policy command to set the policy and
  suppress this warning.

  CUDA_ARCHITECTURES is empty for target "harness_dlrm_v2".
This warning is for project developers.  Use -Wno-dev to suppress it.

-- Generating done
CMake Warning:
  Manually-specified variables were not used by the project:

    USE_RELEASE_TRTLLM


-- Build files have been written to: /work/build/harness
make[2]: Entering directory '/work/build/harness'
make[3]: Entering directory '/work/build/harness'
make[4]: Entering directory '/work/build/harness'
make[4]: Entering directory '/work/build/harness'
make[4]: Entering directory '/work/build/harness'
make[4]: Entering directory '/work/build/harness'
make[4]: Entering directory '/work/build/harness'
make[4]: Leaving directory '/work/build/harness'
make[4]: Leaving directory '/work/build/harness'
make[4]: Leaving directory '/work/build/harness'
make[4]: Leaving directory '/work/build/harness'
make[4]: Entering directory '/work/build/harness'
make[4]: Leaving directory '/work/build/harness'
make[4]: Entering directory '/work/build/harness'
make[4]: Entering directory '/work/build/harness'
make[4]: Entering directory '/work/build/harness'
make[4]: Entering directory '/work/build/harness'
[  4%] Building CXX object lwis/CMakeFiles/lwis.dir/src/lwis.cpp.o
[  8%] Building CXX object CMakeFiles/harness_3dunet.dir/harness_3dunet/main_3dunet.cc.o
[ 12%] Building CXX object CMakeFiles/harness_rnnt.dir/harness_rnnt/main_rnnt.cc.o
[ 24%] Building CUDA object CMakeFiles/harness_3dunet.dir/harness_3dunet/unet3d_sw.cu.o
[ 24%] Building CUDA object CMakeFiles/harness_rnnt.dir/harness_rnnt/rnnt_kernels.cu.o
[ 24%] Building CXX object CMakeFiles/harness_3dunet.dir/harness_3dunet/lwis_3dunet.cpp.o
[ 28%] Building CXX object CMakeFiles/harness_bert.dir/harness_bert/main_bert.cc.o
[ 36%] Building CXX object CMakeFiles/harness_3dunet.dir/common/logger.cpp.o
[ 40%] Building CXX object CMakeFiles/harness_rnnt.dir/common/logger.cpp.o
[ 40%] Building CXX object CMakeFiles/harness_bert.dir/harness_bert/bert_core_vs.cc.o
[ 52%] Building CXX object CMakeFiles/harness_dlrm_v2.dir/harness_dlrm_v2/main_dlrm_v2.cpp.o
[ 52%] Building CXX object CMakeFiles/harness_bert.dir/harness_bert/bert_server.cc.o
[ 52%] Building CXX object CMakeFiles/harness_bert.dir/common/logger.cpp.o
[ 60%] Building CXX object CMakeFiles/harness_dlrm_v2.dir/harness_dlrm_v2/dlrm_v2_server.cpp.o
[ 68%] Building CXX object CMakeFiles/harness_dlrm_v2.dir/harness_dlrm_v2/batch_maker.cpp.o
[ 68%] Building CXX object CMakeFiles/harness_dlrm_v2.dir/common/logger.cpp.o
[ 68%] Building CUDA object CMakeFiles/harness_dlrm_v2.dir/harness_dlrm_v2/dlrm_v2_kernels.cu.o
[ 72%] Linking CXX static library liblwis.a
make[4]: Leaving directory '/work/build/harness'
[ 72%] Built target lwis
make[4]: Entering directory '/work/build/harness'
make[4]: Leaving directory '/work/build/harness'
make[4]: Entering directory '/work/build/harness'
[ 80%] Building CXX object CMakeFiles/harness_default.dir/common/logger.cpp.o
[ 80%] Building CXX object CMakeFiles/harness_default.dir/harness_default/main_default.cc.o
[ 84%] Linking CXX executable /work/build/bin/harness_bert
make[4]: Leaving directory '/work/build/harness'
[ 84%] Built target harness_bert
[ 88%] Linking CXX executable /work/build/bin/harness_dlrm_v2
make[4]: Leaving directory '/work/build/harness'
[ 88%] Built target harness_dlrm_v2
[ 92%] Linking CXX executable /work/build/bin/harness_3dunet
make[4]: Leaving directory '/work/build/harness'
[ 92%] Built target harness_3dunet
[ 96%] Linking CXX executable /work/build/bin/harness_rnnt
make[4]: Leaving directory '/work/build/harness'
[ 96%] Built target harness_rnnt
[100%] Linking CXX executable /work/build/bin/harness_default
make[4]: Leaving directory '/work/build/harness'
[100%] Built target harness_default
make[3]: Leaving directory '/work/build/harness'
make[2]: Leaving directory '/work/build/harness'
Finished building harness.
make[1]: Leaving directory '/work'
make[1]: Entering directory '/work'
Skip cloning FasterTransformer for SM 80.
Skip building FasterTransformer for SM 80.
make[1]: Leaving directory '/work'
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work$ ls -l
total 552
-rwxr-xr-x  1 yhara yhara   9062 Feb  9 20:19 [0m[01;32mMakefile[0m
-rwxr-xr-x  1 yhara yhara  12073 Feb  9 20:19 [01;32mMakefile.build[0m
-rwxr-xr-x  1 yhara yhara   5810 Feb  9 20:19 [01;32mMakefile.const[0m
-rwxr-xr-x  1 yhara yhara   1501 Feb  9 20:19 [01;32mMakefile.data[0m
-rwxr-xr-x  1 yhara yhara  13172 Feb  9 20:21 [01;32mMakefile.docker[0m
-rwxr-xr-x  1 yhara yhara  21031 Feb  9 20:19 [01;32mMakefile.power[0m
-rwxr-xr-x  1 yhara yhara   9354 Feb  9 20:19 [01;32mMakefile.submission[0m
-rwxr-xr-x  1 yhara yhara   1703 Feb  9 20:19 [01;32mMakefile.tests[0m
-rwxr-xr-x  1 yhara yhara  48545 Feb  9 20:19 [01;32mREADME.md[0m
-rwxr-xr-x  1 yhara yhara  12378 Feb  9 20:19 [01;32mREADME_Jetson.md[0m
-rwxr-xr-x  1 yhara yhara      5 Feb  9 20:19 [01;32mVERSION[0m
-rwxr-xr-x  1 yhara yhara   3526 Feb  9 20:19 [01;32mattributions.txt[0m
drwxr-xr-x  7 yhara yhara   4096 Feb 21 10:02 [01;34mbuild[0m
drwxr-xr-x 15 yhara yhara   4096 Feb  9 20:30 [01;34mcode[0m
drwxr-xr-x 11 yhara yhara   4096 Feb  9 20:19 [01;34mconfigs[0m
drwxr-xr-x 11 yhara yhara   4096 Feb  9 20:19 [01;34mdata_maps[0m
drwxr-xr-x  3 yhara yhara   4096 Feb  9 20:26 [01;34mdocker[0m
drwxr-xr-x  3 yhara yhara   4096 Feb  9 20:19 [01;34mdocumentation[0m
drwxrwxr-x  2 yhara yhara   4096 Feb 21 09:34 [01;34mfj_scripts[0m
-rw-r--r--  1 yhara yhara 157767 Feb 21 10:02 make_build_00.log
-rw-rw-r--  1 yhara yhara 184406 Feb 21 12:15 make_prebuild_00.log
drwxr-xr-x  3 yhara yhara   4096 Feb  9 20:19 [01;34mpower[0m
drwxr-xr-x 10 yhara yhara   4096 Feb  9 20:19 [01;34mscripts[0m
drwxr-xr-x  2 yhara yhara   4096 Feb  9 20:19 [01;34msystems[0m
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work$ cd build/
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build$ ls
[0m[01;34mbin[0m   [01;34mharness[0m    [01;36mmodels[0m   [01;34mpower-dev[0m          [01;34msubmission-staging[0m
[01;36mdata[0m  [01;34minference[0m  [01;34mplugins[0m  [01;36mpreprocessed_data[0m
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build$ cd submission-staging/
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging$ ls -l
total 4
drwxr-xr-x 3 yhara yhara 4096 Feb 21 10:22 [0m[01;34mclosed[0m
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging$ cd closed/
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed$ ls -l
total 4
drwxr-xr-x 5 yhara yhara 4096 Feb 21 10:22 [0m[01;34mFujitsu[0m
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed$ cd Fujitsu/
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu$ ls -l
total 12
drwxr-xr-x 4 yhara yhara 4096 Feb 21 12:32 [0m[01;34mcompliance[0m
drwxr-xr-x 4 yhara yhara 4096 Feb 21 12:44 [01;34mmeasurements[0m
drwxr-xr-x 3 yhara yhara 4096 Feb 21 10:22 [01;34mresults[0m
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu$ cd[K[Kcd measurements/
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu/measurements$ ls
[0m[01;34mCDI_L40Sx8_TRT[0m  [01;34mGX2560M7_H100_SXM_80GBx4_TRT[0m
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu/measurements$ cd ..
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu$ cd results/
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu/results$ ls
[0m[01;34mGX2560M7_H100_SXM_80GBx4_TRT[0m
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu/results$ cd ..
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu$ ls -l
total 12
drwxr-xr-x 4 yhara yhara 4096 Feb 21 12:32 [0m[01;34mcompliance[0m
drwxr-xr-x 4 yhara yhara 4096 Feb 21 12:44 [01;34mmeasurements[0m
drwxr-xr-x 3 yhara yhara 4096 Feb 21 10:22 [01;34mresults[0m
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu$ [K[A(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu$ cd ..
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed$ ls[K[Kcd [K[K[Kls -l
total 4
drwxr-xr-x 5 yhara yhara 4096 Feb 21 10:22 [0m[01;34mFujitsu[0m
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed$ cd Fujitsu/
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu$ ls -l
total 12
drwxr-xr-x 5 yhara yhara 4096 Feb 21 22:57 [0m[01;34mcompliance[0m
drwxr-xr-x 6 yhara yhara 4096 Feb 22 01:55 [01;34mmeasurements[0m
drwxr-xr-x 6 yhara yhara 4096 Feb 22 01:59 [01;34mresults[0m
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu$ cd compliance/
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu/compliance$ ls -l
total 12
drwxr-xr-x 3 yhara yhara 4096 Feb 21 11:05 [0m[01;34mCDI_L40Sx16_TRT[0m
drwxr-xr-x 3 yhara yhara 4096 Feb 21 10:52 [01;34mCDI_L40Sx8_TRT[0m
drwxr-xr-x 3 yhara yhara 4096 Feb 21 10:22 [01;34mGX2560M7_H100_SXM_80GBx4_TRT[0m
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu/compliance$ cd ..
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu$ c[Kcd measurements/
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu/measurements$ ls -l
total 16
drwxr-xr-x 4 yhara yhara 4096 Feb 21 10:56 [0m[01;34mCDI_L40Sx16_TRT[0m
drwxr-xr-x 4 yhara yhara 4096 Feb 22 02:09 [01;34mCDI_L40Sx8_MaxP_TRT[0m
drwxr-xr-x 4 yhara yhara 4096 Feb 21 10:43 [01;34mCDI_L40Sx8_TRT[0m
drwxr-xr-x 6 yhara yhara 4096 Feb 21 10:22 [01;34mGX2560M7_H100_SXM_80GBx4_TRT[0m
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu/measurements$ cd ..
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu$ cd results/
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu/results$ ls -l
total 16
drwxr-xr-x 4 yhara yhara 4096 Feb 21 10:56 [0m[01;34mCDI_L40Sx16_TRT[0m
drwxr-xr-x 4 yhara yhara 4096 Feb 21 13:15 [01;34mCDI_L40Sx8_MaxP_TRT[0m
drwxr-xr-x 4 yhara yhara 4096 Feb 21 10:43 [01;34mCDI_L40Sx8_TRT[0m
drwxr-xr-x 6 yhara yhara 4096 Feb 21 10:31 [01;34mGX2560M7_H100_SXM_80GBx4_TRT[0m
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu/results$ cd ..
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed/Fujitsu$ cd ..
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging/closed$ cd ..
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build/submission-staging$ cd ..
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work/build$ cd ..
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work$ make truncate_results SUBMITTER=Fujitsu
INFO:main:closed/Fujitsu/results/CDI_L40Sx8_MaxP_TRT/gptj-99/Server/accuracy/mlperf_log_accuracy.json truncated
INFO:main:closed/Fujitsu/results/CDI_L40Sx8_MaxP_TRT/gptj-99/Offline/accuracy/mlperf_log_accuracy.json truncated
INFO:main:closed/Fujitsu/results/CDI_L40Sx8_MaxP_TRT/gptj-99.9/Server/accuracy/mlperf_log_accuracy.json truncated
INFO:main:closed/Fujitsu/results/CDI_L40Sx8_MaxP_TRT/gptj-99.9/Offline/accuracy/mlperf_log_accuracy.json truncated
INFO:main:closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/resnet50/Server/accuracy/mlperf_log_accuracy.json truncated
INFO:main:closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/resnet50/Offline/accuracy/mlperf_log_accuracy.json truncated
INFO:main:closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Server/accuracy/mlperf_log_accuracy.json truncated
INFO:main:closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/stable-diffusion-xl/Offline/accuracy/mlperf_log_accuracy.json truncated
INFO:main:closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99/Server/accuracy/mlperf_log_accuracy.json truncated
INFO:main:closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99/Offline/accuracy/mlperf_log_accuracy.json truncated
INFO:main:closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99.9/Server/accuracy/mlperf_log_accuracy.json truncated
INFO:main:closed/Fujitsu/results/GX2560M7_H100_SXM_80GBx4_TRT/gptj-99.9/Offline/accuracy/mlperf_log_accuracy.json truncated
INFO:main:closed/Fujitsu/results/CDI_L40Sx16_TRT/resnet50/Server/accuracy/mlperf_log_accuracy.json truncated
INFO:main:closed/Fujitsu/results/CDI_L40Sx16_TRT/resnet50/Offline/accuracy/mlperf_log_accuracy.json truncated
INFO:main:closed/Fujitsu/results/CDI_L40Sx16_TRT/stable-diffusion-xl/Server/accuracy/mlperf_log_accuracy.json truncated
INFO:main:closed/Fujitsu/results/CDI_L40Sx16_TRT/stable-diffusion-xl/Offline/accuracy/mlperf_log_accuracy.json truncated
INFO:main:closed/Fujitsu/results/CDI_L40Sx8_TRT/resnet50/Server/accuracy/mlperf_log_accuracy.json truncated
INFO:main:closed/Fujitsu/results/CDI_L40Sx8_TRT/resnet50/Offline/accuracy/mlperf_log_accuracy.json truncated
INFO:main:closed/Fujitsu/results/CDI_L40Sx8_TRT/stable-diffusion-xl/Server/accuracy/mlperf_log_accuracy.json truncated
INFO:main:closed/Fujitsu/results/CDI_L40Sx8_TRT/stable-diffusion-xl/Offline/accuracy/mlperf_log_accuracy.json truncated
INFO:main:no accuracy.txt in compliance directory closed/Fujitsu/compliance/GX2560M7_H100_SXM_80GBx4_TRT/resnet50/Server/TEST01/accuracy
INFO:main:closed/Fujitsu/compliance/GX2560M7_H100_SXM_80GBx4_TRT/resnet50/Server/TEST01/accuracy/mlperf_log_accuracy.json truncated
INFO:main:no accuracy.txt in compliance directory closed/Fujitsu/compliance/GX2560M7_H100_SXM_80GBx4_TRT/resnet50/Offline/TEST01/accuracy
INFO:main:closed/Fujitsu/compliance/GX2560M7_H100_SXM_80GBx4_TRT/resnet50/Offline/TEST01/accuracy/mlperf_log_accuracy.json truncated
INFO:main:no accuracy.txt in compliance directory closed/Fujitsu/compliance/CDI_L40Sx16_TRT/resnet50/Server/TEST01/accuracy
INFO:main:closed/Fujitsu/compliance/CDI_L40Sx16_TRT/resnet50/Server/TEST01/accuracy/mlperf_log_accuracy.json truncated
INFO:main:no accuracy.txt in compliance directory closed/Fujitsu/compliance/CDI_L40Sx16_TRT/resnet50/Offline/TEST01/accuracy
INFO:main:closed/Fujitsu/compliance/CDI_L40Sx16_TRT/resnet50/Offline/TEST01/accuracy/mlperf_log_accuracy.json truncated
INFO:main:no accuracy.txt in compliance directory closed/Fujitsu/compliance/CDI_L40Sx8_TRT/resnet50/Server/TEST01/accuracy
INFO:main:closed/Fujitsu/compliance/CDI_L40Sx8_TRT/resnet50/Server/TEST01/accuracy/mlperf_log_accuracy.json truncated
INFO:main:no accuracy.txt in compliance directory closed/Fujitsu/compliance/CDI_L40Sx8_TRT/resnet50/Offline/TEST01/accuracy
INFO:main:closed/Fujitsu/compliance/CDI_L40Sx8_TRT/resnet50/Offline/TEST01/accuracy/mlperf_log_accuracy.json truncated
INFO:main:Make sure you keep a backup of closed/Fujitsu/build/full_results in case mlperf wants to see the original accuracy logs
Full accuracy logs stored in build/full_results/. Truncated results stored in /work/build/submission-staging/results/.
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work$ export SUBMITTER=Fujitsu
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work$ make copy_results_artifacts
cp -R /work/build/submission-staging/closed/Fujitsu/results .
cp -R /work/build/submission-staging/closed/Fujitsu/compliance .
cp -R /work/build/submission-staging/closed/Fujitsu/measurements .
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work$ ls -l
total 576
-rwxr-xr-x  1 yhara yhara   9062 Feb  9 20:19 [0m[01;32mMakefile[0m
-rwxr-xr-x  1 yhara yhara  12073 Feb  9 20:19 [01;32mMakefile.build[0m
-rwxr-xr-x  1 yhara yhara   5810 Feb  9 20:19 [01;32mMakefile.const[0m
-rwxr-xr-x  1 yhara yhara   1501 Feb  9 20:19 [01;32mMakefile.data[0m
-rwxr-xr-x  1 yhara yhara  13172 Feb  9 20:21 [01;32mMakefile.docker[0m
-rwxr-xr-x  1 yhara yhara  21031 Feb  9 20:19 [01;32mMakefile.power[0m
-rwxr-xr-x  1 yhara yhara   9354 Feb  9 20:19 [01;32mMakefile.submission[0m
-rwxr-xr-x  1 yhara yhara   1703 Feb  9 20:19 [01;32mMakefile.tests[0m
-rwxr-xr-x  1 yhara yhara  48545 Feb  9 20:19 [01;32mREADME.md[0m
-rwxr-xr-x  1 yhara yhara  12378 Feb  9 20:19 [01;32mREADME_Jetson.md[0m
-rwxr-xr-x  1 yhara yhara      5 Feb  9 20:19 [01;32mVERSION[0m
-rwxr-xr-x  1 yhara yhara   3526 Feb  9 20:19 [01;32mattributions.txt[0m
drwxr-xr-x  9 yhara yhara   4096 Feb 22 05:26 [01;34mbuild[0m
drwxr-xr-x 15 yhara yhara   4096 Feb  9 20:30 [01;34mcode[0m
drwxr-xr-x  5 yhara yhara   4096 Feb 22 05:33 [01;34mcompliance[0m
drwxr-xr-x  5 yhara yhara   4096 Feb 22 05:06 [01;34mconfigs[0m
drwxr-xr-x 11 yhara yhara   4096 Feb  9 20:19 [01;34mconfigs_old[0m
drwxr-xr-x 11 yhara yhara   4096 Feb  9 20:19 [01;34mdata_maps[0m
drwxr-xr-x  3 yhara yhara   4096 Feb  9 20:26 [01;34mdocker[0m
drwxr-xr-x  3 yhara yhara   4096 Feb  9 20:19 [01;34mdocumentation[0m
drwxrwxr-x  2 yhara yhara   4096 Feb 21 09:34 [01;34mfj_scripts[0m
-rw-r--r--  1 yhara yhara 157767 Feb 21 10:02 make_build_00.log
-rw-rw-r--  1 yhara yhara 196317 Feb 22 05:37 make_prebuild_00.log
drwxr-xr-x  6 yhara yhara   4096 Feb 22 05:33 [01;34mmeasurements[0m
drwxr-xr-x  3 yhara yhara   4096 Feb  9 20:19 [01;34mpower[0m
drwxr-xr-x  6 yhara yhara   4096 Feb 22 05:33 [01;34mresults[0m
drwxr-xr-x 10 yhara yhara   4096 Feb  9 20:19 [01;34mscripts[0m
drwxr-xr-x  2 yhara yhara   4096 Feb 22 00:08 [01;34msystems[0m
(mlperf) yhara@mlperf-inference-yhara-x86-64-8374:/work$ 